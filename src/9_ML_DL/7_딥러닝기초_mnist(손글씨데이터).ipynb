{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T00:43:53.863334Z",
     "start_time": "2021-03-24T00:43:39.943194Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist # 데이터셋\n",
    "from tensorflow.keras.models import Sequential # 모델 생성시\n",
    "from tensorflow.keras.layers import Dense # layers\n",
    "import tensorflow.keras.utils as utils # 원 핫 인코딩\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:02:58.459770Z",
     "start_time": "2021-03-23T07:02:58.031895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 셋 준비하기\n",
    "# 훈련셋, 테스트셋 분리. 보통 7:3으로 분류\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data() # mnist 분리\n",
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:07:22.513384Z",
     "start_time": "2021-03-23T07:07:22.375257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27a99ce3fa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:14:00.040339Z",
     "start_time": "2021-03-23T07:14:00.023404Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋에서 검증셋 분리 (X_train, Y_train)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋 - model이 학습할 때 사용\n",
    "X_train\n",
    "Y_train\n",
    "# 검증셋 - model이 학습할 때 사용\n",
    "X_val\n",
    "Y_val\n",
    "# 테스트셋 - 모델 평가할 때 사용\n",
    "X_test\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:24:31.899930Z",
     "start_time": "2021-03-23T07:24:31.645644Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize 하기 위해 색상값으로 나눔\n",
    "X_train = X_train.reshape(50000,784).astype('float')/255.0\n",
    "X_val = X_val.reshape(10000,784).astype('float')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float')/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:31:06.936033Z",
     "start_time": "2021-03-23T07:31:06.927033Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터가 많아 시간상 매우오래 걸릴 수 있음.\n",
    "# 훈련셋과 검증셋700개,300개씩만 가져옴.\n",
    "train_rand_idx = np.random.choice(50000,700)\n",
    "val_rand_idx = np.random.choice(10000,300)\n",
    "\n",
    "X_train = X_train[train_rand_idx]\n",
    "Y_train = Y_train[train_rand_idx]\n",
    "X_val = X_val[val_rand_idx]\n",
    "Y_val = Y_val[val_rand_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:54:42.976315Z",
     "start_time": "2021-03-23T07:54:42.965350Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train) # 자동으로 해준다\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:12.258506Z",
     "start_time": "2021-03-23T08:15:46.333519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2.3061 - accuracy: 0.1400 - val_loss: 2.2402 - val_accuracy: 0.2000\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2293 - accuracy: 0.1739 - val_loss: 2.1825 - val_accuracy: 0.2567\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1838 - accuracy: 0.2288 - val_loss: 2.1341 - val_accuracy: 0.2567\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1000 - accuracy: 0.2449 - val_loss: 2.0950 - val_accuracy: 0.2633\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0965 - accuracy: 0.2490 - val_loss: 2.0527 - val_accuracy: 0.2700\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0589 - accuracy: 0.2497 - val_loss: 2.0165 - val_accuracy: 0.2700\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0205 - accuracy: 0.2775 - val_loss: 1.9940 - val_accuracy: 0.2733\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9935 - accuracy: 0.2774 - val_loss: 1.9610 - val_accuracy: 0.2767\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8789 - accuracy: 0.3045 - val_loss: 1.9365 - val_accuracy: 0.2767\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8813 - accuracy: 0.3250 - val_loss: 1.9202 - val_accuracy: 0.2800\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9146 - accuracy: 0.2895 - val_loss: 1.8979 - val_accuracy: 0.2767\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8488 - accuracy: 0.3107 - val_loss: 1.8711 - val_accuracy: 0.2833\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 1.8260 - accuracy: 0.3195 - val_loss: 1.8557 - val_accuracy: 0.2900\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8584 - accuracy: 0.2892 - val_loss: 1.8483 - val_accuracy: 0.2867\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8075 - accuracy: 0.3461 - val_loss: 1.8262 - val_accuracy: 0.3000\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8294 - accuracy: 0.3144 - val_loss: 1.8060 - val_accuracy: 0.2967\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7830 - accuracy: 0.3197 - val_loss: 1.7905 - val_accuracy: 0.3100\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7798 - accuracy: 0.3427 - val_loss: 1.7873 - val_accuracy: 0.3100\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7551 - accuracy: 0.3631 - val_loss: 1.7744 - val_accuracy: 0.3167\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7180 - accuracy: 0.3437 - val_loss: 1.7542 - val_accuracy: 0.3300\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7187 - accuracy: 0.3564 - val_loss: 1.7425 - val_accuracy: 0.3367\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7064 - accuracy: 0.3480 - val_loss: 1.7327 - val_accuracy: 0.3333\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6999 - accuracy: 0.3553 - val_loss: 1.7134 - val_accuracy: 0.3367\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6754 - accuracy: 0.3524 - val_loss: 1.7078 - val_accuracy: 0.3333\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6738 - accuracy: 0.3496 - val_loss: 1.7055 - val_accuracy: 0.3267\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6125 - accuracy: 0.3979 - val_loss: 1.6952 - val_accuracy: 0.3433\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6166 - accuracy: 0.3630 - val_loss: 1.6740 - val_accuracy: 0.3400\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6408 - accuracy: 0.3505 - val_loss: 1.6740 - val_accuracy: 0.3433\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5666 - accuracy: 0.4160 - val_loss: 1.6576 - val_accuracy: 0.3500\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5931 - accuracy: 0.3920 - val_loss: 1.6442 - val_accuracy: 0.3500\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5771 - accuracy: 0.3652 - val_loss: 1.6428 - val_accuracy: 0.3633\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5561 - accuracy: 0.4172 - val_loss: 1.6388 - val_accuracy: 0.3867\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5837 - accuracy: 0.3948 - val_loss: 1.6210 - val_accuracy: 0.3667\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5477 - accuracy: 0.4117 - val_loss: 1.6105 - val_accuracy: 0.3600\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5391 - accuracy: 0.4291 - val_loss: 1.6105 - val_accuracy: 0.3767\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4539 - accuracy: 0.4553 - val_loss: 1.5912 - val_accuracy: 0.3767\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5170 - accuracy: 0.4349 - val_loss: 1.5875 - val_accuracy: 0.3767\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5153 - accuracy: 0.4001 - val_loss: 1.5787 - val_accuracy: 0.3867\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5110 - accuracy: 0.4246 - val_loss: 1.5709 - val_accuracy: 0.3967\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4809 - accuracy: 0.4345 - val_loss: 1.5819 - val_accuracy: 0.4100\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 1.4541 - accuracy: 0.4197 - val_loss: 1.5654 - val_accuracy: 0.3833\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 1.4358 - accuracy: 0.4730 - val_loss: 1.5597 - val_accuracy: 0.3967\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4760 - accuracy: 0.4253 - val_loss: 1.5484 - val_accuracy: 0.4033\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4445 - accuracy: 0.4483 - val_loss: 1.5423 - val_accuracy: 0.3967\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4460 - accuracy: 0.4446 - val_loss: 1.5345 - val_accuracy: 0.4067\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4611 - accuracy: 0.4566 - val_loss: 1.5326 - val_accuracy: 0.4133\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4154 - accuracy: 0.4527 - val_loss: 1.5183 - val_accuracy: 0.4033\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4041 - accuracy: 0.4350 - val_loss: 1.5209 - val_accuracy: 0.4400\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3859 - accuracy: 0.4501 - val_loss: 1.5284 - val_accuracy: 0.4467\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4204 - accuracy: 0.4445 - val_loss: 1.5097 - val_accuracy: 0.4433\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3691 - accuracy: 0.4554 - val_loss: 1.5108 - val_accuracy: 0.4567\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3878 - accuracy: 0.4893 - val_loss: 1.4956 - val_accuracy: 0.4467\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3703 - accuracy: 0.4720 - val_loss: 1.4991 - val_accuracy: 0.4533\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3603 - accuracy: 0.4678 - val_loss: 1.4905 - val_accuracy: 0.4600\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 944us/step - loss: 1.3530 - accuracy: 0.4867 - val_loss: 1.4831 - val_accuracy: 0.4633\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4000 - accuracy: 0.4981 - val_loss: 1.4880 - val_accuracy: 0.4600\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 981us/step - loss: 1.3669 - accuracy: 0.4789 - val_loss: 1.4788 - val_accuracy: 0.4667\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3104 - accuracy: 0.5560 - val_loss: 1.4794 - val_accuracy: 0.4600\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3192 - accuracy: 0.4944 - val_loss: 1.4770 - val_accuracy: 0.4633\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3282 - accuracy: 0.5006 - val_loss: 1.4600 - val_accuracy: 0.4833\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3428 - accuracy: 0.5320 - val_loss: 1.4549 - val_accuracy: 0.5000\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2771 - accuracy: 0.5320 - val_loss: 1.4663 - val_accuracy: 0.4667\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2957 - accuracy: 0.5307 - val_loss: 1.4416 - val_accuracy: 0.4833\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3374 - accuracy: 0.4930 - val_loss: 1.4439 - val_accuracy: 0.4867\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2640 - accuracy: 0.5465 - val_loss: 1.4625 - val_accuracy: 0.4633\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3122 - accuracy: 0.4999 - val_loss: 1.4382 - val_accuracy: 0.5000\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2698 - accuracy: 0.5344 - val_loss: 1.4371 - val_accuracy: 0.5167\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2840 - accuracy: 0.5390 - val_loss: 1.4289 - val_accuracy: 0.5067\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2589 - accuracy: 0.5607 - val_loss: 1.4294 - val_accuracy: 0.4933\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2601 - accuracy: 0.5639 - val_loss: 1.4266 - val_accuracy: 0.5100\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2439 - accuracy: 0.5643 - val_loss: 1.4195 - val_accuracy: 0.5000\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2882 - accuracy: 0.5639 - val_loss: 1.4223 - val_accuracy: 0.5133\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2335 - accuracy: 0.5760 - val_loss: 1.4120 - val_accuracy: 0.5000\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2148 - accuracy: 0.5773 - val_loss: 1.4137 - val_accuracy: 0.4800\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2444 - accuracy: 0.5314 - val_loss: 1.4140 - val_accuracy: 0.4967\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1854 - accuracy: 0.5520 - val_loss: 1.4115 - val_accuracy: 0.4967\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2480 - accuracy: 0.5784 - val_loss: 1.4144 - val_accuracy: 0.5100\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1909 - accuracy: 0.5996 - val_loss: 1.4048 - val_accuracy: 0.5033\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2342 - accuracy: 0.5796 - val_loss: 1.4198 - val_accuracy: 0.4833\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2221 - accuracy: 0.5566 - val_loss: 1.4119 - val_accuracy: 0.5033\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2007 - accuracy: 0.5678 - val_loss: 1.4055 - val_accuracy: 0.4967\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1610 - accuracy: 0.5980 - val_loss: 1.4089 - val_accuracy: 0.4867\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1649 - accuracy: 0.6227 - val_loss: 1.4120 - val_accuracy: 0.5000\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1757 - accuracy: 0.6081 - val_loss: 1.4077 - val_accuracy: 0.5033\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1838 - accuracy: 0.5836 - val_loss: 1.3983 - val_accuracy: 0.5267\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2042 - accuracy: 0.5887 - val_loss: 1.3989 - val_accuracy: 0.4900\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1616 - accuracy: 0.6098 - val_loss: 1.3989 - val_accuracy: 0.5000\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1978 - accuracy: 0.6009 - val_loss: 1.3982 - val_accuracy: 0.4933\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2044 - accuracy: 0.5687 - val_loss: 1.4001 - val_accuracy: 0.4900\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2262 - accuracy: 0.5754 - val_loss: 1.3918 - val_accuracy: 0.5100\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1797 - accuracy: 0.5632 - val_loss: 1.3928 - val_accuracy: 0.5000\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1332 - accuracy: 0.6230 - val_loss: 1.4028 - val_accuracy: 0.4833\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1519 - accuracy: 0.6085 - val_loss: 1.3965 - val_accuracy: 0.4867\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 961us/step - loss: 1.1464 - accuracy: 0.5871 - val_loss: 1.4100 - val_accuracy: 0.4933\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1498 - accuracy: 0.6038 - val_loss: 1.3903 - val_accuracy: 0.4967\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1532 - accuracy: 0.5865 - val_loss: 1.3901 - val_accuracy: 0.5000\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1295 - accuracy: 0.6143 - val_loss: 1.4118 - val_accuracy: 0.4867\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1138 - accuracy: 0.6119 - val_loss: 1.3910 - val_accuracy: 0.5033\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1413 - accuracy: 0.6086 - val_loss: 1.3897 - val_accuracy: 0.5133\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1602 - accuracy: 0.5988 - val_loss: 1.3914 - val_accuracy: 0.5000\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1383 - accuracy: 0.6315 - val_loss: 1.3882 - val_accuracy: 0.4967\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1228 - accuracy: 0.6154 - val_loss: 1.3972 - val_accuracy: 0.4933\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1050 - accuracy: 0.6238 - val_loss: 1.4037 - val_accuracy: 0.4867\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1332 - accuracy: 0.6319 - val_loss: 1.3858 - val_accuracy: 0.4967\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1400 - accuracy: 0.6303 - val_loss: 1.3895 - val_accuracy: 0.4900\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1297 - accuracy: 0.5974 - val_loss: 1.3941 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0936 - accuracy: 0.6244 - val_loss: 1.3939 - val_accuracy: 0.4833\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0845 - accuracy: 0.6573 - val_loss: 1.3939 - val_accuracy: 0.4867\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1121 - accuracy: 0.6502 - val_loss: 1.3970 - val_accuracy: 0.4967\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 1.0806 - accuracy: 0.6504 - val_loss: 1.3907 - val_accuracy: 0.4867\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0517 - accuracy: 0.6437 - val_loss: 1.3961 - val_accuracy: 0.4833\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0871 - accuracy: 0.6369 - val_loss: 1.4025 - val_accuracy: 0.4867\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0347 - accuracy: 0.6515 - val_loss: 1.3931 - val_accuracy: 0.4933\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0873 - accuracy: 0.6331 - val_loss: 1.3995 - val_accuracy: 0.4900\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0914 - accuracy: 0.6285 - val_loss: 1.3959 - val_accuracy: 0.4967\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1046 - accuracy: 0.6007 - val_loss: 1.3989 - val_accuracy: 0.4767\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1050 - accuracy: 0.6052 - val_loss: 1.4032 - val_accuracy: 0.4933\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0914 - accuracy: 0.6347 - val_loss: 1.4026 - val_accuracy: 0.5000\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0704 - accuracy: 0.6349 - val_loss: 1.3987 - val_accuracy: 0.4967\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0612 - accuracy: 0.6106 - val_loss: 1.4020 - val_accuracy: 0.4900\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0892 - accuracy: 0.6357 - val_loss: 1.4039 - val_accuracy: 0.4900\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1398 - accuracy: 0.6286 - val_loss: 1.3954 - val_accuracy: 0.4933\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0768 - accuracy: 0.6474 - val_loss: 1.3991 - val_accuracy: 0.4967\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0760 - accuracy: 0.6344 - val_loss: 1.4266 - val_accuracy: 0.4733\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 951us/step - loss: 1.0569 - accuracy: 0.6681 - val_loss: 1.4014 - val_accuracy: 0.4867\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0582 - accuracy: 0.6366 - val_loss: 1.4009 - val_accuracy: 0.4900\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0635 - accuracy: 0.6694 - val_loss: 1.3999 - val_accuracy: 0.4833\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0758 - accuracy: 0.6498 - val_loss: 1.4136 - val_accuracy: 0.4733\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0511 - accuracy: 0.6847 - val_loss: 1.4083 - val_accuracy: 0.4833\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0423 - accuracy: 0.6189 - val_loss: 1.4033 - val_accuracy: 0.4933\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0707 - accuracy: 0.6119 - val_loss: 1.4017 - val_accuracy: 0.4800\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 1.0833 - accuracy: 0.6613 - val_loss: 1.4016 - val_accuracy: 0.4767\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.9827 - accuracy: 0.6691 - val_loss: 1.4071 - val_accuracy: 0.4900\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0459 - accuracy: 0.6727 - val_loss: 1.4193 - val_accuracy: 0.4767\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0846 - accuracy: 0.6349 - val_loss: 1.4102 - val_accuracy: 0.4867\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0229 - accuracy: 0.6612 - val_loss: 1.4294 - val_accuracy: 0.4800\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0379 - accuracy: 0.6201 - val_loss: 1.4193 - val_accuracy: 0.4933\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0236 - accuracy: 0.6690 - val_loss: 1.4171 - val_accuracy: 0.4933\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0278 - accuracy: 0.6553 - val_loss: 1.4088 - val_accuracy: 0.4833\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0500 - accuracy: 0.6368 - val_loss: 1.4147 - val_accuracy: 0.4867\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0461 - accuracy: 0.6721 - val_loss: 1.4102 - val_accuracy: 0.4900\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0698 - accuracy: 0.6377 - val_loss: 1.4158 - val_accuracy: 0.4933\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0164 - accuracy: 0.6412 - val_loss: 1.4117 - val_accuracy: 0.4967\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 1.0177 - accuracy: 0.6735 - val_loss: 1.4257 - val_accuracy: 0.5067\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0066 - accuracy: 0.6535 - val_loss: 1.4475 - val_accuracy: 0.4867\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 1.0581 - accuracy: 0.6412 - val_loss: 1.4176 - val_accuracy: 0.5000\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0681 - accuracy: 0.6537 - val_loss: 1.4207 - val_accuracy: 0.4867\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9967 - accuracy: 0.6518 - val_loss: 1.4242 - val_accuracy: 0.4900\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 946us/step - loss: 0.9613 - accuracy: 0.7007 - val_loss: 1.4207 - val_accuracy: 0.4933\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 1.0136 - accuracy: 0.6746 - val_loss: 1.4202 - val_accuracy: 0.4900\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0105 - accuracy: 0.6847 - val_loss: 1.4294 - val_accuracy: 0.5000\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9892 - accuracy: 0.6432 - val_loss: 1.4303 - val_accuracy: 0.4833\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0534 - accuracy: 0.6259 - val_loss: 1.4382 - val_accuracy: 0.4867\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0079 - accuracy: 0.6665 - val_loss: 1.4306 - val_accuracy: 0.4900\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0674 - accuracy: 0.6738 - val_loss: 1.4354 - val_accuracy: 0.4900\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0582 - accuracy: 0.6567 - val_loss: 1.4394 - val_accuracy: 0.4900\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0132 - accuracy: 0.6479 - val_loss: 1.4367 - val_accuracy: 0.4900\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0161 - accuracy: 0.6580 - val_loss: 1.4395 - val_accuracy: 0.4900\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9812 - accuracy: 0.7079 - val_loss: 1.4330 - val_accuracy: 0.4933\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.6810 - val_loss: 1.4480 - val_accuracy: 0.4700\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0284 - accuracy: 0.6603 - val_loss: 1.4361 - val_accuracy: 0.4867\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9716 - accuracy: 0.6799 - val_loss: 1.4436 - val_accuracy: 0.4633\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 988us/step - loss: 1.0193 - accuracy: 0.6783 - val_loss: 1.4354 - val_accuracy: 0.4833\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9810 - accuracy: 0.6948 - val_loss: 1.4450 - val_accuracy: 0.4967\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 0.9724 - accuracy: 0.6912 - val_loss: 1.4502 - val_accuracy: 0.4833\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9523 - accuracy: 0.7134 - val_loss: 1.4411 - val_accuracy: 0.4767\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9651 - accuracy: 0.6862 - val_loss: 1.4471 - val_accuracy: 0.5000\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9712 - accuracy: 0.7056 - val_loss: 1.4544 - val_accuracy: 0.4833\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9501 - accuracy: 0.6846 - val_loss: 1.4664 - val_accuracy: 0.4767\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9765 - accuracy: 0.6852 - val_loss: 1.4475 - val_accuracy: 0.4967\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9637 - accuracy: 0.6767 - val_loss: 1.4689 - val_accuracy: 0.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9911 - accuracy: 0.6772 - val_loss: 1.4526 - val_accuracy: 0.4833\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.6623 - val_loss: 1.4529 - val_accuracy: 0.4767\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9715 - accuracy: 0.6835 - val_loss: 1.4568 - val_accuracy: 0.4800\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9571 - accuracy: 0.7125 - val_loss: 1.4508 - val_accuracy: 0.4833\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.7032 - val_loss: 1.4603 - val_accuracy: 0.4800\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9555 - accuracy: 0.6689 - val_loss: 1.4619 - val_accuracy: 0.4800\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9995 - accuracy: 0.6695 - val_loss: 1.4571 - val_accuracy: 0.4800\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9719 - accuracy: 0.6860 - val_loss: 1.4749 - val_accuracy: 0.4700\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9699 - accuracy: 0.6854 - val_loss: 1.4639 - val_accuracy: 0.4700\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9553 - accuracy: 0.6884 - val_loss: 1.4685 - val_accuracy: 0.4767\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9706 - accuracy: 0.6870 - val_loss: 1.4632 - val_accuracy: 0.4767\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9256 - accuracy: 0.6956 - val_loss: 1.4728 - val_accuracy: 0.4600\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9613 - accuracy: 0.6859 - val_loss: 1.4716 - val_accuracy: 0.4667\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9452 - accuracy: 0.7066 - val_loss: 1.4695 - val_accuracy: 0.4700\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9403 - accuracy: 0.7143 - val_loss: 1.4713 - val_accuracy: 0.4700\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9736 - accuracy: 0.6870 - val_loss: 1.4745 - val_accuracy: 0.4767\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9306 - accuracy: 0.6929 - val_loss: 1.4756 - val_accuracy: 0.4733\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9269 - accuracy: 0.6930 - val_loss: 1.4715 - val_accuracy: 0.4567\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9075 - accuracy: 0.7055 - val_loss: 1.4780 - val_accuracy: 0.4667\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9040 - accuracy: 0.7223 - val_loss: 1.4933 - val_accuracy: 0.4700\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9171 - accuracy: 0.6967 - val_loss: 1.4923 - val_accuracy: 0.4700\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9131 - accuracy: 0.7023 - val_loss: 1.4819 - val_accuracy: 0.4700\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9136 - accuracy: 0.7070 - val_loss: 1.4873 - val_accuracy: 0.4600\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0202 - accuracy: 0.6653 - val_loss: 1.5015 - val_accuracy: 0.4667\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9255 - accuracy: 0.7111 - val_loss: 1.4883 - val_accuracy: 0.4833\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9174 - accuracy: 0.7006 - val_loss: 1.5024 - val_accuracy: 0.4567\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 981us/step - loss: 0.9381 - accuracy: 0.7014 - val_loss: 1.4854 - val_accuracy: 0.4667\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8955 - accuracy: 0.7258 - val_loss: 1.5028 - val_accuracy: 0.4567\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9382 - accuracy: 0.7015 - val_loss: 1.4861 - val_accuracy: 0.4567\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9210 - accuracy: 0.7112 - val_loss: 1.4919 - val_accuracy: 0.4700\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8940 - accuracy: 0.7499 - val_loss: 1.4919 - val_accuracy: 0.4567\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9610 - accuracy: 0.6784 - val_loss: 1.4922 - val_accuracy: 0.4567\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.9303 - accuracy: 0.6929 - val_loss: 1.5070 - val_accuracy: 0.4567\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.7102 - val_loss: 1.5040 - val_accuracy: 0.4633\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9313 - accuracy: 0.7159 - val_loss: 1.5017 - val_accuracy: 0.4633\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8958 - accuracy: 0.7456 - val_loss: 1.5178 - val_accuracy: 0.4733\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8973 - accuracy: 0.7239 - val_loss: 1.5075 - val_accuracy: 0.4467\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9450 - accuracy: 0.6779 - val_loss: 1.4999 - val_accuracy: 0.4633\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8888 - accuracy: 0.7333 - val_loss: 1.5141 - val_accuracy: 0.4533\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9843 - accuracy: 0.7027 - val_loss: 1.5094 - val_accuracy: 0.4567\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8871 - accuracy: 0.7314 - val_loss: 1.5138 - val_accuracy: 0.4567\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8565 - accuracy: 0.7468 - val_loss: 1.5285 - val_accuracy: 0.4633\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8737 - accuracy: 0.7245 - val_loss: 1.5210 - val_accuracy: 0.4500\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9037 - accuracy: 0.7024 - val_loss: 1.5239 - val_accuracy: 0.4600\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.9348 - accuracy: 0.7047 - val_loss: 1.5189 - val_accuracy: 0.4633\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 976us/step - loss: 0.9112 - accuracy: 0.7128 - val_loss: 1.5268 - val_accuracy: 0.4533\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 959us/step - loss: 0.8770 - accuracy: 0.7216 - val_loss: 1.5212 - val_accuracy: 0.4600\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9245 - accuracy: 0.7015 - val_loss: 1.5221 - val_accuracy: 0.4633\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 961us/step - loss: 0.8724 - accuracy: 0.7218 - val_loss: 1.5344 - val_accuracy: 0.4567\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8717 - accuracy: 0.7482 - val_loss: 1.5220 - val_accuracy: 0.4600\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8666 - accuracy: 0.7274 - val_loss: 1.5362 - val_accuracy: 0.4733\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.7216 - val_loss: 1.5298 - val_accuracy: 0.4500\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9145 - accuracy: 0.7135 - val_loss: 1.5275 - val_accuracy: 0.4533\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8950 - accuracy: 0.7370 - val_loss: 1.5255 - val_accuracy: 0.4567\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 984us/step - loss: 0.9115 - accuracy: 0.6986 - val_loss: 1.5316 - val_accuracy: 0.4600\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8798 - accuracy: 0.7145 - val_loss: 1.5292 - val_accuracy: 0.4633\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.8905 - accuracy: 0.7354 - val_loss: 1.5308 - val_accuracy: 0.4567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.7312 - val_loss: 1.5368 - val_accuracy: 0.4533\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.9033 - accuracy: 0.7087 - val_loss: 1.5397 - val_accuracy: 0.4533\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 997us/step - loss: 0.8621 - accuracy: 0.7140 - val_loss: 1.5479 - val_accuracy: 0.4500\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8768 - accuracy: 0.7386 - val_loss: 1.5474 - val_accuracy: 0.4533\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9138 - accuracy: 0.6908 - val_loss: 1.5601 - val_accuracy: 0.4533\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8836 - accuracy: 0.7098 - val_loss: 1.5446 - val_accuracy: 0.4533\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8613 - accuracy: 0.7331 - val_loss: 1.5415 - val_accuracy: 0.4533\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8683 - accuracy: 0.7481 - val_loss: 1.5440 - val_accuracy: 0.4600\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8675 - accuracy: 0.6969 - val_loss: 1.5552 - val_accuracy: 0.4567\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9140 - accuracy: 0.7413 - val_loss: 1.5601 - val_accuracy: 0.4567\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8298 - accuracy: 0.7391 - val_loss: 1.5506 - val_accuracy: 0.4633\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8447 - accuracy: 0.7436 - val_loss: 1.5518 - val_accuracy: 0.4600\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8821 - accuracy: 0.7385 - val_loss: 1.5673 - val_accuracy: 0.4533\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9055 - accuracy: 0.7053 - val_loss: 1.5660 - val_accuracy: 0.4600\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8767 - accuracy: 0.7228 - val_loss: 1.5593 - val_accuracy: 0.4567\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8668 - accuracy: 0.7119 - val_loss: 1.5686 - val_accuracy: 0.4500\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9050 - accuracy: 0.7055 - val_loss: 1.5607 - val_accuracy: 0.4533\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8492 - accuracy: 0.7698 - val_loss: 1.5588 - val_accuracy: 0.4567\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8261 - accuracy: 0.7494 - val_loss: 1.5616 - val_accuracy: 0.4600\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8421 - accuracy: 0.7298 - val_loss: 1.5631 - val_accuracy: 0.4633\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8824 - accuracy: 0.7326 - val_loss: 1.5738 - val_accuracy: 0.4600\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8985 - accuracy: 0.7305 - val_loss: 1.5710 - val_accuracy: 0.4567\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8655 - accuracy: 0.7531 - val_loss: 1.5835 - val_accuracy: 0.4500\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8430 - accuracy: 0.7402 - val_loss: 1.5759 - val_accuracy: 0.4533\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8382 - accuracy: 0.7410 - val_loss: 1.5948 - val_accuracy: 0.4600\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8135 - accuracy: 0.7226 - val_loss: 1.5818 - val_accuracy: 0.4500\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8738 - accuracy: 0.7319 - val_loss: 1.5867 - val_accuracy: 0.4533\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8694 - accuracy: 0.7392 - val_loss: 1.5805 - val_accuracy: 0.4600\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8638 - accuracy: 0.7199 - val_loss: 1.5872 - val_accuracy: 0.4700\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8505 - accuracy: 0.7444 - val_loss: 1.5813 - val_accuracy: 0.4600\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8330 - accuracy: 0.7321 - val_loss: 1.5892 - val_accuracy: 0.4733\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.8342 - accuracy: 0.7366 - val_loss: 1.5918 - val_accuracy: 0.4633\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 993us/step - loss: 0.8179 - accuracy: 0.7411 - val_loss: 1.5926 - val_accuracy: 0.4500\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8422 - accuracy: 0.7431 - val_loss: 1.6031 - val_accuracy: 0.4533\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8668 - accuracy: 0.7243 - val_loss: 1.5999 - val_accuracy: 0.4567\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8642 - accuracy: 0.7332 - val_loss: 1.6065 - val_accuracy: 0.4567\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.8597 - accuracy: 0.7601 - val_loss: 1.6144 - val_accuracy: 0.4500\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8865 - accuracy: 0.7097 - val_loss: 1.6011 - val_accuracy: 0.4533\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8094 - accuracy: 0.7568 - val_loss: 1.5968 - val_accuracy: 0.4533\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8512 - accuracy: 0.7626 - val_loss: 1.6158 - val_accuracy: 0.4500\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8050 - accuracy: 0.7765 - val_loss: 1.6092 - val_accuracy: 0.4567\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8065 - accuracy: 0.7368 - val_loss: 1.6167 - val_accuracy: 0.4467\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8534 - accuracy: 0.7179 - val_loss: 1.6082 - val_accuracy: 0.4500\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8430 - accuracy: 0.7472 - val_loss: 1.6184 - val_accuracy: 0.4600\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8618 - accuracy: 0.7348 - val_loss: 1.6038 - val_accuracy: 0.4533\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8064 - accuracy: 0.7589 - val_loss: 1.6292 - val_accuracy: 0.4600\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8098 - accuracy: 0.7724 - val_loss: 1.6159 - val_accuracy: 0.4533\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 940us/step - loss: 0.8211 - accuracy: 0.7550 - val_loss: 1.6176 - val_accuracy: 0.4600\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.8139 - accuracy: 0.7590 - val_loss: 1.6157 - val_accuracy: 0.4533\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8059 - accuracy: 0.7617 - val_loss: 1.6227 - val_accuracy: 0.4533\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 978us/step - loss: 0.8267 - accuracy: 0.7251 - val_loss: 1.6215 - val_accuracy: 0.4667\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8455 - accuracy: 0.7493 - val_loss: 1.6355 - val_accuracy: 0.4500\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8361 - accuracy: 0.7209 - val_loss: 1.6407 - val_accuracy: 0.4500\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8093 - accuracy: 0.7801 - val_loss: 1.6274 - val_accuracy: 0.4567\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8203 - accuracy: 0.7570 - val_loss: 1.6413 - val_accuracy: 0.4567\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8230 - accuracy: 0.7483 - val_loss: 1.6391 - val_accuracy: 0.4700\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8095 - accuracy: 0.7469 - val_loss: 1.6462 - val_accuracy: 0.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7887 - accuracy: 0.7627 - val_loss: 1.6396 - val_accuracy: 0.4500\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8402 - accuracy: 0.7513 - val_loss: 1.6352 - val_accuracy: 0.4667\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8143 - accuracy: 0.7362 - val_loss: 1.6312 - val_accuracy: 0.4700\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8408 - accuracy: 0.7309 - val_loss: 1.6473 - val_accuracy: 0.4467\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.7727 - val_loss: 1.6454 - val_accuracy: 0.4533\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8287 - accuracy: 0.7539 - val_loss: 1.6529 - val_accuracy: 0.4600\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8270 - accuracy: 0.7394 - val_loss: 1.6398 - val_accuracy: 0.4633\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.8007 - val_loss: 1.6643 - val_accuracy: 0.4467\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8006 - accuracy: 0.7821 - val_loss: 1.6483 - val_accuracy: 0.4633\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8239 - accuracy: 0.7359 - val_loss: 1.6456 - val_accuracy: 0.4600\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8125 - accuracy: 0.7961 - val_loss: 1.6643 - val_accuracy: 0.4467\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8509 - accuracy: 0.7149 - val_loss: 1.6603 - val_accuracy: 0.4467\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.7576 - val_loss: 1.6574 - val_accuracy: 0.4467\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7954 - accuracy: 0.7556 - val_loss: 1.6532 - val_accuracy: 0.4600\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8032 - accuracy: 0.7764 - val_loss: 1.6895 - val_accuracy: 0.4533\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.7506 - val_loss: 1.6661 - val_accuracy: 0.4600\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8544 - accuracy: 0.7430 - val_loss: 1.6730 - val_accuracy: 0.4467\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8043 - accuracy: 0.7617 - val_loss: 1.6721 - val_accuracy: 0.4633\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8072 - accuracy: 0.7666 - val_loss: 1.6682 - val_accuracy: 0.4567\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8393 - accuracy: 0.7451 - val_loss: 1.6768 - val_accuracy: 0.4533\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8289 - accuracy: 0.7374 - val_loss: 1.6833 - val_accuracy: 0.4533\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8004 - accuracy: 0.7557 - val_loss: 1.6755 - val_accuracy: 0.4500\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8434 - accuracy: 0.7644 - val_loss: 1.6685 - val_accuracy: 0.4600\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8060 - accuracy: 0.7428 - val_loss: 1.6808 - val_accuracy: 0.4467\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.7661 - val_loss: 1.6838 - val_accuracy: 0.4600\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8011 - accuracy: 0.7378 - val_loss: 1.6771 - val_accuracy: 0.4500\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7563 - accuracy: 0.8066 - val_loss: 1.6746 - val_accuracy: 0.4533\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.7440 - val_loss: 1.6936 - val_accuracy: 0.4500\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8203 - accuracy: 0.7793 - val_loss: 1.6924 - val_accuracy: 0.4467\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8458 - accuracy: 0.7358 - val_loss: 1.7088 - val_accuracy: 0.4400\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7774 - accuracy: 0.7696 - val_loss: 1.6853 - val_accuracy: 0.4633\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8067 - accuracy: 0.7382 - val_loss: 1.6885 - val_accuracy: 0.4567\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7832 - accuracy: 0.7754 - val_loss: 1.6969 - val_accuracy: 0.4567\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 955us/step - loss: 0.7672 - accuracy: 0.7754 - val_loss: 1.7154 - val_accuracy: 0.4467\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7855 - accuracy: 0.7773 - val_loss: 1.6987 - val_accuracy: 0.4600\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 987us/step - loss: 0.7661 - accuracy: 0.7842 - val_loss: 1.7052 - val_accuracy: 0.4633\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.7644 - val_loss: 1.7089 - val_accuracy: 0.4633\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7811 - accuracy: 0.7769 - val_loss: 1.7020 - val_accuracy: 0.4533\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8112 - accuracy: 0.7216 - val_loss: 1.6973 - val_accuracy: 0.4533\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7627 - accuracy: 0.7986 - val_loss: 1.7033 - val_accuracy: 0.4667\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.7808 - accuracy: 0.7786 - val_loss: 1.7105 - val_accuracy: 0.4633\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8177 - accuracy: 0.7663 - val_loss: 1.7167 - val_accuracy: 0.4533\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7565 - accuracy: 0.7896 - val_loss: 1.7112 - val_accuracy: 0.4533\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7929 - accuracy: 0.7687 - val_loss: 1.7199 - val_accuracy: 0.4533\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7738 - accuracy: 0.7663 - val_loss: 1.7199 - val_accuracy: 0.4533\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8016 - accuracy: 0.7630 - val_loss: 1.7288 - val_accuracy: 0.4533\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8081 - accuracy: 0.7794 - val_loss: 1.7209 - val_accuracy: 0.4667\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8069 - accuracy: 0.7386 - val_loss: 1.7348 - val_accuracy: 0.4533\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8100 - accuracy: 0.7727 - val_loss: 1.7280 - val_accuracy: 0.4567\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7756 - accuracy: 0.7610 - val_loss: 1.7328 - val_accuracy: 0.4500\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7508 - accuracy: 0.7724 - val_loss: 1.7437 - val_accuracy: 0.4500\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.8209 - val_loss: 1.7304 - val_accuracy: 0.4600\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8131 - accuracy: 0.7632 - val_loss: 1.7340 - val_accuracy: 0.4533\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8160 - accuracy: 0.7581 - val_loss: 1.7345 - val_accuracy: 0.4500\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.7917 - val_loss: 1.7330 - val_accuracy: 0.4533\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.8021 - val_loss: 1.7385 - val_accuracy: 0.4533\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8012 - accuracy: 0.7744 - val_loss: 1.7387 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7454 - accuracy: 0.7762 - val_loss: 1.7298 - val_accuracy: 0.4500\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7484 - accuracy: 0.7648 - val_loss: 1.7441 - val_accuracy: 0.4500\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7905 - accuracy: 0.7839 - val_loss: 1.7490 - val_accuracy: 0.4600\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.7842 - val_loss: 1.7472 - val_accuracy: 0.4500\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7643 - accuracy: 0.8029 - val_loss: 1.7686 - val_accuracy: 0.4500\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8048 - accuracy: 0.7685 - val_loss: 1.7460 - val_accuracy: 0.4500\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7537 - accuracy: 0.7913 - val_loss: 1.7735 - val_accuracy: 0.4500\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.7794 - val_loss: 1.7585 - val_accuracy: 0.4633\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7679 - accuracy: 0.7798 - val_loss: 1.7635 - val_accuracy: 0.4567\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.8065 - val_loss: 1.7800 - val_accuracy: 0.4433\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8053 - accuracy: 0.7498 - val_loss: 1.7596 - val_accuracy: 0.4533\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7572 - accuracy: 0.7810 - val_loss: 1.7571 - val_accuracy: 0.4467\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 970us/step - loss: 0.8253 - accuracy: 0.7612 - val_loss: 1.7763 - val_accuracy: 0.4433\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8146 - accuracy: 0.7381 - val_loss: 1.7786 - val_accuracy: 0.4633\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7811 - accuracy: 0.7744 - val_loss: 1.7613 - val_accuracy: 0.4500\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.7886 - val_loss: 1.7731 - val_accuracy: 0.4567\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7510 - accuracy: 0.7919 - val_loss: 1.7951 - val_accuracy: 0.4367\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7179 - accuracy: 0.7991 - val_loss: 1.7738 - val_accuracy: 0.4500\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 938us/step - loss: 0.7820 - accuracy: 0.7728 - val_loss: 1.7803 - val_accuracy: 0.4667\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7679 - accuracy: 0.7798 - val_loss: 1.7915 - val_accuracy: 0.4600\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7454 - accuracy: 0.7905 - val_loss: 1.7796 - val_accuracy: 0.4433\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.7804 - val_loss: 1.7869 - val_accuracy: 0.4467\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7606 - accuracy: 0.7902 - val_loss: 1.7809 - val_accuracy: 0.4533\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7568 - accuracy: 0.7739 - val_loss: 1.8130 - val_accuracy: 0.4367\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7348 - accuracy: 0.7913 - val_loss: 1.7967 - val_accuracy: 0.4533\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7716 - accuracy: 0.7799 - val_loss: 1.8005 - val_accuracy: 0.4633\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7689 - accuracy: 0.7692 - val_loss: 1.7907 - val_accuracy: 0.4533\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7552 - accuracy: 0.7915 - val_loss: 1.8109 - val_accuracy: 0.4533\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7262 - accuracy: 0.7905 - val_loss: 1.7949 - val_accuracy: 0.4533\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7480 - accuracy: 0.7773 - val_loss: 1.8003 - val_accuracy: 0.4700\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7836 - accuracy: 0.7624 - val_loss: 1.8152 - val_accuracy: 0.4533\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7837 - accuracy: 0.7841 - val_loss: 1.8091 - val_accuracy: 0.4567\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7600 - accuracy: 0.7756 - val_loss: 1.8087 - val_accuracy: 0.4500\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7716 - accuracy: 0.7674 - val_loss: 1.8165 - val_accuracy: 0.4600\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6817 - accuracy: 0.8063 - val_loss: 1.8143 - val_accuracy: 0.4433\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7571 - accuracy: 0.8070 - val_loss: 1.8115 - val_accuracy: 0.4433\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.7805 - val_loss: 1.8164 - val_accuracy: 0.4533\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.8088 - val_loss: 1.8065 - val_accuracy: 0.4567\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.7727 - val_loss: 1.8303 - val_accuracy: 0.4367\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7585 - accuracy: 0.7731 - val_loss: 1.8127 - val_accuracy: 0.4533\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7005 - accuracy: 0.7797 - val_loss: 1.8222 - val_accuracy: 0.4567\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7718 - accuracy: 0.7806 - val_loss: 1.8257 - val_accuracy: 0.4567\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 954us/step - loss: 0.7476 - accuracy: 0.7715 - val_loss: 1.8192 - val_accuracy: 0.4600\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7283 - accuracy: 0.7760 - val_loss: 1.8291 - val_accuracy: 0.4533\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7509 - accuracy: 0.7826 - val_loss: 1.8439 - val_accuracy: 0.4333\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7181 - accuracy: 0.7987 - val_loss: 1.8359 - val_accuracy: 0.4600\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 0.7286 - accuracy: 0.7981 - val_loss: 1.8437 - val_accuracy: 0.4433\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.7865 - val_loss: 1.8512 - val_accuracy: 0.4600\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7798 - accuracy: 0.7712 - val_loss: 1.8320 - val_accuracy: 0.4433\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7573 - accuracy: 0.7750 - val_loss: 1.8456 - val_accuracy: 0.4467\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.8101 - val_loss: 1.8291 - val_accuracy: 0.4433\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7668 - accuracy: 0.7867 - val_loss: 1.8508 - val_accuracy: 0.4400\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.7916 - val_loss: 1.8442 - val_accuracy: 0.4433\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.8239 - val_loss: 1.8580 - val_accuracy: 0.4467\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7330 - accuracy: 0.7583 - val_loss: 1.8676 - val_accuracy: 0.4433\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 1000us/step - loss: 0.7472 - accuracy: 0.7908 - val_loss: 1.8876 - val_accuracy: 0.4433\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7864 - accuracy: 0.7713 - val_loss: 1.8629 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.8126 - val_loss: 1.8487 - val_accuracy: 0.4467\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7447 - accuracy: 0.7795 - val_loss: 1.8641 - val_accuracy: 0.4467\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7384 - accuracy: 0.7794 - val_loss: 1.8694 - val_accuracy: 0.4433\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7520 - accuracy: 0.7769 - val_loss: 1.8533 - val_accuracy: 0.4467\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6977 - accuracy: 0.8151 - val_loss: 1.8704 - val_accuracy: 0.4567\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7506 - accuracy: 0.7817 - val_loss: 1.8554 - val_accuracy: 0.4433\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7063 - accuracy: 0.8106 - val_loss: 1.9004 - val_accuracy: 0.4433\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.7942 - val_loss: 1.8886 - val_accuracy: 0.4500\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7102 - accuracy: 0.7981 - val_loss: 1.8776 - val_accuracy: 0.4400\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6754 - accuracy: 0.8002 - val_loss: 1.9001 - val_accuracy: 0.4433\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7007 - accuracy: 0.7989 - val_loss: 1.8788 - val_accuracy: 0.4500\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6764 - accuracy: 0.8156 - val_loss: 1.8882 - val_accuracy: 0.4467\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.7956 - val_loss: 1.8954 - val_accuracy: 0.4400\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7490 - accuracy: 0.7765 - val_loss: 1.8888 - val_accuracy: 0.4467\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7653 - accuracy: 0.7706 - val_loss: 1.8771 - val_accuracy: 0.4467\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8056 - accuracy: 0.7527 - val_loss: 1.8807 - val_accuracy: 0.4567\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.7849 - val_loss: 1.8822 - val_accuracy: 0.4567\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7363 - accuracy: 0.7877 - val_loss: 1.8906 - val_accuracy: 0.4533\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7203 - accuracy: 0.7863 - val_loss: 1.8838 - val_accuracy: 0.4500\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.7812 - val_loss: 1.8893 - val_accuracy: 0.4433\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7223 - accuracy: 0.7933 - val_loss: 1.9040 - val_accuracy: 0.4433\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6905 - accuracy: 0.8143 - val_loss: 1.8983 - val_accuracy: 0.4500\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7527 - accuracy: 0.7766 - val_loss: 1.8990 - val_accuracy: 0.4467\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7068 - accuracy: 0.8012 - val_loss: 1.8993 - val_accuracy: 0.4600\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.7951 - val_loss: 1.9064 - val_accuracy: 0.4367\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 994us/step - loss: 0.7020 - accuracy: 0.8011 - val_loss: 1.9083 - val_accuracy: 0.4533\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.8002 - val_loss: 1.9146 - val_accuracy: 0.4433\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.8231 - val_loss: 1.8898 - val_accuracy: 0.4467\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 994us/step - loss: 0.6868 - accuracy: 0.7901 - val_loss: 1.9098 - val_accuracy: 0.4467\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.7900 - val_loss: 1.9043 - val_accuracy: 0.4500\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 963us/step - loss: 0.6651 - accuracy: 0.7873 - val_loss: 1.9172 - val_accuracy: 0.4467\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.7758 - val_loss: 1.9129 - val_accuracy: 0.4400\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 0.7273 - accuracy: 0.7884 - val_loss: 1.9008 - val_accuracy: 0.4533\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 989us/step - loss: 0.7070 - accuracy: 0.7823 - val_loss: 1.8952 - val_accuracy: 0.4533\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 0.7351 - accuracy: 0.7779 - val_loss: 1.9554 - val_accuracy: 0.4433\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.8307 - val_loss: 1.9344 - val_accuracy: 0.4600\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 944us/step - loss: 0.6884 - accuracy: 0.8164 - val_loss: 1.9110 - val_accuracy: 0.4567\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6967 - accuracy: 0.8122 - val_loss: 1.9293 - val_accuracy: 0.4500\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7228 - accuracy: 0.7889 - val_loss: 1.9261 - val_accuracy: 0.4433\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7176 - accuracy: 0.7948 - val_loss: 1.9129 - val_accuracy: 0.4467\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7062 - accuracy: 0.7759 - val_loss: 1.9321 - val_accuracy: 0.4567\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7287 - accuracy: 0.8114 - val_loss: 1.9292 - val_accuracy: 0.4600\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7086 - accuracy: 0.7855 - val_loss: 1.9200 - val_accuracy: 0.4467\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.8057 - val_loss: 1.9593 - val_accuracy: 0.4433\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 925us/step - loss: 0.7136 - accuracy: 0.7811 - val_loss: 1.9247 - val_accuracy: 0.4533\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.7786 - val_loss: 1.9519 - val_accuracy: 0.4567\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7073 - accuracy: 0.8070 - val_loss: 1.9372 - val_accuracy: 0.4467\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.7839 - val_loss: 1.9742 - val_accuracy: 0.4467\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.7890 - val_loss: 1.9309 - val_accuracy: 0.4500\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.8024 - val_loss: 1.9612 - val_accuracy: 0.4500\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 995us/step - loss: 0.6679 - accuracy: 0.8210 - val_loss: 1.9316 - val_accuracy: 0.4567\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.8094 - val_loss: 1.9805 - val_accuracy: 0.4433\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.7129 - accuracy: 0.7991 - val_loss: 1.9421 - val_accuracy: 0.4500\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6787 - accuracy: 0.8068 - val_loss: 1.9686 - val_accuracy: 0.4567\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7291 - accuracy: 0.7724 - val_loss: 1.9683 - val_accuracy: 0.4533\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7170 - accuracy: 0.7848 - val_loss: 1.9579 - val_accuracy: 0.4467\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 957us/step - loss: 0.7444 - accuracy: 0.7752 - val_loss: 1.9682 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7374 - accuracy: 0.7879 - val_loss: 1.9885 - val_accuracy: 0.4500\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7087 - accuracy: 0.8099 - val_loss: 1.9709 - val_accuracy: 0.4533\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.8180 - val_loss: 1.9898 - val_accuracy: 0.4500\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7067 - accuracy: 0.7879 - val_loss: 1.9761 - val_accuracy: 0.4533\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.8121 - val_loss: 1.9706 - val_accuracy: 0.4500\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.7827 - val_loss: 1.9909 - val_accuracy: 0.4500\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7411 - accuracy: 0.7927 - val_loss: 1.9728 - val_accuracy: 0.4533\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.8169 - val_loss: 1.9603 - val_accuracy: 0.4567\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7282 - accuracy: 0.8112 - val_loss: 1.9691 - val_accuracy: 0.4500\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7427 - accuracy: 0.8031 - val_loss: 1.9969 - val_accuracy: 0.4533\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6902 - accuracy: 0.7906 - val_loss: 1.9822 - val_accuracy: 0.4567\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7620 - accuracy: 0.7821 - val_loss: 1.9727 - val_accuracy: 0.4433\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6672 - accuracy: 0.8127 - val_loss: 1.9918 - val_accuracy: 0.4567\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6838 - accuracy: 0.8091 - val_loss: 2.0140 - val_accuracy: 0.4500\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.7865 - val_loss: 1.9839 - val_accuracy: 0.4500\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.8036 - val_loss: 2.0030 - val_accuracy: 0.4567\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.7867 - val_loss: 2.0179 - val_accuracy: 0.4433\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.8214 - val_loss: 2.0009 - val_accuracy: 0.4500\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.8006 - val_loss: 2.0070 - val_accuracy: 0.4433\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.8161 - val_loss: 1.9974 - val_accuracy: 0.4500\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6730 - accuracy: 0.8201 - val_loss: 2.0009 - val_accuracy: 0.4533\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6754 - accuracy: 0.8186 - val_loss: 2.0130 - val_accuracy: 0.4467\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.8282 - val_loss: 2.0326 - val_accuracy: 0.4500\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6915 - accuracy: 0.7876 - val_loss: 2.0086 - val_accuracy: 0.4467\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.7996 - val_loss: 2.0230 - val_accuracy: 0.4467\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6858 - accuracy: 0.7908 - val_loss: 2.0136 - val_accuracy: 0.4500\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.8006 - val_loss: 2.0111 - val_accuracy: 0.4500\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6675 - accuracy: 0.7946 - val_loss: 2.0231 - val_accuracy: 0.4467\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7156 - accuracy: 0.8037 - val_loss: 2.0326 - val_accuracy: 0.4533\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.7905 - val_loss: 2.0422 - val_accuracy: 0.4500\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7120 - accuracy: 0.8114 - val_loss: 2.0507 - val_accuracy: 0.4467\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7368 - accuracy: 0.7569 - val_loss: 2.0074 - val_accuracy: 0.4500\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6643 - accuracy: 0.8154 - val_loss: 2.0343 - val_accuracy: 0.4500\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.8191 - val_loss: 2.0427 - val_accuracy: 0.4500\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7193 - accuracy: 0.7854 - val_loss: 2.0618 - val_accuracy: 0.4433\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.8172 - val_loss: 2.0475 - val_accuracy: 0.4467\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7473 - accuracy: 0.7617 - val_loss: 2.0492 - val_accuracy: 0.4400\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.8098 - val_loss: 2.0262 - val_accuracy: 0.4433\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6802 - accuracy: 0.8004 - val_loss: 2.0355 - val_accuracy: 0.4467\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.7944 - val_loss: 2.0254 - val_accuracy: 0.4433\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7108 - accuracy: 0.8076 - val_loss: 2.0461 - val_accuracy: 0.4500\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.8031 - val_loss: 2.0472 - val_accuracy: 0.4433\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.8311 - val_loss: 2.0514 - val_accuracy: 0.4433\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 981us/step - loss: 0.6589 - accuracy: 0.8116 - val_loss: 2.0555 - val_accuracy: 0.4567\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.8034 - val_loss: 2.0577 - val_accuracy: 0.4500\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7858 - val_loss: 2.0608 - val_accuracy: 0.4500\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.8017 - val_loss: 2.0553 - val_accuracy: 0.4433\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.8311 - val_loss: 2.0582 - val_accuracy: 0.4500\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.8107 - val_loss: 2.0830 - val_accuracy: 0.4467\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.8144 - val_loss: 2.0846 - val_accuracy: 0.4467\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6901 - accuracy: 0.8048 - val_loss: 2.0732 - val_accuracy: 0.4467\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7011 - accuracy: 0.7900 - val_loss: 2.0469 - val_accuracy: 0.4500\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.8093 - val_loss: 2.0783 - val_accuracy: 0.4567\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6741 - accuracy: 0.7909 - val_loss: 2.0524 - val_accuracy: 0.4467\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6883 - accuracy: 0.8075 - val_loss: 2.0489 - val_accuracy: 0.4467\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7995 - val_loss: 2.0532 - val_accuracy: 0.4433\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 974us/step - loss: 0.7133 - accuracy: 0.7905 - val_loss: 2.0703 - val_accuracy: 0.4467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.6713 - accuracy: 0.7895 - val_loss: 2.0565 - val_accuracy: 0.4433\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 978us/step - loss: 0.7044 - accuracy: 0.7925 - val_loss: 2.0560 - val_accuracy: 0.4467\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.8039 - val_loss: 2.0664 - val_accuracy: 0.4467\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.8043 - val_loss: 2.0689 - val_accuracy: 0.4533\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.7906 - val_loss: 2.0762 - val_accuracy: 0.4467\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.8264 - val_loss: 2.0638 - val_accuracy: 0.4433\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.8113 - val_loss: 2.0707 - val_accuracy: 0.4367\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.8163 - val_loss: 2.0957 - val_accuracy: 0.4500\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.7904 - val_loss: 2.0775 - val_accuracy: 0.4467\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.8000 - val_loss: 2.0884 - val_accuracy: 0.4467\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6774 - accuracy: 0.8031 - val_loss: 2.0747 - val_accuracy: 0.4467\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.7944 - val_loss: 2.0729 - val_accuracy: 0.4467\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.8145 - val_loss: 2.0964 - val_accuracy: 0.4467\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.7870 - val_loss: 2.1084 - val_accuracy: 0.4433\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6789 - accuracy: 0.8089 - val_loss: 2.0848 - val_accuracy: 0.4433\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.8139 - val_loss: 2.0845 - val_accuracy: 0.4367\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.8278 - val_loss: 2.0953 - val_accuracy: 0.4467\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6668 - accuracy: 0.7953 - val_loss: 2.1018 - val_accuracy: 0.4467\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.7943 - val_loss: 2.0948 - val_accuracy: 0.4533\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7048 - accuracy: 0.7866 - val_loss: 2.1043 - val_accuracy: 0.4467\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.7954 - val_loss: 2.0998 - val_accuracy: 0.4367\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7997 - val_loss: 2.0914 - val_accuracy: 0.4433\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.7863 - val_loss: 2.0918 - val_accuracy: 0.4367\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6655 - accuracy: 0.7817 - val_loss: 2.0923 - val_accuracy: 0.4500\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.8181 - val_loss: 2.1098 - val_accuracy: 0.4467\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6680 - accuracy: 0.7853 - val_loss: 2.1186 - val_accuracy: 0.4433\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.8102 - val_loss: 2.1133 - val_accuracy: 0.4467\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.8175 - val_loss: 2.1006 - val_accuracy: 0.4400\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7024 - accuracy: 0.7891 - val_loss: 2.1054 - val_accuracy: 0.4433\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.8263 - val_loss: 2.1168 - val_accuracy: 0.4433\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.8257 - val_loss: 2.1138 - val_accuracy: 0.4367\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 999us/step - loss: 0.6628 - accuracy: 0.8080 - val_loss: 2.1135 - val_accuracy: 0.4467\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.8275 - val_loss: 2.1082 - val_accuracy: 0.4467\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.8111 - val_loss: 2.1240 - val_accuracy: 0.4467\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.7976 - val_loss: 2.1366 - val_accuracy: 0.4467\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6847 - accuracy: 0.8202 - val_loss: 2.1142 - val_accuracy: 0.4400\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6805 - accuracy: 0.7995 - val_loss: 2.1338 - val_accuracy: 0.4467\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.8291 - val_loss: 2.1276 - val_accuracy: 0.4400\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.7906 - val_loss: 2.1259 - val_accuracy: 0.4433\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.8137 - val_loss: 2.1405 - val_accuracy: 0.4400\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6728 - accuracy: 0.8013 - val_loss: 2.1447 - val_accuracy: 0.4533\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.8073 - val_loss: 2.1391 - val_accuracy: 0.4433\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.8304 - val_loss: 2.1290 - val_accuracy: 0.4400\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.8198 - val_loss: 2.1536 - val_accuracy: 0.4500\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6568 - accuracy: 0.8138 - val_loss: 2.1274 - val_accuracy: 0.4333\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.7920 - val_loss: 2.1319 - val_accuracy: 0.4367\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.7932 - val_loss: 2.1372 - val_accuracy: 0.4400\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 0.6398 - accuracy: 0.8043 - val_loss: 2.1411 - val_accuracy: 0.4400\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.8168 - val_loss: 2.1298 - val_accuracy: 0.4333\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.6374 - accuracy: 0.8140 - val_loss: 2.1463 - val_accuracy: 0.4367\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.8266 - val_loss: 2.1340 - val_accuracy: 0.4400\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.8069 - val_loss: 2.1429 - val_accuracy: 0.4333\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.8255 - val_loss: 2.1694 - val_accuracy: 0.4467\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6892 - accuracy: 0.7842 - val_loss: 2.1585 - val_accuracy: 0.4500\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6714 - accuracy: 0.7965 - val_loss: 2.1631 - val_accuracy: 0.4467\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7947 - val_loss: 2.1422 - val_accuracy: 0.4367\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6095 - accuracy: 0.8370 - val_loss: 2.1591 - val_accuracy: 0.4400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.8177 - val_loss: 2.1580 - val_accuracy: 0.4400\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.7990 - val_loss: 2.1556 - val_accuracy: 0.4367\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 0.6651 - accuracy: 0.7840 - val_loss: 2.1692 - val_accuracy: 0.4367\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.8033 - val_loss: 2.1699 - val_accuracy: 0.4400\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.8321 - val_loss: 2.1702 - val_accuracy: 0.4433\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.8035 - val_loss: 2.1930 - val_accuracy: 0.4467\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.8080 - val_loss: 2.1769 - val_accuracy: 0.4400\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.7785 - val_loss: 2.1822 - val_accuracy: 0.4433\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6634 - accuracy: 0.7912 - val_loss: 2.1674 - val_accuracy: 0.4400\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.8148 - val_loss: 2.1881 - val_accuracy: 0.4400\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6362 - accuracy: 0.7959 - val_loss: 2.1825 - val_accuracy: 0.4433\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.7979 - val_loss: 2.1837 - val_accuracy: 0.4400\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.8162 - val_loss: 2.1775 - val_accuracy: 0.4433\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.8303 - val_loss: 2.1782 - val_accuracy: 0.4400\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.8025 - val_loss: 2.1533 - val_accuracy: 0.4400\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.7928 - val_loss: 2.1762 - val_accuracy: 0.4400\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.8040 - val_loss: 2.1955 - val_accuracy: 0.4433\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.7995 - val_loss: 2.2197 - val_accuracy: 0.4467\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.8096 - val_loss: 2.1982 - val_accuracy: 0.4467\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7172 - accuracy: 0.7882 - val_loss: 2.1984 - val_accuracy: 0.4433\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.8048 - val_loss: 2.2118 - val_accuracy: 0.4500\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6041 - accuracy: 0.8246 - val_loss: 2.1984 - val_accuracy: 0.4400\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.8299 - val_loss: 2.1935 - val_accuracy: 0.4333\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.8095 - val_loss: 2.2009 - val_accuracy: 0.4367\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6074 - accuracy: 0.8165 - val_loss: 2.2128 - val_accuracy: 0.4467\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.7941 - val_loss: 2.2133 - val_accuracy: 0.4400\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.8092 - val_loss: 2.2127 - val_accuracy: 0.4367\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6359 - accuracy: 0.8045 - val_loss: 2.2077 - val_accuracy: 0.4400\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.8312 - val_loss: 2.2108 - val_accuracy: 0.4400\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.8190 - val_loss: 2.2000 - val_accuracy: 0.4367\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 987us/step - loss: 0.6291 - accuracy: 0.8107 - val_loss: 2.2218 - val_accuracy: 0.4400\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.7939 - val_loss: 2.2008 - val_accuracy: 0.4367\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 955us/step - loss: 0.6083 - accuracy: 0.8080 - val_loss: 2.2134 - val_accuracy: 0.4433\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 974us/step - loss: 0.6468 - accuracy: 0.8196 - val_loss: 2.2260 - val_accuracy: 0.4367\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 0.6671 - accuracy: 0.7938 - val_loss: 2.2216 - val_accuracy: 0.4500\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.8151 - val_loss: 2.2517 - val_accuracy: 0.4400\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.8299 - val_loss: 2.2264 - val_accuracy: 0.4433\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.8024 - val_loss: 2.2425 - val_accuracy: 0.4333\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6880 - accuracy: 0.7829 - val_loss: 2.2477 - val_accuracy: 0.4433\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.8404 - val_loss: 2.2118 - val_accuracy: 0.4433\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6691 - accuracy: 0.8073 - val_loss: 2.2443 - val_accuracy: 0.4400\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.8107 - val_loss: 2.2625 - val_accuracy: 0.4533\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.8333 - val_loss: 2.2481 - val_accuracy: 0.4400\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 999us/step - loss: 0.5930 - accuracy: 0.8154 - val_loss: 2.2187 - val_accuracy: 0.4333\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5986 - accuracy: 0.8305 - val_loss: 2.2427 - val_accuracy: 0.4433\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 988us/step - loss: 0.6367 - accuracy: 0.8138 - val_loss: 2.2305 - val_accuracy: 0.4400\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.8168 - val_loss: 2.2319 - val_accuracy: 0.4367\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.8343 - val_loss: 2.2460 - val_accuracy: 0.4433\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.8208 - val_loss: 2.2486 - val_accuracy: 0.4400\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.7924 - val_loss: 2.2339 - val_accuracy: 0.4300\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6141 - accuracy: 0.8198 - val_loss: 2.2508 - val_accuracy: 0.4467\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.8061 - val_loss: 2.2600 - val_accuracy: 0.4433\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 927us/step - loss: 0.5804 - accuracy: 0.8260 - val_loss: 2.2281 - val_accuracy: 0.4400\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 969us/step - loss: 0.6294 - accuracy: 0.8289 - val_loss: 2.2696 - val_accuracy: 0.4333\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6179 - accuracy: 0.8314 - val_loss: 2.2647 - val_accuracy: 0.4400\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.8078 - val_loss: 2.2653 - val_accuracy: 0.4333\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6135 - accuracy: 0.8132 - val_loss: 2.2474 - val_accuracy: 0.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.8072 - val_loss: 2.2440 - val_accuracy: 0.4400\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.8096 - val_loss: 2.2718 - val_accuracy: 0.4433\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 0.6483 - accuracy: 0.8026 - val_loss: 2.2657 - val_accuracy: 0.4367\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6788 - accuracy: 0.7830 - val_loss: 2.2829 - val_accuracy: 0.4300\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.8267 - val_loss: 2.2613 - val_accuracy: 0.4367\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.8178 - val_loss: 2.2673 - val_accuracy: 0.4400\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.8071 - val_loss: 2.2637 - val_accuracy: 0.4367\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.8025 - val_loss: 2.2574 - val_accuracy: 0.4333\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.8146 - val_loss: 2.2781 - val_accuracy: 0.4367\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.8331 - val_loss: 2.2606 - val_accuracy: 0.4367\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.8177 - val_loss: 2.2686 - val_accuracy: 0.4400\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.8279 - val_loss: 2.3182 - val_accuracy: 0.4333\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6350 - accuracy: 0.8018 - val_loss: 2.2628 - val_accuracy: 0.4400\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.8394 - val_loss: 2.2692 - val_accuracy: 0.4367\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 974us/step - loss: 0.6109 - accuracy: 0.8182 - val_loss: 2.2889 - val_accuracy: 0.4333\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6862 - accuracy: 0.8024 - val_loss: 2.2744 - val_accuracy: 0.4367\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 941us/step - loss: 0.6072 - accuracy: 0.8235 - val_loss: 2.2816 - val_accuracy: 0.4400\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 981us/step - loss: 0.6042 - accuracy: 0.8205 - val_loss: 2.2810 - val_accuracy: 0.4400\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.8191 - val_loss: 2.2828 - val_accuracy: 0.4367\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 0.6258 - accuracy: 0.8323 - val_loss: 2.2888 - val_accuracy: 0.4367\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.7999 - val_loss: 2.2900 - val_accuracy: 0.4433\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.6015 - accuracy: 0.8220 - val_loss: 2.2910 - val_accuracy: 0.4300\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.8043 - val_loss: 2.2940 - val_accuracy: 0.4367\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.8367 - val_loss: 2.3119 - val_accuracy: 0.4333\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.5845 - accuracy: 0.8384 - val_loss: 2.3035 - val_accuracy: 0.4333\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 976us/step - loss: 0.5746 - accuracy: 0.8141 - val_loss: 2.3101 - val_accuracy: 0.4267\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.8099 - val_loss: 2.2904 - val_accuracy: 0.4333\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.8043 - val_loss: 2.3135 - val_accuracy: 0.4333\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5651 - accuracy: 0.8278 - val_loss: 2.3001 - val_accuracy: 0.4367\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.8133 - val_loss: 2.2857 - val_accuracy: 0.4333\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5569 - accuracy: 0.8229 - val_loss: 2.3004 - val_accuracy: 0.4300\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.8429 - val_loss: 2.3159 - val_accuracy: 0.4233\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.8462 - val_loss: 2.3213 - val_accuracy: 0.4267\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.8026 - val_loss: 2.3096 - val_accuracy: 0.4267\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 0.6741 - accuracy: 0.8008 - val_loss: 2.3143 - val_accuracy: 0.4400\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 975us/step - loss: 0.6407 - accuracy: 0.8181 - val_loss: 2.3125 - val_accuracy: 0.4267\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.8248 - val_loss: 2.2963 - val_accuracy: 0.4233\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.8171 - val_loss: 2.3117 - val_accuracy: 0.4300\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.8192 - val_loss: 2.3259 - val_accuracy: 0.4267\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.8125 - val_loss: 2.3145 - val_accuracy: 0.4333\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5429 - accuracy: 0.8456 - val_loss: 2.3202 - val_accuracy: 0.4400\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6612 - accuracy: 0.8138 - val_loss: 2.3220 - val_accuracy: 0.4267\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6022 - accuracy: 0.8149 - val_loss: 2.3287 - val_accuracy: 0.4267\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.8044 - val_loss: 2.3446 - val_accuracy: 0.4267\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.8120 - val_loss: 2.3390 - val_accuracy: 0.4200\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.8286 - val_loss: 2.3345 - val_accuracy: 0.4167\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6323 - accuracy: 0.8139 - val_loss: 2.3407 - val_accuracy: 0.4233\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.8225 - val_loss: 2.3202 - val_accuracy: 0.4400\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.6078 - accuracy: 0.8229 - val_loss: 2.3371 - val_accuracy: 0.4367\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.8229 - val_loss: 2.3360 - val_accuracy: 0.4300\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.8065 - val_loss: 2.3368 - val_accuracy: 0.4233\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.8059 - val_loss: 2.3324 - val_accuracy: 0.4233\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.8436 - val_loss: 2.3090 - val_accuracy: 0.4267\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 990us/step - loss: 0.5478 - accuracy: 0.8406 - val_loss: 2.3311 - val_accuracy: 0.4267\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6737 - accuracy: 0.7767 - val_loss: 2.3433 - val_accuracy: 0.4300\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 0.6140 - accuracy: 0.8216 - val_loss: 2.3274 - val_accuracy: 0.4233\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 955us/step - loss: 0.5572 - accuracy: 0.8440 - val_loss: 2.3377 - val_accuracy: 0.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 987us/step - loss: 0.5940 - accuracy: 0.8248 - val_loss: 2.3547 - val_accuracy: 0.4167\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.8271 - val_loss: 2.3367 - val_accuracy: 0.4400\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.8297 - val_loss: 2.3362 - val_accuracy: 0.4267\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.8086 - val_loss: 2.3649 - val_accuracy: 0.4200\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.8330 - val_loss: 2.3529 - val_accuracy: 0.4200\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.8302 - val_loss: 2.3409 - val_accuracy: 0.4433\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.8192 - val_loss: 2.3550 - val_accuracy: 0.4333\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.7981 - val_loss: 2.3423 - val_accuracy: 0.4200\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.8444 - val_loss: 2.3666 - val_accuracy: 0.4200\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5938 - accuracy: 0.8244 - val_loss: 2.3569 - val_accuracy: 0.4333\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.8084 - val_loss: 2.3889 - val_accuracy: 0.4267\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 0.5871 - accuracy: 0.8181 - val_loss: 2.3473 - val_accuracy: 0.4233\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 0.6574 - accuracy: 0.8030 - val_loss: 2.3738 - val_accuracy: 0.4300\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.8249 - val_loss: 2.3568 - val_accuracy: 0.4167\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.8194 - val_loss: 2.3551 - val_accuracy: 0.4200\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5912 - accuracy: 0.8470 - val_loss: 2.3634 - val_accuracy: 0.4400\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.8105 - val_loss: 2.3652 - val_accuracy: 0.4333\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5957 - accuracy: 0.8467 - val_loss: 2.3680 - val_accuracy: 0.4467\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5984 - accuracy: 0.8327 - val_loss: 2.3618 - val_accuracy: 0.4233\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.8221 - val_loss: 2.3820 - val_accuracy: 0.4167\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.8143 - val_loss: 2.3582 - val_accuracy: 0.4233\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.8183 - val_loss: 2.3646 - val_accuracy: 0.4400\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.8476 - val_loss: 2.3649 - val_accuracy: 0.4300\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.8184 - val_loss: 2.3572 - val_accuracy: 0.4300\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.8098 - val_loss: 2.3822 - val_accuracy: 0.4267\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.8263 - val_loss: 2.4129 - val_accuracy: 0.4233\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.8155 - val_loss: 2.3941 - val_accuracy: 0.4167\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.8342 - val_loss: 2.3927 - val_accuracy: 0.4367\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.8191 - val_loss: 2.3798 - val_accuracy: 0.4333\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.8347 - val_loss: 2.3985 - val_accuracy: 0.4467\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.8041 - val_loss: 2.3950 - val_accuracy: 0.4300\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.8377 - val_loss: 2.3920 - val_accuracy: 0.4200\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.8421 - val_loss: 2.3818 - val_accuracy: 0.4200\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.8203 - val_loss: 2.4218 - val_accuracy: 0.4133\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5976 - accuracy: 0.8348 - val_loss: 2.3949 - val_accuracy: 0.4133\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.8225 - val_loss: 2.4253 - val_accuracy: 0.4100\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.8275 - val_loss: 2.3994 - val_accuracy: 0.4333\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5484 - accuracy: 0.8550 - val_loss: 2.3922 - val_accuracy: 0.4333\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.8265 - val_loss: 2.4338 - val_accuracy: 0.4267\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.7932 - val_loss: 2.4190 - val_accuracy: 0.4333\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.7996 - val_loss: 2.4067 - val_accuracy: 0.4167\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.8125 - val_loss: 2.3970 - val_accuracy: 0.4267\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.8245 - val_loss: 2.3985 - val_accuracy: 0.4367\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.8072 - val_loss: 2.4169 - val_accuracy: 0.4233\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.8261 - val_loss: 2.4094 - val_accuracy: 0.4333\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.8248 - val_loss: 2.3875 - val_accuracy: 0.4300\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.8306 - val_loss: 2.4178 - val_accuracy: 0.4433\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 988us/step - loss: 0.5390 - accuracy: 0.8402 - val_loss: 2.4143 - val_accuracy: 0.4133\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.8561 - val_loss: 2.4087 - val_accuracy: 0.4433\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5431 - accuracy: 0.8517 - val_loss: 2.4164 - val_accuracy: 0.4300\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.8346 - val_loss: 2.4547 - val_accuracy: 0.4133\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.5733 - accuracy: 0.8277 - val_loss: 2.4485 - val_accuracy: 0.4233\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8516 - val_loss: 2.4391 - val_accuracy: 0.4200\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5351 - accuracy: 0.8368 - val_loss: 2.4263 - val_accuracy: 0.4233\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.8337 - val_loss: 2.4246 - val_accuracy: 0.4267\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.8731 - val_loss: 2.4262 - val_accuracy: 0.4400\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 951us/step - loss: 0.5515 - accuracy: 0.8462 - val_loss: 2.4377 - val_accuracy: 0.4367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.5598 - accuracy: 0.8290 - val_loss: 2.4036 - val_accuracy: 0.4367\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5563 - accuracy: 0.8486 - val_loss: 2.4465 - val_accuracy: 0.4300\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 0.5673 - accuracy: 0.8375 - val_loss: 2.4337 - val_accuracy: 0.4167\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.8239 - val_loss: 2.4294 - val_accuracy: 0.4433\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.8141 - val_loss: 2.4636 - val_accuracy: 0.4167\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.8315 - val_loss: 2.4394 - val_accuracy: 0.4367\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.8338 - val_loss: 2.4459 - val_accuracy: 0.4233\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.8213 - val_loss: 2.4831 - val_accuracy: 0.4100\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5420 - accuracy: 0.8377 - val_loss: 2.4679 - val_accuracy: 0.4167\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.8352 - val_loss: 2.4442 - val_accuracy: 0.4100\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.8153 - val_loss: 2.4527 - val_accuracy: 0.4200\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.8191 - val_loss: 2.4786 - val_accuracy: 0.4300\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.8410 - val_loss: 2.4481 - val_accuracy: 0.4167\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.8314 - val_loss: 2.4504 - val_accuracy: 0.4300\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.8319 - val_loss: 2.4367 - val_accuracy: 0.4333\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5539 - accuracy: 0.8271 - val_loss: 2.4699 - val_accuracy: 0.4233\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.8334 - val_loss: 2.4691 - val_accuracy: 0.4267\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.8327 - val_loss: 2.4785 - val_accuracy: 0.4200\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.8544 - val_loss: 2.4728 - val_accuracy: 0.4367\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5591 - accuracy: 0.8367 - val_loss: 2.4655 - val_accuracy: 0.4300\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.8334 - val_loss: 2.4622 - val_accuracy: 0.4333\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5428 - accuracy: 0.8530 - val_loss: 2.4808 - val_accuracy: 0.4200\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.8385 - val_loss: 2.4566 - val_accuracy: 0.4200\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.8273 - val_loss: 2.4921 - val_accuracy: 0.4200\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 980us/step - loss: 0.6352 - accuracy: 0.8112 - val_loss: 2.4819 - val_accuracy: 0.4367\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.8097 - val_loss: 2.4805 - val_accuracy: 0.4233\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.8407 - val_loss: 2.4639 - val_accuracy: 0.4267\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.8352 - val_loss: 2.4892 - val_accuracy: 0.4433\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5553 - accuracy: 0.8533 - val_loss: 2.4602 - val_accuracy: 0.4267\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.8298 - val_loss: 2.4832 - val_accuracy: 0.4233\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 973us/step - loss: 0.5562 - accuracy: 0.8325 - val_loss: 2.4880 - val_accuracy: 0.4267\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 986us/step - loss: 0.5272 - accuracy: 0.8442 - val_loss: 2.4679 - val_accuracy: 0.4300\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.8270 - val_loss: 2.4902 - val_accuracy: 0.4200\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.8168 - val_loss: 2.4899 - val_accuracy: 0.4233\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.8173 - val_loss: 2.5041 - val_accuracy: 0.4267\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.8173 - val_loss: 2.4913 - val_accuracy: 0.4200\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.5641 - accuracy: 0.8485 - val_loss: 2.4919 - val_accuracy: 0.4167\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.8232 - val_loss: 2.4970 - val_accuracy: 0.4200\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.8192 - val_loss: 2.4959 - val_accuracy: 0.4233\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.8179 - val_loss: 2.4862 - val_accuracy: 0.4267\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.8197 - val_loss: 2.5059 - val_accuracy: 0.4233\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5397 - accuracy: 0.8284 - val_loss: 2.4801 - val_accuracy: 0.4333\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.5819 - accuracy: 0.8258 - val_loss: 2.5120 - val_accuracy: 0.4233\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.8275 - val_loss: 2.5309 - val_accuracy: 0.4233\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.8369 - val_loss: 2.5069 - val_accuracy: 0.4200\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.8356 - val_loss: 2.5096 - val_accuracy: 0.4200\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5225 - accuracy: 0.8416 - val_loss: 2.4870 - val_accuracy: 0.4233\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5572 - accuracy: 0.8524 - val_loss: 2.5183 - val_accuracy: 0.4233\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.8217 - val_loss: 2.5159 - val_accuracy: 0.4267\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5576 - accuracy: 0.8393 - val_loss: 2.5231 - val_accuracy: 0.4233\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5512 - accuracy: 0.8475 - val_loss: 2.5145 - val_accuracy: 0.4233\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.8426 - val_loss: 2.5411 - val_accuracy: 0.4167\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.8275 - val_loss: 2.5108 - val_accuracy: 0.4267\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.8237 - val_loss: 2.5165 - val_accuracy: 0.4167\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5526 - accuracy: 0.8320 - val_loss: 2.5218 - val_accuracy: 0.4200\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.8539 - val_loss: 2.5220 - val_accuracy: 0.4233\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.8172 - val_loss: 2.5338 - val_accuracy: 0.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.8117 - val_loss: 2.5325 - val_accuracy: 0.4200\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.8344 - val_loss: 2.5125 - val_accuracy: 0.4267\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.8629 - val_loss: 2.5166 - val_accuracy: 0.4367\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5746 - accuracy: 0.8388 - val_loss: 2.5211 - val_accuracy: 0.4233\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.8322 - val_loss: 2.5653 - val_accuracy: 0.4133\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.8208 - val_loss: 2.5250 - val_accuracy: 0.4233\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5567 - accuracy: 0.8446 - val_loss: 2.5497 - val_accuracy: 0.4233\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.8645 - val_loss: 2.5751 - val_accuracy: 0.4133\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.8462 - val_loss: 2.5139 - val_accuracy: 0.4233\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.8257 - val_loss: 2.5423 - val_accuracy: 0.4167\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6027 - accuracy: 0.8160 - val_loss: 2.5418 - val_accuracy: 0.4233\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5489 - accuracy: 0.8467 - val_loss: 2.5449 - val_accuracy: 0.4200\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6075 - accuracy: 0.8015 - val_loss: 2.5277 - val_accuracy: 0.4267\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.8092 - val_loss: 2.5433 - val_accuracy: 0.4233\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.8190 - val_loss: 2.5394 - val_accuracy: 0.4200\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5668 - accuracy: 0.8349 - val_loss: 2.5282 - val_accuracy: 0.4267\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5517 - accuracy: 0.8420 - val_loss: 2.5599 - val_accuracy: 0.4200\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.8291 - val_loss: 2.5528 - val_accuracy: 0.4167\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5897 - accuracy: 0.8349 - val_loss: 2.5540 - val_accuracy: 0.4200\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5318 - accuracy: 0.8432 - val_loss: 2.5544 - val_accuracy: 0.4267\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5409 - accuracy: 0.8392 - val_loss: 2.5412 - val_accuracy: 0.4233\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5497 - accuracy: 0.8428 - val_loss: 2.5597 - val_accuracy: 0.4233\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.8486 - val_loss: 2.5633 - val_accuracy: 0.4200\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.8287 - val_loss: 2.5531 - val_accuracy: 0.4233\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 985us/step - loss: 0.5706 - accuracy: 0.8310 - val_loss: 2.5785 - val_accuracy: 0.4267\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.8225 - val_loss: 2.5680 - val_accuracy: 0.4233\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5619 - accuracy: 0.8369 - val_loss: 2.5629 - val_accuracy: 0.4200\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5911 - accuracy: 0.8466 - val_loss: 2.5514 - val_accuracy: 0.4200\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8433 - val_loss: 2.5647 - val_accuracy: 0.4233\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 978us/step - loss: 0.5497 - accuracy: 0.8552 - val_loss: 2.5738 - val_accuracy: 0.4233\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 968us/step - loss: 0.5424 - accuracy: 0.8345 - val_loss: 2.5701 - val_accuracy: 0.4233\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.8420 - val_loss: 2.5578 - val_accuracy: 0.4167\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.8405 - val_loss: 2.5760 - val_accuracy: 0.4233\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.8123 - val_loss: 2.5702 - val_accuracy: 0.4267\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.8326 - val_loss: 2.5841 - val_accuracy: 0.4200\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.8437 - val_loss: 2.5863 - val_accuracy: 0.4200\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.8429 - val_loss: 2.6087 - val_accuracy: 0.4233\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.8269 - val_loss: 2.5697 - val_accuracy: 0.4233\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5374 - accuracy: 0.8411 - val_loss: 2.5818 - val_accuracy: 0.4233\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.5451 - accuracy: 0.8387 - val_loss: 2.5444 - val_accuracy: 0.4233\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.8387 - val_loss: 2.5908 - val_accuracy: 0.4233\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 971us/step - loss: 0.5670 - accuracy: 0.8230 - val_loss: 2.5718 - val_accuracy: 0.4267\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.8512 - val_loss: 2.5785 - val_accuracy: 0.4233\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.8307 - val_loss: 2.5951 - val_accuracy: 0.4233\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5237 - accuracy: 0.8509 - val_loss: 2.5935 - val_accuracy: 0.4267\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5543 - accuracy: 0.8248 - val_loss: 2.5918 - val_accuracy: 0.4200\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.8492 - val_loss: 2.5794 - val_accuracy: 0.4233\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.8466 - val_loss: 2.5873 - val_accuracy: 0.4233\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5096 - accuracy: 0.8577 - val_loss: 2.6356 - val_accuracy: 0.4200\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8293 - val_loss: 2.6051 - val_accuracy: 0.4167\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8530 - val_loss: 2.5823 - val_accuracy: 0.4267\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5584 - accuracy: 0.8409 - val_loss: 2.6274 - val_accuracy: 0.4233\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5679 - accuracy: 0.8315 - val_loss: 2.6340 - val_accuracy: 0.4233\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5455 - accuracy: 0.8214 - val_loss: 2.6265 - val_accuracy: 0.4233\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.8506 - val_loss: 2.6068 - val_accuracy: 0.4233\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 989us/step - loss: 0.5484 - accuracy: 0.8217 - val_loss: 2.5943 - val_accuracy: 0.4200\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.8414 - val_loss: 2.6107 - val_accuracy: 0.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.8247 - val_loss: 2.5919 - val_accuracy: 0.4233\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8413 - val_loss: 2.6020 - val_accuracy: 0.4200\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.8520 - val_loss: 2.6312 - val_accuracy: 0.4233\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5587 - accuracy: 0.8425 - val_loss: 2.6110 - val_accuracy: 0.4233\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5605 - accuracy: 0.8149 - val_loss: 2.6064 - val_accuracy: 0.4233\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5385 - accuracy: 0.8342 - val_loss: 2.6349 - val_accuracy: 0.4233\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5230 - accuracy: 0.8414 - val_loss: 2.5971 - val_accuracy: 0.4300\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 0.6053 - accuracy: 0.8276 - val_loss: 2.6270 - val_accuracy: 0.4233\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.8211 - val_loss: 2.6549 - val_accuracy: 0.4233\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8524 - val_loss: 2.6382 - val_accuracy: 0.4233\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.8266 - val_loss: 2.6345 - val_accuracy: 0.4200\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5235 - accuracy: 0.8485 - val_loss: 2.6478 - val_accuracy: 0.4200\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.8248 - val_loss: 2.6223 - val_accuracy: 0.4233\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.8489 - val_loss: 2.6297 - val_accuracy: 0.4167\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5100 - accuracy: 0.8499 - val_loss: 2.6347 - val_accuracy: 0.4233\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5566 - accuracy: 0.8222 - val_loss: 2.6352 - val_accuracy: 0.4367\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 0.8410 - val_loss: 2.6888 - val_accuracy: 0.4133\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.8522 - val_loss: 2.6298 - val_accuracy: 0.4233\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5674 - accuracy: 0.8362 - val_loss: 2.6330 - val_accuracy: 0.4267\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5341 - accuracy: 0.8433 - val_loss: 2.6643 - val_accuracy: 0.4167\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 991us/step - loss: 0.5732 - accuracy: 0.8216 - val_loss: 2.6328 - val_accuracy: 0.4200\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.8088 - val_loss: 2.6704 - val_accuracy: 0.4167\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 998us/step - loss: 0.5539 - accuracy: 0.8373 - val_loss: 2.6399 - val_accuracy: 0.4200\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.8469 - val_loss: 2.6486 - val_accuracy: 0.4167\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5330 - accuracy: 0.8458 - val_loss: 2.6065 - val_accuracy: 0.4267\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.8284 - val_loss: 2.6449 - val_accuracy: 0.4200\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 933us/step - loss: 0.5751 - accuracy: 0.8285 - val_loss: 2.6524 - val_accuracy: 0.4233\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5166 - accuracy: 0.8539 - val_loss: 2.6651 - val_accuracy: 0.4200\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4868 - accuracy: 0.8525 - val_loss: 2.6623 - val_accuracy: 0.4233\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5405 - accuracy: 0.8357 - val_loss: 2.6378 - val_accuracy: 0.4200\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.8400 - val_loss: 2.6705 - val_accuracy: 0.4233\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.8386 - val_loss: 2.6847 - val_accuracy: 0.4233\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5396 - accuracy: 0.8321 - val_loss: 2.6531 - val_accuracy: 0.4233\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8501 - val_loss: 2.6598 - val_accuracy: 0.4133\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8482 - val_loss: 2.6607 - val_accuracy: 0.4233\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5709 - accuracy: 0.8175 - val_loss: 2.6675 - val_accuracy: 0.4167\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.8269 - val_loss: 2.6430 - val_accuracy: 0.4167\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6275 - accuracy: 0.8139 - val_loss: 2.6622 - val_accuracy: 0.4167\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 0.8565 - val_loss: 2.6749 - val_accuracy: 0.4200\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5238 - accuracy: 0.8606 - val_loss: 2.6710 - val_accuracy: 0.4133\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.8418 - val_loss: 2.6902 - val_accuracy: 0.4133\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.8386 - val_loss: 2.6560 - val_accuracy: 0.4233\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.8663 - val_loss: 2.6463 - val_accuracy: 0.4267\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.8246 - val_loss: 2.6789 - val_accuracy: 0.4200\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.8248 - val_loss: 2.6789 - val_accuracy: 0.4167\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.8655 - val_loss: 2.6626 - val_accuracy: 0.4200\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5084 - accuracy: 0.8470 - val_loss: 2.6808 - val_accuracy: 0.4267\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.8460 - val_loss: 2.6519 - val_accuracy: 0.4167\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.8808 - val_loss: 2.6662 - val_accuracy: 0.4167\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5516 - accuracy: 0.8421 - val_loss: 2.6648 - val_accuracy: 0.4200\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5274 - accuracy: 0.8303 - val_loss: 2.6901 - val_accuracy: 0.4233\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.8488 - val_loss: 2.6796 - val_accuracy: 0.4233\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.8319 - val_loss: 2.6977 - val_accuracy: 0.4167\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.8465 - val_loss: 2.6903 - val_accuracy: 0.4200\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8522 - val_loss: 2.7059 - val_accuracy: 0.4133\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.8335 - val_loss: 2.6862 - val_accuracy: 0.4167\n",
      "Epoch 912/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4857 - accuracy: 0.8618 - val_loss: 2.7186 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.8582 - val_loss: 2.7004 - val_accuracy: 0.4133\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.8498 - val_loss: 2.7273 - val_accuracy: 0.4167\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.8430 - val_loss: 2.6809 - val_accuracy: 0.4133\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.8386 - val_loss: 2.6868 - val_accuracy: 0.4200\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.8601 - val_loss: 2.7236 - val_accuracy: 0.4200\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.8506 - val_loss: 2.6830 - val_accuracy: 0.4200\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.8325 - val_loss: 2.7032 - val_accuracy: 0.4200\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8400 - val_loss: 2.6952 - val_accuracy: 0.4200\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.8613 - val_loss: 2.7282 - val_accuracy: 0.4133\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8546 - val_loss: 2.7316 - val_accuracy: 0.4233\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.8420 - val_loss: 2.7010 - val_accuracy: 0.4233\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5538 - accuracy: 0.8388 - val_loss: 2.7180 - val_accuracy: 0.4233\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5425 - accuracy: 0.8365 - val_loss: 2.7081 - val_accuracy: 0.4233\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.8308 - val_loss: 2.7125 - val_accuracy: 0.4233\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 0.8299 - val_loss: 2.7292 - val_accuracy: 0.4267\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5240 - accuracy: 0.8383 - val_loss: 2.7046 - val_accuracy: 0.4167\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.8286 - val_loss: 2.7252 - val_accuracy: 0.4200\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5109 - accuracy: 0.8527 - val_loss: 2.7032 - val_accuracy: 0.4167\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.8299 - val_loss: 2.6999 - val_accuracy: 0.4200\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.8343 - val_loss: 2.7388 - val_accuracy: 0.4200\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.8472 - val_loss: 2.7040 - val_accuracy: 0.4200\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.8568 - val_loss: 2.7296 - val_accuracy: 0.4200\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5974 - accuracy: 0.8238 - val_loss: 2.7105 - val_accuracy: 0.4167\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5363 - accuracy: 0.8193 - val_loss: 2.7403 - val_accuracy: 0.4067\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 972us/step - loss: 0.5223 - accuracy: 0.8517 - val_loss: 2.7229 - val_accuracy: 0.4167\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.8341 - val_loss: 2.7339 - val_accuracy: 0.4200\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 0.5080 - accuracy: 0.8505 - val_loss: 2.7373 - val_accuracy: 0.4233\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5339 - accuracy: 0.8496 - val_loss: 2.7438 - val_accuracy: 0.4167\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.8422 - val_loss: 2.7083 - val_accuracy: 0.4200\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.8244 - val_loss: 2.7360 - val_accuracy: 0.4200\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5340 - accuracy: 0.8430 - val_loss: 2.7402 - val_accuracy: 0.4067\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.8493 - val_loss: 2.7339 - val_accuracy: 0.4200\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5201 - accuracy: 0.8385 - val_loss: 2.7338 - val_accuracy: 0.4133\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5389 - accuracy: 0.8298 - val_loss: 2.7753 - val_accuracy: 0.4067\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5382 - accuracy: 0.8383 - val_loss: 2.7701 - val_accuracy: 0.4300\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5511 - accuracy: 0.8347 - val_loss: 2.7725 - val_accuracy: 0.4200\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5413 - accuracy: 0.8523 - val_loss: 2.7524 - val_accuracy: 0.4200\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5015 - accuracy: 0.8624 - val_loss: 2.7530 - val_accuracy: 0.4233\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 958us/step - loss: 0.5078 - accuracy: 0.8592 - val_loss: 2.7515 - val_accuracy: 0.4167\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.8166 - val_loss: 2.7583 - val_accuracy: 0.4200\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 977us/step - loss: 0.4923 - accuracy: 0.8534 - val_loss: 2.7725 - val_accuracy: 0.4200\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 970us/step - loss: 0.4947 - accuracy: 0.8597 - val_loss: 2.7602 - val_accuracy: 0.4200\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.8240 - val_loss: 2.7585 - val_accuracy: 0.4167\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.8401 - val_loss: 2.7480 - val_accuracy: 0.4233\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5577 - accuracy: 0.8360 - val_loss: 2.7734 - val_accuracy: 0.4167\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 0.5182 - accuracy: 0.8363 - val_loss: 2.7577 - val_accuracy: 0.4167\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5010 - accuracy: 0.8529 - val_loss: 2.7537 - val_accuracy: 0.4200\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.8541 - val_loss: 2.7824 - val_accuracy: 0.4167\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 983us/step - loss: 0.4680 - accuracy: 0.8787 - val_loss: 2.7617 - val_accuracy: 0.4200\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4709 - accuracy: 0.8690 - val_loss: 2.7992 - val_accuracy: 0.4200\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.8138 - val_loss: 2.7647 - val_accuracy: 0.4167\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 966us/step - loss: 0.5184 - accuracy: 0.8498 - val_loss: 2.7780 - val_accuracy: 0.4100\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5094 - accuracy: 0.8517 - val_loss: 2.7609 - val_accuracy: 0.4200\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.8209 - val_loss: 2.7780 - val_accuracy: 0.4133\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.8243 - val_loss: 2.7683 - val_accuracy: 0.4133\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5620 - accuracy: 0.8586 - val_loss: 2.7720 - val_accuracy: 0.4200\n",
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5595 - accuracy: 0.8368 - val_loss: 2.7550 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.8161 - val_loss: 2.7726 - val_accuracy: 0.4200\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5138 - accuracy: 0.8410 - val_loss: 2.7924 - val_accuracy: 0.4167\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5322 - accuracy: 0.8488 - val_loss: 2.7854 - val_accuracy: 0.4100\n",
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.8281 - val_loss: 2.7780 - val_accuracy: 0.4167\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.8327 - val_loss: 2.7823 - val_accuracy: 0.4233\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.8564 - val_loss: 2.8012 - val_accuracy: 0.4133\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5445 - accuracy: 0.8299 - val_loss: 2.8108 - val_accuracy: 0.4100\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4955 - accuracy: 0.8400 - val_loss: 2.8120 - val_accuracy: 0.4133\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4935 - accuracy: 0.8658 - val_loss: 2.7757 - val_accuracy: 0.4100\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5459 - accuracy: 0.8469 - val_loss: 2.7963 - val_accuracy: 0.4133\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.8178 - val_loss: 2.7872 - val_accuracy: 0.4167\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8456 - val_loss: 2.7973 - val_accuracy: 0.4100\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4963 - accuracy: 0.8508 - val_loss: 2.8124 - val_accuracy: 0.4200\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8532 - val_loss: 2.7834 - val_accuracy: 0.4100\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5444 - accuracy: 0.8429 - val_loss: 2.7900 - val_accuracy: 0.4133\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5135 - accuracy: 0.8248 - val_loss: 2.7858 - val_accuracy: 0.4133\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4890 - accuracy: 0.8559 - val_loss: 2.8148 - val_accuracy: 0.4133\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5491 - accuracy: 0.8428 - val_loss: 2.8083 - val_accuracy: 0.4133\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.8502 - val_loss: 2.8141 - val_accuracy: 0.4167\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4911 - accuracy: 0.8527 - val_loss: 2.8155 - val_accuracy: 0.4133\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5232 - accuracy: 0.8319 - val_loss: 2.8079 - val_accuracy: 0.4133\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.8567 - val_loss: 2.7970 - val_accuracy: 0.4133\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.8560 - val_loss: 2.8176 - val_accuracy: 0.4133\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.8299 - val_loss: 2.8016 - val_accuracy: 0.4167\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5142 - accuracy: 0.8578 - val_loss: 2.8199 - val_accuracy: 0.4100\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 0.8610 - val_loss: 2.7948 - val_accuracy: 0.4033\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.4906 - accuracy: 0.8528 - val_loss: 2.8115 - val_accuracy: 0.4200\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.8295 - val_loss: 2.8156 - val_accuracy: 0.4100\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.8415 - val_loss: 2.8162 - val_accuracy: 0.4133\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.8476 - val_loss: 2.8007 - val_accuracy: 0.4167\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.8331 - val_loss: 2.8183 - val_accuracy: 0.4133\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "# 2단레이어 구조로 deeplearning\n",
    "model.add(Dense(units=2,input_dim=784,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "# 4. 학습\n",
    "hist = model.fit(X_train,Y_train,epochs=1000,batch_size=10,validation_data=(X_val,Y_val))\n",
    "# validation_data로 과적합 발생률을 줄여준다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:38:31.028698Z",
     "start_time": "2021-03-23T08:38:30.653002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델학습과정을 표시하고 평가하기\n",
    "# val_acc가 중요함\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')\n",
    "loss_ax.set_xlabel('epochs')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유 하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r',label='val acc')\n",
    "acc_ax.set_ylabel('acc')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:43:48.918388Z",
     "start_time": "2021-03-23T08:43:48.437216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 961us/step - loss: 2.6408 - accuracy: 0.4840\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test,Y_test,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:44:59.155209Z",
     "start_time": "2021-03-23T08:44:59.148208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  2.6407930850982666\n",
      "accuracy :  0.48399999737739563\n"
     ]
    }
   ],
   "source": [
    "print('loss: ',loss_and_metrics[0])\n",
    "print('accuracy : ',loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:53:41.385951Z",
     "start_time": "2021-03-23T08:53:41.180613Z"
    }
   },
   "outputs": [],
   "source": [
    "# 6. 모델저장 및 로드\n",
    "# 저장\n",
    "model.save('model/mnist.h5')\n",
    "           \n",
    "# 로드\n",
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('model/mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:55:13.158501Z",
     "start_time": "2021-03-23T08:55:13.035627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27aa7432670>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:57:21.107235Z",
     "start_time": "2021-03-23T08:57:21.060685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model2.predict(X_train[3].reshape(1,784)).argmax()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:58:45.230092Z",
     "start_time": "2021-03-23T08:58:45.221094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[3].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T09:04:36.681528Z",
     "start_time": "2021-03-23T09:04:36.619588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(X_val[0].reshape(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 콜백함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:19:16.356007Z",
     "start_time": "2021-03-24T01:18:08.915580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, loss : 2.2870070934295654, val_loss : 2.2355408668518066, acc : 0.14142857491970062, val_acc : 0.15333333611488342\n",
      "epoch : 10, loss : 1.708188772201538, val_loss : 1.7047215700149536, acc : 0.4000000059604645, val_acc : 0.4166666567325592\n",
      "epoch : 20, loss : 1.4816445112228394, val_loss : 1.5323421955108643, acc : 0.48571428656578064, val_acc : 0.4566666781902313\n",
      "epoch : 30, loss : 1.352245569229126, val_loss : 1.4311578273773193, acc : 0.550000011920929, val_acc : 0.47333332896232605\n",
      "epoch : 40, loss : 1.2567483186721802, val_loss : 1.3767914772033691, acc : 0.5871428847312927, val_acc : 0.49666666984558105\n",
      "epoch : 50, loss : 1.187603235244751, val_loss : 1.3332966566085815, acc : 0.6028571724891663, val_acc : 0.5199999809265137\n",
      "epoch : 60, loss : 1.1314783096313477, val_loss : 1.3037102222442627, acc : 0.6257143020629883, val_acc : 0.5133333206176758\n",
      "epoch : 70, loss : 1.086045265197754, val_loss : 1.2878608703613281, acc : 0.6257143020629883, val_acc : 0.5233333110809326\n",
      "epoch : 80, loss : 1.0495935678482056, val_loss : 1.2711933851242065, acc : 0.6399999856948853, val_acc : 0.5299999713897705\n",
      "epoch : 90, loss : 1.0164986848831177, val_loss : 1.260292887687683, acc : 0.6442857384681702, val_acc : 0.5333333611488342\n",
      "epoch : 100, loss : 0.9906612038612366, val_loss : 1.2609673738479614, acc : 0.6485714316368103, val_acc : 0.5366666913032532\n",
      "epoch : 110, loss : 0.9664444327354431, val_loss : 1.2586605548858643, acc : 0.6485714316368103, val_acc : 0.5299999713897705\n",
      "epoch : 120, loss : 0.944840669631958, val_loss : 1.2600204944610596, acc : 0.6557142734527588, val_acc : 0.5400000214576721\n",
      "epoch : 130, loss : 0.9245347380638123, val_loss : 1.2671453952789307, acc : 0.6700000166893005, val_acc : 0.5333333611488342\n",
      "epoch : 140, loss : 0.9067981839179993, val_loss : 1.269817590713501, acc : 0.668571412563324, val_acc : 0.5400000214576721\n",
      "epoch : 150, loss : 0.889197051525116, val_loss : 1.275808572769165, acc : 0.6857143044471741, val_acc : 0.54666668176651\n",
      "epoch : 160, loss : 0.8748744130134583, val_loss : 1.2916828393936157, acc : 0.6828571557998657, val_acc : 0.5299999713897705\n",
      "epoch : 170, loss : 0.862800657749176, val_loss : 1.2924798727035522, acc : 0.6942856907844543, val_acc : 0.5366666913032532\n",
      "epoch : 180, loss : 0.8506514430046082, val_loss : 1.2989301681518555, acc : 0.6899999976158142, val_acc : 0.5400000214576721\n",
      "epoch : 190, loss : 0.8383078575134277, val_loss : 1.3091953992843628, acc : 0.7014285922050476, val_acc : 0.5366666913032532\n",
      "epoch : 200, loss : 0.8253086805343628, val_loss : 1.3235372304916382, acc : 0.7028571367263794, val_acc : 0.5299999713897705\n",
      "epoch : 210, loss : 0.8165680766105652, val_loss : 1.3246914148330688, acc : 0.7057142853736877, val_acc : 0.5400000214576721\n",
      "epoch : 220, loss : 0.8054599165916443, val_loss : 1.3326393365859985, acc : 0.7114285826683044, val_acc : 0.5166666507720947\n",
      "epoch : 230, loss : 0.797490119934082, val_loss : 1.3466020822525024, acc : 0.7157142758369446, val_acc : 0.5266666412353516\n",
      "epoch : 240, loss : 0.7895854711532593, val_loss : 1.3587305545806885, acc : 0.7185714244842529, val_acc : 0.5299999713897705\n",
      "epoch : 250, loss : 0.7812173962593079, val_loss : 1.3572710752487183, acc : 0.7185714244842529, val_acc : 0.5299999713897705\n",
      "epoch : 260, loss : 0.7725820541381836, val_loss : 1.3778659105300903, acc : 0.7285714149475098, val_acc : 0.5266666412353516\n",
      "epoch : 270, loss : 0.7657114863395691, val_loss : 1.397896409034729, acc : 0.7228571176528931, val_acc : 0.5266666412353516\n",
      "epoch : 280, loss : 0.758152961730957, val_loss : 1.4102553129196167, acc : 0.7314285635948181, val_acc : 0.5266666412353516\n",
      "epoch : 290, loss : 0.7512871623039246, val_loss : 1.4059638977050781, acc : 0.7342857122421265, val_acc : 0.5266666412353516\n",
      "epoch : 300, loss : 0.7462248206138611, val_loss : 1.423064112663269, acc : 0.7314285635948181, val_acc : 0.5199999809265137\n",
      "epoch : 310, loss : 0.7398389577865601, val_loss : 1.4304397106170654, acc : 0.7328571677207947, val_acc : 0.5199999809265137\n",
      "epoch : 320, loss : 0.7319672703742981, val_loss : 1.4427860975265503, acc : 0.7400000095367432, val_acc : 0.5166666507720947\n",
      "epoch : 330, loss : 0.7281903624534607, val_loss : 1.4649467468261719, acc : 0.7342857122421265, val_acc : 0.5199999809265137\n",
      "epoch : 340, loss : 0.7225582599639893, val_loss : 1.4511158466339111, acc : 0.7385714054107666, val_acc : 0.5099999904632568\n",
      "epoch : 350, loss : 0.7172906994819641, val_loss : 1.4728339910507202, acc : 0.741428554058075, val_acc : 0.5166666507720947\n",
      "epoch : 360, loss : 0.7110063433647156, val_loss : 1.490524172782898, acc : 0.7385714054107666, val_acc : 0.5133333206176758\n",
      "epoch : 370, loss : 0.7060534358024597, val_loss : 1.4887672662734985, acc : 0.7428571581840515, val_acc : 0.5066666603088379\n",
      "epoch : 380, loss : 0.7013471126556396, val_loss : 1.5084296464920044, acc : 0.7442857027053833, val_acc : 0.5066666603088379\n",
      "epoch : 390, loss : 0.6966803073883057, val_loss : 1.5238037109375, acc : 0.7485714554786682, val_acc : 0.5066666603088379\n",
      "epoch : 400, loss : 0.6927903294563293, val_loss : 1.5387617349624634, acc : 0.7514285445213318, val_acc : 0.503333330154419\n",
      "epoch : 410, loss : 0.6875752210617065, val_loss : 1.5393892526626587, acc : 0.7514285445213318, val_acc : 0.5133333206176758\n",
      "epoch : 420, loss : 0.6838261485099792, val_loss : 1.545266032218933, acc : 0.7571428418159485, val_acc : 0.5099999904632568\n",
      "epoch : 430, loss : 0.6785644292831421, val_loss : 1.5692079067230225, acc : 0.758571445941925, val_acc : 0.5133333206176758\n",
      "epoch : 440, loss : 0.6742339730262756, val_loss : 1.5699280500411987, acc : 0.7685714364051819, val_acc : 0.5066666603088379\n",
      "epoch : 450, loss : 0.6721709370613098, val_loss : 1.5707899332046509, acc : 0.758571445941925, val_acc : 0.5\n",
      "epoch : 460, loss : 0.6676751971244812, val_loss : 1.5918110609054565, acc : 0.7628571391105652, val_acc : 0.5066666603088379\n",
      "epoch : 470, loss : 0.6612160205841064, val_loss : 1.5933176279067993, acc : 0.7657142877578735, val_acc : 0.503333330154419\n",
      "epoch : 480, loss : 0.659664511680603, val_loss : 1.6237118244171143, acc : 0.7671428322792053, val_acc : 0.503333330154419\n",
      "epoch : 490, loss : 0.6558210253715515, val_loss : 1.6334935426712036, acc : 0.7699999809265137, val_acc : 0.503333330154419\n",
      "epoch : 500, loss : 0.6522179245948792, val_loss : 1.6298633813858032, acc : 0.7742857336997986, val_acc : 0.49666666984558105\n",
      "epoch : 510, loss : 0.6493096947669983, val_loss : 1.6573423147201538, acc : 0.7785714268684387, val_acc : 0.503333330154419\n",
      "epoch : 520, loss : 0.6461926102638245, val_loss : 1.6457023620605469, acc : 0.7714285850524902, val_acc : 0.4933333396911621\n",
      "epoch : 530, loss : 0.6425924897193909, val_loss : 1.662164568901062, acc : 0.7785714268684387, val_acc : 0.49666666984558105\n",
      "epoch : 540, loss : 0.637935221195221, val_loss : 1.6930441856384277, acc : 0.7757142782211304, val_acc : 0.5\n",
      "epoch : 550, loss : 0.6345383524894714, val_loss : 1.707427740097046, acc : 0.7814285755157471, val_acc : 0.49666666984558105\n",
      "epoch : 560, loss : 0.633971095085144, val_loss : 1.6928685903549194, acc : 0.7771428823471069, val_acc : 0.49666666984558105\n",
      "epoch : 570, loss : 0.6274564862251282, val_loss : 1.6991393566131592, acc : 0.7828571200370789, val_acc : 0.4933333396911621\n",
      "epoch : 580, loss : 0.6251941919326782, val_loss : 1.7183274030685425, acc : 0.7785714268684387, val_acc : 0.503333330154419\n",
      "epoch : 590, loss : 0.6204970479011536, val_loss : 1.7194565534591675, acc : 0.7828571200370789, val_acc : 0.4933333396911621\n",
      "epoch : 600, loss : 0.6176884174346924, val_loss : 1.744119644165039, acc : 0.7828571200370789, val_acc : 0.49666666984558105\n",
      "epoch : 610, loss : 0.6150416135787964, val_loss : 1.7539058923721313, acc : 0.7942857146263123, val_acc : 0.5\n",
      "epoch : 620, loss : 0.6121478080749512, val_loss : 1.7520971298217773, acc : 0.7914285659790039, val_acc : 0.4933333396911621\n",
      "epoch : 630, loss : 0.6089077591896057, val_loss : 1.7666393518447876, acc : 0.7842857241630554, val_acc : 0.4933333396911621\n",
      "epoch : 640, loss : 0.6054860949516296, val_loss : 1.7576173543930054, acc : 0.7914285659790039, val_acc : 0.49000000953674316\n",
      "epoch : 650, loss : 0.6026787161827087, val_loss : 1.767843246459961, acc : 0.7900000214576721, val_acc : 0.4833333194255829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 660, loss : 0.5992796421051025, val_loss : 1.7777477502822876, acc : 0.7928571701049805, val_acc : 0.49000000953674316\n",
      "epoch : 670, loss : 0.5964441895484924, val_loss : 1.7769348621368408, acc : 0.7942857146263123, val_acc : 0.49000000953674316\n",
      "epoch : 680, loss : 0.593474268913269, val_loss : 1.8122886419296265, acc : 0.7985714077949524, val_acc : 0.49000000953674316\n",
      "epoch : 690, loss : 0.5915572047233582, val_loss : 1.8212153911590576, acc : 0.8042857050895691, val_acc : 0.4866666793823242\n",
      "epoch : 700, loss : 0.5892757773399353, val_loss : 1.8357800245285034, acc : 0.8071428537368774, val_acc : 0.47999998927116394\n",
      "epoch : 710, loss : 0.5856098532676697, val_loss : 1.8533538579940796, acc : 0.8042857050895691, val_acc : 0.47999998927116394\n",
      "epoch : 720, loss : 0.5848721265792847, val_loss : 1.859802007675171, acc : 0.8057143092155457, val_acc : 0.4866666793823242\n",
      "epoch : 730, loss : 0.5812816619873047, val_loss : 1.865067720413208, acc : 0.808571457862854, val_acc : 0.47999998927116394\n",
      "epoch : 740, loss : 0.5793194770812988, val_loss : 1.8801342248916626, acc : 0.8071428537368774, val_acc : 0.47999998927116394\n",
      "epoch : 750, loss : 0.5759704113006592, val_loss : 1.8713598251342773, acc : 0.808571457862854, val_acc : 0.47999998927116394\n",
      "epoch : 760, loss : 0.5737099051475525, val_loss : 1.9018197059631348, acc : 0.808571457862854, val_acc : 0.4833333194255829\n",
      "epoch : 770, loss : 0.5718501210212708, val_loss : 1.919589877128601, acc : 0.8114285469055176, val_acc : 0.4866666793823242\n",
      "epoch : 780, loss : 0.5690241456031799, val_loss : 1.9147145748138428, acc : 0.8128571510314941, val_acc : 0.4699999988079071\n",
      "epoch : 790, loss : 0.5654447674751282, val_loss : 1.8987764120101929, acc : 0.8171428442001343, val_acc : 0.476666659116745\n",
      "epoch : 800, loss : 0.5634015202522278, val_loss : 1.9282177686691284, acc : 0.8185714483261108, val_acc : 0.47999998927116394\n",
      "epoch : 810, loss : 0.5610564947128296, val_loss : 1.9376822710037231, acc : 0.8214285969734192, val_acc : 0.47333332896232605\n",
      "epoch : 820, loss : 0.5592100024223328, val_loss : 1.9607144594192505, acc : 0.8185714483261108, val_acc : 0.47999998927116394\n",
      "epoch : 830, loss : 0.556392252445221, val_loss : 1.9671311378479004, acc : 0.8199999928474426, val_acc : 0.47333332896232605\n",
      "epoch : 840, loss : 0.5544068217277527, val_loss : 1.982136845588684, acc : 0.8199999928474426, val_acc : 0.476666659116745\n",
      "epoch : 850, loss : 0.552477240562439, val_loss : 1.9730865955352783, acc : 0.8257142901420593, val_acc : 0.4699999988079071\n",
      "epoch : 860, loss : 0.5503054857254028, val_loss : 1.997279405593872, acc : 0.822857141494751, val_acc : 0.476666659116745\n",
      "epoch : 870, loss : 0.5479407906532288, val_loss : 1.9789060354232788, acc : 0.8242856860160828, val_acc : 0.47999998927116394\n",
      "epoch : 880, loss : 0.5463492274284363, val_loss : 2.0161097049713135, acc : 0.8299999833106995, val_acc : 0.4699999988079071\n",
      "epoch : 890, loss : 0.5450891852378845, val_loss : 2.0188488960266113, acc : 0.8214285969734192, val_acc : 0.47333332896232605\n",
      "epoch : 900, loss : 0.5427409410476685, val_loss : 2.027689218521118, acc : 0.8271428346633911, val_acc : 0.476666659116745\n",
      "epoch : 910, loss : 0.5422462224960327, val_loss : 2.046830654144287, acc : 0.8299999833106995, val_acc : 0.46666666865348816\n",
      "epoch : 920, loss : 0.5392362475395203, val_loss : 2.03352427482605, acc : 0.8299999833106995, val_acc : 0.47999998927116394\n",
      "epoch : 930, loss : 0.5379921793937683, val_loss : 2.0531249046325684, acc : 0.8328571319580078, val_acc : 0.476666659116745\n",
      "epoch : 940, loss : 0.5363833904266357, val_loss : 2.0612924098968506, acc : 0.8285714387893677, val_acc : 0.4833333194255829\n",
      "epoch : 950, loss : 0.5344422459602356, val_loss : 2.0894320011138916, acc : 0.831428587436676, val_acc : 0.4833333194255829\n",
      "epoch : 960, loss : 0.5334722399711609, val_loss : 2.077577829360962, acc : 0.831428587436676, val_acc : 0.47999998927116394\n",
      "epoch : 970, loss : 0.5321154594421387, val_loss : 2.10493540763855, acc : 0.8299999833106995, val_acc : 0.476666659116745\n",
      "epoch : 980, loss : 0.529761791229248, val_loss : 2.1025872230529785, acc : 0.8342857360839844, val_acc : 0.47999998927116394\n",
      "epoch : 990, loss : 0.5281503200531006, val_loss : 2.1065361499786377, acc : 0.8328571319580078, val_acc : 0.47999998927116394\n"
     ]
    }
   ],
   "source": [
    "class CustomHistory(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []\n",
    "        self.val_acc = []\n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('accuracy'))\n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        if self.epoch % 10 == 0:\n",
    "            print('epoch : {}, loss : {}, val_loss : {}, acc : {}, val_acc : {}'.format(self.epoch,logs.get('loss'),logs.get('val_loss'),logs.get('accuracy'),logs.get('val_accuracy')))\n",
    "        self.epoch +=1\n",
    "\n",
    "# 1. 데이터 셋 준비하기\n",
    "# 훈련셋, 테스트셋 분리. 보통 7:3으로 분류\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data() # mnist 분리\n",
    "# 훈련셋에서 검증셋 분리 (X_train, Y_train)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눔\n",
    "X_train = X_train.reshape(50000,784).astype('float')/255.0\n",
    "X_val = X_val.reshape(10000,784).astype('float')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float')/255.0\n",
    "# 데이터가 많아 시간상 매우오래 걸릴 수 있음.\n",
    "# 훈련셋과 검증셋700개,300개씩만 가져옴.\n",
    "train_rand_idx = np.random.choice(50000,700)\n",
    "val_rand_idx = np.random.choice(10000,300)\n",
    "X_train = X_train[train_rand_idx]\n",
    "Y_train = Y_train[train_rand_idx]\n",
    "X_val = X_val[val_rand_idx]\n",
    "Y_val = Y_val[val_rand_idx]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train) # 자동으로 해준다\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "# 2단레이어 구조로 deeplearning\n",
    "model.add(Dense(units=2,input_dim=784,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "# 4. 학습\n",
    "cus_his = CustomHistory()\n",
    "hist = model.fit(X_train,Y_train,epochs=1000,batch_size=10,validation_data=(X_val,Y_val),verbose=0,\n",
    "                 callbacks=[cus_his])\n",
    "# validation_data로 과적합 발생률을 줄여준다.\n",
    "# 콜백함수에서 accuracy 프린트해주기 때문에 verbose는 0\n",
    "# callbacks에는 CustomHistory() 객체를 넣어준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:18:06.723708Z",
     "start_time": "2021-03-24T01:18:06.714706Z"
    }
   },
   "source": [
    "# 2. early stopping\n",
    "- val_loss값이 늘어나면 epoch를 다 수행하지 않고 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:53:10.471563Z",
     "start_time": "2021-03-24T01:52:57.293371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 0s 3ms/step - loss: 2.2907 - accuracy: 0.1695 - val_loss: 2.2485 - val_accuracy: 0.2167\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2263 - accuracy: 0.2330 - val_loss: 2.1772 - val_accuracy: 0.2533\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1513 - accuracy: 0.2556 - val_loss: 2.1072 - val_accuracy: 0.2767\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0823 - accuracy: 0.2749 - val_loss: 2.0430 - val_accuracy: 0.2767\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0042 - accuracy: 0.2820 - val_loss: 1.9993 - val_accuracy: 0.2767\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9435 - accuracy: 0.2758 - val_loss: 1.9638 - val_accuracy: 0.2833\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9277 - accuracy: 0.3263 - val_loss: 1.9273 - val_accuracy: 0.2900\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8905 - accuracy: 0.2868 - val_loss: 1.8899 - val_accuracy: 0.3033\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8922 - accuracy: 0.3066 - val_loss: 1.8577 - val_accuracy: 0.3100\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7867 - accuracy: 0.3382 - val_loss: 1.8318 - val_accuracy: 0.3233\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7453 - accuracy: 0.3692 - val_loss: 1.8053 - val_accuracy: 0.3433\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7662 - accuracy: 0.3648 - val_loss: 1.7835 - val_accuracy: 0.3533\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7199 - accuracy: 0.3583 - val_loss: 1.7612 - val_accuracy: 0.3600\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6385 - accuracy: 0.3852 - val_loss: 1.7406 - val_accuracy: 0.3733\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6715 - accuracy: 0.3938 - val_loss: 1.7259 - val_accuracy: 0.3733\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6241 - accuracy: 0.3976 - val_loss: 1.7054 - val_accuracy: 0.3800\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6180 - accuracy: 0.3826 - val_loss: 1.6875 - val_accuracy: 0.3700\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5756 - accuracy: 0.3872 - val_loss: 1.6727 - val_accuracy: 0.3967\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5480 - accuracy: 0.4391 - val_loss: 1.6601 - val_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5631 - accuracy: 0.4336 - val_loss: 1.6432 - val_accuracy: 0.4067\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5161 - accuracy: 0.4544 - val_loss: 1.6315 - val_accuracy: 0.3967\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5316 - accuracy: 0.4125 - val_loss: 1.6193 - val_accuracy: 0.4033\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4691 - accuracy: 0.4226 - val_loss: 1.6064 - val_accuracy: 0.4167\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4785 - accuracy: 0.4272 - val_loss: 1.5993 - val_accuracy: 0.4133\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4742 - accuracy: 0.4263 - val_loss: 1.5878 - val_accuracy: 0.4333\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4281 - accuracy: 0.4489 - val_loss: 1.5774 - val_accuracy: 0.4633\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4355 - accuracy: 0.4509 - val_loss: 1.5673 - val_accuracy: 0.4467\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4329 - accuracy: 0.4722 - val_loss: 1.5643 - val_accuracy: 0.4333\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4010 - accuracy: 0.4607 - val_loss: 1.5535 - val_accuracy: 0.4300\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4315 - accuracy: 0.4533 - val_loss: 1.5476 - val_accuracy: 0.4333\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3659 - accuracy: 0.4713 - val_loss: 1.5413 - val_accuracy: 0.4167\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4173 - accuracy: 0.4384 - val_loss: 1.5314 - val_accuracy: 0.4200\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3638 - accuracy: 0.4586 - val_loss: 1.5248 - val_accuracy: 0.4300\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3696 - accuracy: 0.4631 - val_loss: 1.5231 - val_accuracy: 0.4467\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3428 - accuracy: 0.4787 - val_loss: 1.5133 - val_accuracy: 0.4367\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3226 - accuracy: 0.4828 - val_loss: 1.5075 - val_accuracy: 0.4367\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3063 - accuracy: 0.5080 - val_loss: 1.5079 - val_accuracy: 0.4333\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2967 - accuracy: 0.5169 - val_loss: 1.4968 - val_accuracy: 0.4600\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 987us/step - loss: 1.3032 - accuracy: 0.4813 - val_loss: 1.4981 - val_accuracy: 0.4233\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3022 - accuracy: 0.4804 - val_loss: 1.4872 - val_accuracy: 0.4400\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2769 - accuracy: 0.4912 - val_loss: 1.4841 - val_accuracy: 0.4433\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2925 - accuracy: 0.4577 - val_loss: 1.4807 - val_accuracy: 0.4467\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2519 - accuracy: 0.5092 - val_loss: 1.4747 - val_accuracy: 0.4433\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2613 - accuracy: 0.5049 - val_loss: 1.4733 - val_accuracy: 0.4633\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2657 - accuracy: 0.5141 - val_loss: 1.4710 - val_accuracy: 0.4433\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2388 - accuracy: 0.5308 - val_loss: 1.4674 - val_accuracy: 0.4467\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2084 - accuracy: 0.5470 - val_loss: 1.4605 - val_accuracy: 0.4567\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2669 - accuracy: 0.5086 - val_loss: 1.4631 - val_accuracy: 0.4433\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2021 - accuracy: 0.5258 - val_loss: 1.4629 - val_accuracy: 0.4267\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2309 - accuracy: 0.5423 - val_loss: 1.4511 - val_accuracy: 0.4567\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2528 - accuracy: 0.5226 - val_loss: 1.4487 - val_accuracy: 0.4433\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2427 - accuracy: 0.5099 - val_loss: 1.4520 - val_accuracy: 0.4400\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2149 - accuracy: 0.5165 - val_loss: 1.4464 - val_accuracy: 0.4433\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1837 - accuracy: 0.5287 - val_loss: 1.4406 - val_accuracy: 0.4467\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2125 - accuracy: 0.5540 - val_loss: 1.4424 - val_accuracy: 0.4367\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2217 - accuracy: 0.4794 - val_loss: 1.4383 - val_accuracy: 0.4467\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1697 - accuracy: 0.5625 - val_loss: 1.4405 - val_accuracy: 0.4433\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1754 - accuracy: 0.5562 - val_loss: 1.4379 - val_accuracy: 0.4500\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1260 - accuracy: 0.5762 - val_loss: 1.4353 - val_accuracy: 0.4533\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1351 - accuracy: 0.5597 - val_loss: 1.4311 - val_accuracy: 0.4500\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1390 - accuracy: 0.5583 - val_loss: 1.4274 - val_accuracy: 0.4600\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1646 - accuracy: 0.5461 - val_loss: 1.4227 - val_accuracy: 0.4567\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1682 - accuracy: 0.5613 - val_loss: 1.4301 - val_accuracy: 0.4467\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1560 - accuracy: 0.5608 - val_loss: 1.4228 - val_accuracy: 0.4633\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1351 - accuracy: 0.5819 - val_loss: 1.4220 - val_accuracy: 0.4733\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1408 - accuracy: 0.5899 - val_loss: 1.4171 - val_accuracy: 0.4600\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1519 - accuracy: 0.5440 - val_loss: 1.4145 - val_accuracy: 0.4867\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0838 - accuracy: 0.6016 - val_loss: 1.4093 - val_accuracy: 0.4967\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1056 - accuracy: 0.5740 - val_loss: 1.4096 - val_accuracy: 0.4833\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 979us/step - loss: 1.1277 - accuracy: 0.5895 - val_loss: 1.4084 - val_accuracy: 0.4667\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1119 - accuracy: 0.5798 - val_loss: 1.4075 - val_accuracy: 0.5033\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0755 - accuracy: 0.6151 - val_loss: 1.4085 - val_accuracy: 0.4833\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0700 - accuracy: 0.6006 - val_loss: 1.4066 - val_accuracy: 0.4767\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1315 - accuracy: 0.5864 - val_loss: 1.4008 - val_accuracy: 0.4967\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0531 - accuracy: 0.6101 - val_loss: 1.4000 - val_accuracy: 0.4867\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 982us/step - loss: 1.0714 - accuracy: 0.6096 - val_loss: 1.4005 - val_accuracy: 0.4967\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1307 - accuracy: 0.5873 - val_loss: 1.3954 - val_accuracy: 0.5100\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1175 - accuracy: 0.6049 - val_loss: 1.3982 - val_accuracy: 0.5133\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1051 - accuracy: 0.5886 - val_loss: 1.3951 - val_accuracy: 0.5133\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0507 - accuracy: 0.6150 - val_loss: 1.3953 - val_accuracy: 0.5133\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0499 - accuracy: 0.6363 - val_loss: 1.3951 - val_accuracy: 0.5300\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1255 - accuracy: 0.5700 - val_loss: 1.3974 - val_accuracy: 0.5100\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0479 - accuracy: 0.6507 - val_loss: 1.3881 - val_accuracy: 0.5167\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0856 - accuracy: 0.5954 - val_loss: 1.3857 - val_accuracy: 0.5300\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0410 - accuracy: 0.6162 - val_loss: 1.3810 - val_accuracy: 0.5200\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0470 - accuracy: 0.6178 - val_loss: 1.3813 - val_accuracy: 0.5200\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0584 - accuracy: 0.6170 - val_loss: 1.3830 - val_accuracy: 0.5333\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0554 - accuracy: 0.6147 - val_loss: 1.3781 - val_accuracy: 0.5233\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0101 - accuracy: 0.6448 - val_loss: 1.3867 - val_accuracy: 0.5300\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0414 - accuracy: 0.6610 - val_loss: 1.3753 - val_accuracy: 0.5233\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0170 - accuracy: 0.6663 - val_loss: 1.3781 - val_accuracy: 0.5167\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0516 - accuracy: 0.6144 - val_loss: 1.3774 - val_accuracy: 0.5133\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.6383 - val_loss: 1.3771 - val_accuracy: 0.5233\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0046 - accuracy: 0.6745 - val_loss: 1.3722 - val_accuracy: 0.5200\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0340 - accuracy: 0.6514 - val_loss: 1.3740 - val_accuracy: 0.5167\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0236 - accuracy: 0.6391 - val_loss: 1.3728 - val_accuracy: 0.5267\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9969 - accuracy: 0.6564 - val_loss: 1.3698 - val_accuracy: 0.5100\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1052 - accuracy: 0.6220 - val_loss: 1.3760 - val_accuracy: 0.5167\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0042 - accuracy: 0.6349 - val_loss: 1.3722 - val_accuracy: 0.5267\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0188 - accuracy: 0.6544 - val_loss: 1.3786 - val_accuracy: 0.5333\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9683 - accuracy: 0.6865 - val_loss: 1.3696 - val_accuracy: 0.5233\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9533 - accuracy: 0.6832 - val_loss: 1.3757 - val_accuracy: 0.5167\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 992us/step - loss: 1.0337 - accuracy: 0.6214 - val_loss: 1.3739 - val_accuracy: 0.5233\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.6680 - val_loss: 1.3731 - val_accuracy: 0.5200\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9605 - accuracy: 0.6705 - val_loss: 1.3642 - val_accuracy: 0.5300\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9795 - accuracy: 0.6823 - val_loss: 1.3636 - val_accuracy: 0.5367\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9732 - accuracy: 0.6549 - val_loss: 1.3643 - val_accuracy: 0.5333\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0015 - accuracy: 0.6757 - val_loss: 1.3693 - val_accuracy: 0.5200\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9847 - accuracy: 0.6712 - val_loss: 1.3620 - val_accuracy: 0.5367\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9879 - accuracy: 0.6803 - val_loss: 1.3603 - val_accuracy: 0.5467\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9271 - accuracy: 0.6741 - val_loss: 1.3624 - val_accuracy: 0.5400\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9241 - accuracy: 0.6920 - val_loss: 1.3584 - val_accuracy: 0.5467\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9989 - accuracy: 0.6533 - val_loss: 1.3714 - val_accuracy: 0.5267\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9347 - accuracy: 0.6898 - val_loss: 1.3635 - val_accuracy: 0.5367\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9669 - accuracy: 0.6714 - val_loss: 1.3611 - val_accuracy: 0.5367\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9443 - accuracy: 0.6721 - val_loss: 1.3640 - val_accuracy: 0.5367\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9505 - accuracy: 0.6895 - val_loss: 1.3599 - val_accuracy: 0.5533\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9208 - accuracy: 0.6907 - val_loss: 1.3632 - val_accuracy: 0.5367\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9537 - accuracy: 0.6667 - val_loss: 1.3642 - val_accuracy: 0.5433\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9468 - accuracy: 0.6901 - val_loss: 1.3866 - val_accuracy: 0.5400\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9495 - accuracy: 0.6851 - val_loss: 1.3655 - val_accuracy: 0.5467\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9336 - accuracy: 0.7014 - val_loss: 1.3715 - val_accuracy: 0.5367\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.7215 - val_loss: 1.3668 - val_accuracy: 0.5400\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8863 - accuracy: 0.7230 - val_loss: 1.3693 - val_accuracy: 0.5467\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.7013 - val_loss: 1.3647 - val_accuracy: 0.5400\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9463 - accuracy: 0.7017 - val_loss: 1.3656 - val_accuracy: 0.5467\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9128 - accuracy: 0.6961 - val_loss: 1.3719 - val_accuracy: 0.5433\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9356 - accuracy: 0.6945 - val_loss: 1.3693 - val_accuracy: 0.5467\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9213 - accuracy: 0.7017 - val_loss: 1.3694 - val_accuracy: 0.5400\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 981us/step - loss: 0.9260 - accuracy: 0.6807 - val_loss: 1.3686 - val_accuracy: 0.5433\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 962us/step - loss: 0.8994 - accuracy: 0.7258 - val_loss: 1.3775 - val_accuracy: 0.5467\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8815 - accuracy: 0.7129 - val_loss: 1.3796 - val_accuracy: 0.5400\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 958us/step - loss: 0.9138 - accuracy: 0.6770 - val_loss: 1.3727 - val_accuracy: 0.5533\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8659 - accuracy: 0.7194 - val_loss: 1.3821 - val_accuracy: 0.5467\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8518 - accuracy: 0.7515 - val_loss: 1.3781 - val_accuracy: 0.5367\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8737 - accuracy: 0.7198 - val_loss: 1.3756 - val_accuracy: 0.5500\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8949 - accuracy: 0.6909 - val_loss: 1.3800 - val_accuracy: 0.5400\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8709 - accuracy: 0.7163 - val_loss: 1.3750 - val_accuracy: 0.5300\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8592 - accuracy: 0.7349 - val_loss: 1.3850 - val_accuracy: 0.5333\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8773 - accuracy: 0.7286 - val_loss: 1.3760 - val_accuracy: 0.5400\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8757 - accuracy: 0.7127 - val_loss: 1.3793 - val_accuracy: 0.5233\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8780 - accuracy: 0.7255 - val_loss: 1.3817 - val_accuracy: 0.5367\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 셋 준비하기\n",
    "# 훈련셋, 테스트셋 분리. 보통 7:3으로 분류\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data() # mnist 분리\n",
    "# 훈련셋에서 검증셋 분리 (X_train, Y_train)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눔\n",
    "X_train = X_train.reshape(50000,784).astype('float')/255.0\n",
    "X_val = X_val.reshape(10000,784).astype('float')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float')/255.0\n",
    "# 데이터가 많아 시간상 매우오래 걸릴 수 있음.\n",
    "# 훈련셋과 검증셋700개,300개씩만 가져옴.\n",
    "train_rand_idx = np.random.choice(50000,700)\n",
    "val_rand_idx = np.random.choice(10000,300)\n",
    "X_train = X_train[train_rand_idx]\n",
    "Y_train = Y_train[train_rand_idx]\n",
    "X_val = X_val[val_rand_idx]\n",
    "Y_val = Y_val[val_rand_idx]\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train) # 자동으로 해준다\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "# 2단레이어 구조로 deeplearning\n",
    "model.add(Dense(units=2,input_dim=784,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "# 4. 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stop = EarlyStopping() # 성급한 조기종료( 1번이라도 val_loss가 커지면 종료)\n",
    "early_stop = EarlyStopping(patience=30) # patience 인자 수만큼 loss가 올라도 진행\n",
    "hist = model.fit(X_train,Y_train,epochs=1000,batch_size=10,validation_data=(X_val,Y_val),verbose=1,\n",
    "                 callbacks=[early_stop])\n",
    "# validation_data로 과적합 발생률을 줄여준다.\n",
    "# early_stop 객체를 callbaks에 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:53:16.993868Z",
     "start_time": "2021-03-24T01:53:16.732153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABn7ElEQVR4nO2dd3hUxfeH30nvHUIJoffeQRCwAgKiYkGKYsPefypiw/a1i72golixoqJIk6qA9N4hBAIhjfSe3fP7YzYFSAOy2U0y7/Psk733zp177ia5nz0zZ85RIoLBYDAYDM6Ei6MNMBgMBoPhVIw4GQwGg8HpMOJkMBgMBqfDiJPBYDAYnA4jTgaDwWBwOtwcbcCZ4uLiIt7e3o42w2AwGGoUWVlZIiI1xiGpceLk7e1NZmamo80wGAyGGoVSKtvRNpwJNUZFDQaDwVB3MOJkMBgMBqfDiJPBYDAYnI4aN+dUGvn5+cTExJCTk+NoU2osXl5eRERE4O7u7mhTDAaDoXaIU0xMDP7+/jRr1gyllKPNqXGICElJScTExNC8eXNHm2MwGAy1Y1gvJyeH0NBQI0xniVKK0NBQ43kaDAanoVaIE2CE6Rwxn5/BYHAmao04VYTFkk1OzhFELI42xWAwGM6Y556DjRsdbUX1UWfEyWrNJT8/Doslq8r7TklJ4YMPPjircy+77DJSUlIq3X7atGm8/vrrZ3Utg8HgOOLioG1bePFFKKuM3pYt8PXXpx//5Rd45hn4+Wf72+ks1BlxcnX1BcBiyajyvssTJ4ulfE9t3rx5BAUFVblNBoPBuXjhBdi7F558Eh59tFiA4uLgp59gxAjo1g0mToTPPy8+79gxuO026NlTC1Rdoc6Ik4uLO0p5YrVWfeqjKVOmcODAAbp168YjjzzCsmXLuOCCCxg3bhydO3cG4IorrqBnz5507NiRGTNmFJ3brFkzEhMTOXToEO3bt+e2226jY8eOXHrppWRnl59tZPPmzfTr148uXbpw5ZVXkpycDMA777xDhw4d6NKlC2PHjgVg+fLldOvWjW7dutG9e3fS09Or/HMwGAwQHQ1ffqmFqFCADh2Cjz+GW2+Fe+6B118Hf3/9atAArrkG1q7VXtUFF8B998GBA5CeDpMmQXa29qg8PBx5Z9VLrQglL8m+fQ+QkbH5tP0WsZBbkI2HC7i5+p1Rn35+3Wjd+q0yj7/88sts376dzZv1dZctW8batWvZvn17UWj2zJkzCQkJITs7m969ezNmzBhCQ0NPsX0f3333HZ988gnXXnstP//8MxMmTCjzujfccAPvvvsugwcP5umnn+bZZ5/lrbfe4uWXXyYqKgpPT8+iIcPXX3+d999/nwEDBpCRkYGXl9cZfQYGQ13k66+1qCxaBJX5l8nJgZEjYft2vd24sRaaTZvAxUV7Po0bQ9eusHOnbtOoEQwcCD16aPGZOBG6dIFhwyAxEVJStA3t2tntNp2SWidO5WERwSoAVuztNPbp0+ekNUPvvPMOc+bMAeDIkSPs27fvNHFq3rw53bp1A6Bnz54cOnSozP5TU1NJSUlh8ODBANx4441cc801AHTp0oXx48dzxRVXcMUVVwAwYMAAHnroIcaPH89VV11FREREFd2pwVA7yc+HqVPhyBH44AN46KGKz5k6VQvTZ5+BxQI//giPPaaPPfwwFP7b3Xpr2X00aaLFaNw4GD0aHn8cevU69/upDEqpYcDbgCvwqYi8fMrxR4Dxtk03oD1QT0ROVLUttU6cyvJwLFYLm45vItQDIgKb4+4eWmq7qsLX17fo/bJly1i8eDGrV6/Gx8eHIUOGlLqmyNPTs+i9q6trhcN6ZfHnn3+yYsUKfv/9d55//nl27NjBlClTGDFiBPPmzaNfv34sXryYdnXtq5jBcAZ8950WpiZN4H//04ISEKCPJSRo8Zg0CcbbHtWLFsH06XD33XDzzXrfbbfB+vXw66/wf/9X+Wtfe60WphKPBLujlHIF3gcuAWKAdUqp30VkZ2EbEXkNeM3WfhTwoD2ECerQnJOriyvebt7kWMBiqdp5J39//3LncFJTUwkODsbHx4fdu3ezZs2ac75mYGAgwcHBrFy5EoCvvvqKwYMHY7VaOXLkCBdccAGvvvoqKSkpZGRkcODAATp37sxjjz1Gr1692L179znbYDA4M088cfYBBFYrvPIKdO6sI+SSkuDNN/Wx3Fy46ipYvFiL07Jl8M8/MGaMHnp79dWT++rVSwdDnGncU3UKk40+wH4ROSgiecBsYHQ57a8HvrOXMbXOcyoPPw8/krKzqzxiLzQ0lAEDBtCpUyeGDx/OiBEjTjo+bNgwPvroI7p06ULbtm3p169flVx31qxZ3HHHHWRlZdGiRQs+//xzLBYLEyZMIDU1FRHhwQcfJCgoiKeeeoqlS5fi6upKhw4dGD58eJXYYDA4I/HxWiQKCmD4cCj5L2e1am+mVy89DwSwaxeEhkL9+nr711/1nNA330Dv3lp4XntNR9bFxmox+uQTLVhXXaXnmpo0gYULwcen2m+3srgppdaX2J4hIjNKbDcGjpTYjgH6ltaRUsoHGAbcU+VWFiIidnkBTYClwC5gB3B/KW3GA1ttr1VA14r69fHxkVPZuXPnaftKIyEzQdYdXScJKevEarVU6py6RGU/R4PB2XnjDREQCQkR6dFDpKCg+Njbb+tjF18ssn+/yF136W0vL5F77hEZN07ExUWkVSuR/Hx9zqFDIpddJuLvr9s+95zef+CASFiYSJcuInFx1X+fZwKQKeU/s69BzzMVbk8E3i2j7XXA3PL6O9eXPT2nAuBhEdmolPIHNiilFkmJ8UsgChgsIslKqeHADMpQ6qrA113PAxUO7bm5+dvrUgaDoZo4eBCaN4fCDFwiOiChb1948EEYO1YHGNx1lw7NfuEFaNMGVq2CVq30Offfr4999JEeTnvoIR3A4GZ7QjZtCn/+qT2xI0egWTO9v0UL2LdPe0u1IMw7Bu1UFBIBHCuj7VjsOKQHdhzWE5FYINb2Pl0ptQvtNpacXFtV4pQ16A/Dbni5eeGqXMixWLFaswAjTgZDTWbZMr0uaPJkHVHn6grr1ukhuY8/1oEFn36qgxFattRriRISYO5cPQf0wgtwww1wySW6v1deAXd3CAws/XpubloIS1KL1tCvA1orpZoDR9ECNO7URkqpQGAwUPY6lyqgWuaclFLNgO7Af+U0uwX4q4zzJwOTATzO4euJUgofd19yCjKqPCjCYDDYj7Q0PVd0qhDMn69/zpgBGRl6TdHbb4O3t/aYlIJvv4VLL4VRo7R3c8UV2qsC+Oqrk/sLC7P3nTgvIlKglLoHWIAOJZ8pIjuUUnfYjn9ka3olsFBE7PoQVVJWkqequoBSfsBy4EUR+aWMNhcAHwADRSSpvP58fX0lM/Pkz2TXrl20b9++UvYcTTtKbEYsbQO88PfrVKlz6gpn8jkaDNWFCJx3HuzeXewNFdK/vxagUaP0GqNCbrwRvviieDslBS67THtOmzdDpzr4r6+UyhIR34pbOgd29ZyUUu7Az8A35QhTF+BTYHhFwlQV+Hro301WQQ5+YkGH9hsMBmciOVl7SUrBkiWwZg00bAjXXQcrVsB772lPaf16eOQRvVB16FAdTaeUFq2SBAXpfmJiiueZDM6N3dY5KV0g6DNgl4i8WUabSOAXYKKI7LWXLSU5OSji7Ba5GgwG+/HzzxAerhe9iuh5oAYNdK66O+6A99+HrVt1QENBAdiSpNCjhw4bHzas9DkjLy8jTDUJe3pOA9ChiNuUUptt+6YCkVA0fvk0EAp8YCt2VyAidk3U4e7qjoerBzmWPFsS2DPLs1dV+Pn5kZFx+nqrsvYbDLUdEZ0w9eab9XqjmTP1PNOiRVqg/Px0YtQvvtACFRamAyAGDHC05QZ7YM9ovX+AcsurisitQDlZpuyDn7sfabkn7FLbyWAwnIxIcZh3accWL9ZCtGKFLg9x0UV6Eeytt2ohCgzUHhNASIhOF/T11zr6rlcvLVqG2kedSV9UEl8PXwoEcguqJtjkscceO6me07Rp03jjjTfIyMjgoosuokePHnTu3Jnffvut0n2KCI888gidOnWic+fOfP/99wDExsYyaNAgunXrRqdOnVi5ciUWi4VJkyYVtZ0+fXqV3JfBUFl27tSVWmNiivcdOqTzzPn46FDto0dPPmftWujTR0fS/f03DBqk1xn98YcWnM8/15kZXnqpOKcd6D6zsmDbtuIhPUPto9alL3pg/gNsPr653DYWsZCVn4WnC3i4+VGBg0e3Bt14a9hbZR4fO3YsDzzwAHfddRcAP/zwA/Pnz8fLy4s5c+YQEBBAYmIi/fr14/LLL0eV9TWyBL/88gubN29my5YtJCYm0rt3bwYNGsS3337L0KFDeeKJJ7BYLGRlZbF582aOHj3Kdlue/jOprGswnCvHjmmBOXpUrxsaPhz279eC5e6uE5jOm6fLQLz5pk6YumKF3h8SosPAb7jh9Fxy3t66CN+pdO+uo/dWrYIhQ6rlFg0OoE56Tq62CD2rgIj1nPvr3r078fHxHDt2jC1bthAcHExkZCQiwtSpU+nSpQsXX3wxR48eJS4urlJ9/vPPP1x//fW4uroSHh7O4MGDWbduHb179+bzzz9n2rRpbNu2DX9/f1q0aMHBgwe59957mT9/PgElv2YaDHYkK0uLTEqK9nhuv13XLmraVGfyPnhQl43YuFEPw02aBK1b66qvzZtr7+m22848yelTT+mqseefb4ebMjgFtc5zKs/DKcnOhB2INZvWwU3w8Ag/5+teffXV/PTTTxw/fryo+uw333xDQkICGzZswN3dnWbNmpVaKqM0ylp/NmjQIFasWMGff/7JxIkTeeSRR7jhhhvYsmULCxYs4P333+eHH35g5syZ53xPhrrFSy/B7NlaMEqKxcGD2lPp3VuvJSoZpn3HHbBhg54jGjFCv9599/S+27aF//7TKYBefhkiI2HOHJ1s9WwYNky/DLWXOuk5Afh5+JNrgYIqyhQxduxYZs+ezU8//cTVV18N6FIZ9evXx93dnaVLlxIdHV3p/gYNGsT333+PxWIhISGBFStW0KdPH6Kjo6lfvz633XYbt9xyCxs3biQxMRGr1cqYMWN4/vnn2bhxY5Xck6HuIKKH17Zu1dm2S/LAAzrv3OrVWqRuvVUX0ps9W2dYePppuPzyiq+hlK4S+88/eljvbIXJUDeodZ5TZfF19yUeyM5Px8f73Pvr2LEj6enpNG7cmIYNGwIwfvx4Ro0aRa9evejWrdsZFfe78sorWb16NV27dkUpxauvvkqDBg2YNWsWr732Gu7u7vj5+fHll19y9OhRbrrpJqxWPUT50ksvnfsNGeoUmzbpAAY/Pz1vdNNN4Ourc9DNnavLRdx5Jzz/vA7rTkyE5ct1KYonn3S09YbaiN3TF1U155q+qJCcghy2x28n3BMaB3fBxaXmpxQ+V0z6orrLE09o0fn1V50KaNo0HWE3YYIOTNi8WQc3ALzxhk6k6usLW7bouSSD82PSF9UQPF09cXNxJdtiwWLJNOJkqLOI6Ki4Cy7Qw26F4jRtmk6UunBhsTCBLiXRqpVef2SEyWAv6qw4KaXw8/AnMzcFiyUDd/dgR5tkMNgNq1Xnljv//NMj43bs0KmBHnhAb7/7rg777tkTBg6EevVO7290ecW7DYYqoNYERJzN8KSfhx/5ArkF6XawqGZR04Z3DWfGzJl6mG7kSDhlVJyff9bBCldeqbebNtXzTldeWbowGQzVQa0QJy8vL5KSks74AevvoYsNZuRlVcl6p5qKiJCUlISXl5ejTTHYgZwcePZZHb69ZIleMBsfr48tWaKDHS64QCdXNRichVoxrBcREUFMTAwJCQlndJ6IkJSWRKaLkOK7FReXM1wJWIvw8vIiIsKuhYgNdiQ6WkfalRae/cEHOq3QkiWQlKQzNDRrpusizZ6t54++/rraTTYYyqVWROudCxfNGsyhhBUsvfY1IiP/r8r6NRiqCxEtNvn5Oolqhw7Fx9LSoEULXU5i4UK9b/duHZn39dfQtSssWGDWHNUFalq0Xq0Y1jsXBje7iKhMOJKw2NGmGAxnxbZtcPiwHqobNEinCirk/fe1t/Tii8X72rXTSVWPHYN//zXCZHBO6rw4nR95PgL8e3g5Vmu+o80xGM6Y+fP1z6VL9dDeqFE6o0N2Nrz1lk7z07v36efVq3fmOe0MhuqizotT34i+uLu4sSU5h7S0NY42x2A4Y+bP16Hf558P33+vPaLnntO1kOLjYcoUR1toMJw5dV6cfNx96B/Rl3+T4MSJBY42x2A4I9LTda66wiSoffvq3HdvvaVTDfXrp4f6DIaaRp0XJ4BxnScSnQX/RVe+GKDBUF2sWgXXXKPXHY0dC6+/DuvW6UCIpUt1IETJDN2FxfliY7XXVInyYQaD01Hno/UAkrKSaPB6fa6OsPLlxCTc3UOqtH+D4WzZs0d7P25u0KiRjr47dEgfGz1a572bOxdOnNCphgr5/Xe9/+OPwcV8BTVgovWKUEo1UUotVUrtUkrtUErdX0obpZR6Rym1Xym1VSnVw172lEeoTygXNu3L0nhIOrHIESYYDKeRlKQzOri7a09pyxaIitIe0auvwl9/6XVKF110sjCBLmHxySdGmAw1F3v+6RYAD4tIe6AfcLdSqsMpbYYDrW2vycCHdrSnXCZ0u4O4XFiyz6xGNDgHDz6oQ8R//VWvYyqkQQN45BFdFPDii+GuuxxlocFgP6ptWE8p9RvwnogsKrHvY2CZiHxn294DDBGR2LL6scewHkBGXgb1Xg1ieENPfr45HaXMV05D9WKxaE9HKUhOhoYNdXDDe+852jJDbcAM65WCUqoZ0B3475RDjYEjJbZjbPtOPX+yUmq9Ump9QUGBXWz08/BjePM+LDqeRWzSUrtcw2AojWPHdH2koKDisO9vv4XcXLjlFoeaZjA4DLuLk1LKD/gZeEBE0k49XMopp7lyIjJDRHqJSC83N/ulA7zvvGfIKICZ61622zUMhrw8LTz79sHtt0Pz5jB9ug54eOMNXSp95kzo1g26d3e0tYa6hFJqmFJqjy0OoNQVckqpIUqpzbZYguX2ssWu4qSUckcL0zci8kspTWKAJiW2I4Bj9rSpPAY3u5S2gQF8sXN5Uclzg6GqSE+Hm28GLy/9atMGZs3S+/bt0yHjQUE6bHzjRr3fYKgulFKuwPvoWIAOwPWnxgkopYKAD4DLRaQjcI297LFntJ4CPgN2icibZTT7HbjBFrXXD0gtb77J3iiluK3rGA5k5DN/9yeOMsNQy4iOhq++0l7QrFlw553wv/9pbykqCj78UCdnDQ2Fl1/Whf88PGD8eEdbbqhj9AH2i8hBEckDZgOnlpUcB/wiIocBRCTeXsbYLSBCKTUQWAlsAwrdkKlAJICIfGQTsPeAYUAWcJOIrC+vX3sFRBSSmhVDk+lNGNioLfNu2m236xhqPyJw/fU6pRDoiLsvv9RphsrCaoWhQ3UZiw8dFrtqqI0opfLQz+NCZojIjBLHrwaGicittu2JQF8RuadEm7cAd6Aj4A+8LSJf2sNeu03giMg/lD6nVLKNAHfby4azIdAngquaNePrA3s4nHKYyKBIR5tkqKH8+qsWpnvu0YENnTuDq2v557i4wCKz1M5gHwpEpFc5xysTA+AG9AQuAryB1UqpNSKyt4psLMLES5fCnb3uwCrw7upnHG2KoYaSmQn3368Fafp0HdxQkTAZDA6mMjEAMcB8EckUkURgBdDVHsYYcSqFni3v5LwwF2ZumU1OQY6jzTE4KXl5OrddaSPjL7wAR47oKrR2DDA1GKqSdUBrpVRzpZQHMBYdF1CS34DzlVJuSikfoC+wyx7GGHEqBTe3AG7qcAEncnP4ftu3jjbH4KS89BJceCG89trJ++fP1+mFJk2CgQMdYprBcMaISAFwD7AALTg/iMgOpdQdSqk7bG12AfOBrcBa4FMR2W4Pe0zi1zJISlpE988uJdS/JZvu3G/36xlqFlarXp907JjO7PDzzzpr+I4d0L+/jr775x9d/M9gcAZMhohaQkjIhVzTNIjN8QdYd3Sdo80xOAFxcTrXHcCSJfr9jBnQp4+OyuvYUXtKvr46I7gRJoPh7DHiVAZKuXJD15vxcoH3/nvD0eYYHExurg4B79pVl7GYOROCg7Uo/fYbTJwIHTrAZZfpbOFNmlTcp8FgKBszrFcOWVl7uO7rdiyOd+fYw3EEewdXy3UNzsf//gdPPKGL+NWrBzExcNtt8O67jrbMYKgcZlivFuHj05ZxrTuTY8ln1pZZjjbH4CAOHdLRd2PGaK8oJkZ7Uia9kMFgP4znVAFHj37Epd/fSYF7M3bfcxBlal7XCWJi4PHHdWG/Q4f0z127IDIS/vgDVq+GF190tJUGQ+UxnlMto37967i8sRt7Txzi76i/HW2OoRr4+Wfo0gV++QVycnRxv5kztTCBrk5rhMlgsC9GnCrA3T2Ya9qPJsRD8fI/LznaHIOd2b4drr5a57bbvFmHg//zD1x3naMtMxjqFkacKkHTxjdzTYTwd9QS1h8rNy+twcnJytLzRYVs2gTPP1+c5aEwr90vv0Dr1tVvn8Fg0BhxqgTBwZdydbNG+Lu78ZLxnmosFgv066fDvwt54gl4+mkdHg6wbJn2miIiHGKiwWCwYcSpEri4uNEy4jauaFjAnF1z2JVgl1RSBjvz22+wbZvOFn7ggA56WLBAH/v9d531YeVKGDzYoWYaDAaMOFWahg1v5qrGCm83Nx7/+3FHm2M4Q0TglVe0R+TqqmslzZqlBSkiQmd02LoVkpNhyBBHW2s4J/7v/+DPPx1thZ7AnDQJEhMdbUmNxIhTJfHyiqRFg8uY2MyL3/b8xqIDpuiOo1m0SA/DVYZly2DtWnjySbjqKvjsM/0aMgRuukmXSP/lF93WeE41mO3b4Y039Fito5kyRX8DGjFC11ApyZdfwsaNjrGrpiAiNerl4+MjjiIh4VdZ8DfS9M1waf9ee8kryHOYLXUdq1UkIkKka9fKtb34YpHwcJHsbJEVK0S0LyXy5Zcia9fq976+Ii1a2N10Q2VYvVokNbV4+9AhkYMHKz7vsceKf7k7dpTeJjdXZNky/YdxKtu26WsVkpgosnhxcducHJE//9Q/Szt3+3b9fudObcOll4q4uIgMGyaSZ3te7NkjopRI8+YiWVkV31MVAWSKEzzDK/tyuAFn+nKkOFks+bJqVYRM/6uLMA15a/VbDrOlrrN9u/7rdXPTglMer72m2775pt62WkW6dBEJCBDJzBSxWEQaNNBtbrrJ/rYbKmDpUv3L6NNHJCND/7KDgkQ6dCj/PItFf2Pp21fE1VXk8cf1/pwckaQk/b6gQOSaa3T/H3988vkrV4p4eYnUry+yb59IcrJI5866bd++Im+/rQUFRMaM0X2JiBw+LHLDDVpwfH31t51bb9V9xcfr64DIK6/o9nfcof9wQWTatKr61CrEiFMtFicRkUOHXpAlS5CLvhgggS8FSnxGvEPtqau8/roUfUH+7z+979gxkRdeEHn2WZGXXhJZuFBk9mz9zLjmGv3sKmT7dpHly4u3b71V9zVrVvXeh+EU8vK0CNWrpz2Oiy4SadxY/xJBZO/ess8tFLXvvtOeSmSkSHq6SP/+Ip6e2qu64w7dpmFDkZAQkYQEfe62bVoAW7cWCQ3VLvTAgSLu7iJPPinSqJE+r0sXkfvu0+8nT9YC6OWl+3/4YZFmzUTCwvT2HXcU23b55Vq4Nm7U7W+9VWTsWN3uwAG7fqSFGHEq7BhmAvHA9jKOBwJzgS3ADuCmyvTraHHKzY2TZcs8ZN66ceL2nJtM/n2yQ+2pbURFicybV7ydm6uH3lJSTm538cX6+QUi77+v9z30ULFglXz17q09pPJYuVI/A48dq9LbMZwphd86fvtNZMYM/T4gQG+DyBtvlH3uzTeL+PvrX/bXX+v2nTtrYbvssuI/iIcf1mLk6qrP+eQT/cfUsKH+A1yzRsTHp1joRLQHt2ZNsbf0yCPF/U2YUDwUuGePFiel9PtCDh7UohQYqM/ZuVMkJkbEz09kxIjThxh/+UWkbVvtwRVS2jDkGWDEqVh8BgE9yhGnqcArtvf1gBOAR0X9OlqcRER27pwoK1b4yX3z7hI1TcnGYxsdbVKtYexY/YW5cLrglVf0X2nTplpARPRzwsND5MEH9XPg5pv1/g4dtGhZLHq6YsECkZdfFjl+3CG3YiiLV18VmTTp9DmkuDj9sB45snjfTz9pb0NEpFMnkSFD9Pv//hMZNEgP/RW+vLx0vyL6j8TXV//xfPih3rdhgxa8Qhf64YeLBaZ//5PnqNasEZk7t+x7sFi0qK1ff/qxXbtE5sw5ff9zz+lrjRhRvK+kGBeybJn2qEBkyhS9z2oVOe88kffeK9umCjDidLIANStHnB4HPgAU0BzYD7hU1KcziFNq6n+ydCmyff8rUu/VetLnkz6Sb8l3tFk1noICPdICIldeqYf8g4P1cH+LFlq03nlH5I8/dJuFC0WGDtVBEdHRUuEX6zrBwoUi339ffddbvlx7KZXl7bf1L0op/Q3j6aeLj73xhpQbyPD449rbOX5cpF07PTc0bFjxa+RI7REV8tlnWozKIi1ND6/9+OM5eyWVIjtb5PbbRbZsKd5XOIzZtKn2+BYt0t5Vu3Yi558v0qSJFsJ586QogucsMeJUeXHyB5YCsUAGMKKcfiYD64H1Hh4eZ/WLqWrWr+8rq1c3l2+2fC1MQ55Z+oyjTarxrFmj/yJ79NA/R43SPzdu1M+R0aP1dsuWIt7e+n/9iSf086rwmVfWc61GEh0tsmnT6futVv2t/tRIkNxcPTTl5qaHjUT0nMv8+fZ5+K5Yob/hK6WDACri++912yuu0Pd29dX6l1Z4bvfuegy2LFatkiIvB/S3lNpA4VxZq1b6Z4sW+vP59lu9vWyZyIUX6nHn3NyzvowRp8qL09XAdJvn1AqIAgIq6tMZPCcRkfj4ObJ0KXL8+Lcy4ZcJ4vKsi6w6vMrRZtVopk3Tz66oqOL5pOuuKz6en6+H90FPIYjooXnQ89BNmlTPF+Bq44IL9Lhl4TxHIb/+KkVzJyX54gu938NDP8yys/UwGIhMnXp2NsTElL6/MICgbVstiL16nW5nSY4c0cNsAwYUh0+npWkv4brrisMv33mn7D4KCor/MEaPPrv7cVYmTdJza6+8UvylIzNTD3MWivGrr57TJYw4VV6c/gTOL7G9BOhTUZ/OIk5Wq0X++6+9rF3bRZKzkqXp9KbS/K3mkpqTWvHJdRSrVX9JLFzucSr9+ukhPBEd5ODtffKcsoge4XjnnWKHonA4D0Ruu81eljuAkjdWONlWyMCBer+ra/EwltWq52Q6d9YfXmEwAOjhoYoe/KVRGFSwbNnJ+7Oz9bf8Ro10IEDhN/yPPiq7r+uuKz0y7ZFH9Hjt2LH6fuLiyrfp1lv1H0ZU1Jndi7NjsZTuFd14o/5s/fz0OPc5YMSp8uL0ITDN9j4cOAqEVdSns4iTiEhs7BeydCmSmPinrIxeKS7PusiNc250tFlOy7JlUrSWyGrVI07XXy/y/PN6raOLi8gzz+i2Vqv+Yl0RVmvxl+mffrKr+dXLSy8VC9CjjxbvLxz7fPJJPSE3eLD+EObP1/u/+EJ7GD17StEkXH6+9jSUOn0+ymrVa3a6dNHDZIWuZ3KyntMB/YAsSeHE/qJFxX1ccIH2pHbv1vtWrtS/mJtuKha50tb0HDlSvOanZKBAWaSklB9OXttYtEh/Ng8+eM5dGXEqFp/vbPNJ+UAMcAtwB3CH7XgjYCGwDdgOTKhMv84kThZLrqxa1UQ2bjxfRESe/PtJYRryw/YfHGyZc/Loo1LkDDz1lPaUSoZ7g04McKYMG6af4ef4xdJ5sFr1JPmAATr8sH374mPXXKOHwtLStKcC+nhYmPZkCr99R0efrNZZWdrj8vAQWbKkeP9PP+k+CiNRLrxQR7Xdd58WswED9Lf2wlj8wpDoa6892eYDB7SYNW2qgzKCgvRwn4eHFM2jlJUNYeJEOSls21CM1Soyc2aV/HEbcbLzy5nESUTkyJG3ZelSJCXlH8kryJM+n/SR4JeD5UjqEUeb5nR06aKnQK67Tv/lubuL/PxzcURvcHD50xZlsXixyPTpVW6u49i4UYpCoAsjPfbt0x6Di4teTCqiP6wpU7RXNHq0noArjxMnRDp21GuB5s3T4daFOaCysvSwX2ioFEXT3XVXsbv77bd66GnECD13dKSUv+/167WQFS5yLUw5dM89OpihLArbVJTqw3BOGHGqY+JUUJAhK1eGytatem3G3sS94vuir1zwxQVisVoqOLvucPSo/mt75RX9HLznHi0qIvrL4fvv6y+IdY7sbB0e/O67xa+RI7XHkZSkH9ygwxLbttUeydGjZ3+9I0dE2rTRfUZG6p///FN8PCVFi9/552sxs1h0pMnw4SL/93+6/Vtvld3/4sV6Ar9kuLTBKTDiVMfESUQkKuo5WboUSU/fKiIin274VJiGvPrPuUXX1HQyMnTaMREtPGCeWUVYrdobadpUisY2S77GjStu27Gj3ufldXpwxNmQk6NdzZAQve6mIqZMKbbr7rtrWUhk3cGIUx0Up7y8JFm+3Fd27NAPFKvVKlfOvlLcn3OXxQcWO9i66ic1VQc5hIZqB+Cff/RQXsOG5rlWxA8/6H+/7t31pHdCwsmvkokAn3lGD+f9+mvV2lBQULlfyM6delLv6qvPbtzV4BTUNHFS2uaag6+vr2SeWhvFCdi///+IiZlOnz478fFpS1JWEhfMuoC9SXv5+dqfGdFmhKNNrDauuw5++EGXsdmzB1JSID9f11GaOdPR1jkBItC7N6Snw86duvpheRQU6LK9zZpVi3mlEhUFTZqAm5vjbDCcE0qpLBHxraDNMOBtwBX4VERePuX4EOA39LpUgF9E5Lmqt9YUG6wyIiMfxcXFm0OHpgEQ6hPK0huX0ql+J678/so6U5wwO1tXlb3zTvjjD12Q1GKB1FQYNszR1tmJ+Hi49FKIjq5c+xUrYMMGeOihioUJtCA4UpgAmjc3wlTLUUq5Au8Dw4EOwPVKqQ6lNF0pIt1sL7sIExhxqjI8POoTEXEf8fHfk5GxHdAC9fcNf9M2rC3jfxnPsfRjDray6khP19Ww587VjkAhS5ZogRo9Wm+3aQNz5sAll9RicVq2TJfl/frryrV//XUIC4MbbrCrWQbDGdIH2C8iB0UkD5gNjHaUMUacqpAmTf4PV1d/Dh16pmhfoFcgP1z9A5n5mYz/ZTwWq8WBFlYNFguMG6erYV9+OXTtqh0B0GLl56fLnxcyeDAsXAgBAQ4xt+rYsgX+++/0/Tt36p9z555+bNOmk8tx796tXcp77gFvb/vYaTCUjptSan2J1+RTjjcGjpTYjrHtO5X+SqktSqm/lFId7WWsEacqxN09hCZNHiYx8RfS0oofYu3rtefDER+y7NAynlzypAMtrBoefVQ/X99+G778EpKSYMIEyM3Vz+dLLwVPT0dbWcWkpWnXb+RIyMo6+VihOK1dC3FxJx8bO1Z/IElJevvxx8HHB+66y/42GwwnUyAivUq8ZpxyXJVyzqlBCRuBpiLSFXgX+NUOdgJGnKqciIiH8PBowP79D1Ey2OSGrjdwe8/befnfl/li8xeOM/AsiYrSAhQZCW++Cffdp18TJ8KMGdohmDQJjh2DUaMcba0dmDYNjh+HxEStyCXZuRNatNDjm3/+Wbx/zx7Yu1cL0xNPwLx58Ouv8NRTUK9edVpvMFSGGKBJie0I4KS5CBFJE5EM2/t5gLtSKswu1jg6XPBMX84YSn4qx459KkuXInFxJ6cxyivIk4u/vFjcn3OXpVFLHWPcWXLxxToxwDXXiHz8sU7XVpLCchZKicTXtsr1W7fqUOrJk3Wepdati0O98/J0qospU/Ri1SuuKD7vtdf0h3L11fqDadhQL6Q9h7IHBsPZQgWh5IAbcBBdX88DXaW84yltGkBRlHcf4HDhdlW/HC42Z/qqCeJktRbI2rVdZPXqZlJQcHJKluTsZGn/XnvxfdFXlkUtc5CFZTNnzsn12kRE/v5b/6W8+WbZ50VF6TWi551nT+scxCWX6EVbiYk6cSoUrznatUtvf/WVyJ136vLehWl4Bg3SOZtSUkQaNJCTkqUaDNVMReKkm3AZsBc4ADxh21cyJ+o9wA6bcK0Bzquoz7N9OVxszvRVE8RJRCQpaZEsXYpERT1/2rFjacek/XvtxfsFb1m4f6EDrCudgwf1F3w/P13gVESv0ezTRzsFFaU+W7ZMl+WpVWRkaK/p8cf1dn6+zuowcKDe/vln/W+0YYPIX3/p93Pm6NRDrq467ZCIyL//inzwgSPuwGAQkcqJkzO9zJyTnQgJuZh69a7h8OEXyc4+eNKxhv4NWTZpGa1DW3PZt5fxyYZPHGTlyXz4Ibi4QKNGMHQoPP20nldauxaeeQa8vMo/f/Bg6Gi32B0HsX69Dk8cOFBvu7npSLt//tFzSjt3glLQrh1ccIGee7rtNh0tYrEUT8Cdd55e/GUwGCqFyRBhR3Jzj7J2bTsCAwfRufMfKHVyMExKTgpjfxrLggMLuL/v/UwfOv20NtVFVhZERMBFF8EHH+hnamHUdLdusG5dHV2D+dJLMHWqDmoICdH7YmP1hzV1Kuzfrz+og7YvIPv2wYABkJAA4eE6QsTFfAc0OJ7KZIhwJsx/jR3x9GxMs2bPceLEPBITfz3teJBXEH+M+4P7+97P2/+9zZTFU6rfSBuzZ0NysnYK6tWD1ashJ0e/NmyoY8KUn1/8ftUq7RUVChNAw4Zw8cV60e327dChxCL61q11VJ6fH1xzjREmg+EsMf85dqZx43vx9e3C/v33UVCQcdpxNxc3pg+dzl297uLVVa8yffX0ardRBN57Dzp1gkGD9D6l9FolT8869nz97z+9WnjePP3BrFqlh+ROZcIEOHTodHEC6NULDh/Wq5QNBsNZUZceOw7BxcWNNm0+IDc3hujo0tNQKaV4Z/g7jGk/hocWPsRTS56q0kwS+/fr6ZHSsFr1VMimTfDAA1qU6iwWi14cm5MD//ufXqN04kTp4nTllXoxLZwuTgDBweDhYV97DYZajBGnaiAwcAANGtxCTMz0orx7p+Lq4so3V33DTd1u4oWVLzDi2xEkZSVVyfXHj9ceUUrKyfszM+HGG+Hjj2HKFLj55iq5XM1lxgydauiSS+Dff/VqYyhdnPz8tEBB6eJkMBjODUeHC57pq6aEkp9Kbm6CrFwZKuvX9xaLJa/MdlarVWasnyEez3tI0+lNZf3R9eV3nJoq8vnnJ9f/KUFSkg4PB5F779X70tJEnnuuuCL3iy+e5U1VxOHDFZcOdxbi43WV2YsuEklP1+9B/yzjs5VNm0SuusqUFzfUCKhhoeQON+BMXzVVnERE4uJ+lKVLkYMHn6mw7dqYtdLkzSbi+bynzNo8q+yGb7+tf40LS18vVbgMp18/Xa/u009FWrbU+0aNElm1qpLGZ2eL7NhRycY2brxRX+hcyopXNYcO6VLlp/LCC9rWwnssrP46fHj12mcw2ImaJk6VGtZTSt2vlApQms+UUhuVUpdWcM5MpVS8Uqr0cSzdZohSarNSaodSavmZ+Xw1j/r1ryY8fALR0S+Qlra23La9G/dm4+0bOa/Jedz4641M/XsqVrGe3nD9ev3zq6+Kdh08qKdPAP7+W49A/fYbhIbCrbfq2nUrVsDvv0P//pU0fvp06N5dF2aqDBZLcZ65P/44/Xh29sm1NgoR0Rlk7UFysi7y17KlrveRnFx8za++0mOfhUN0996r55Quusg+thgMdQCl1JVKqcAS20FKqSsqdXJlFAzYYvs5FPgd6ApsrOCcQUAPYHsZx4OAnUCkbbt+ZWypyZ6TiEheXrKsWhUha9a0kYKCzIrbF+TJ5N8nC9OQAZ8NkHl754m1ZGnt9u31N3xfX5GMDFm6VA/jPfigPtymjciIEfr9/Pl6f3LyWRh+6aX6OqtXV679v//q9iAycuTJxw4dEgkMFHnjjdPPe+45kchIkaysszCyAu6+W7uP11yjP6S2bbVHuG6dtnPGjJPbx8efnkTQYKih4ADPCdhcyr5NlTq3khfYavv5NnBlZS8ANCtHnO4CXjjTm63p4iQicuLEYlm6FNm7955KtbdarfLJhk8k4s0IYRrS/9P+cij5kJ4bUUrkwgtFQDI+/lqaNNG/VQ8PkX/+kQpz4lWKggKRgADd2WefVe6cKVNE3NxEJk7USfcySwjxFVfovho0EMnJOfm8wYP1sY8+Ojeb8/NFPvxQpHt3kUcfFVmyRAtT4cTbH3/o6zz/vMj99+sP7KxU22CoGThInLaWsm9bpc6t5AU+BxYC+wAfwB/YUInzyhOnt9AlgZcBG4AbyulnMrAeWO/h4XFOvyBnYd++B2TpUiQpaUGlz8ktyJVPN3wqAS8FSPDLwfLP1y/pX+Hvv4s1MlI2NRwmrq4iP/0k4umpk2CDyJYt52js1q1S5AU9/HDlzunYUeSCC/RcmM1GERH5808pmssBHcxRiMUi4u+v97dpU3YgQkXs3l3sUbZrVxwRUr/+yQJ0zTVaOENCRMaMObtrGQw1BAeJ00zgTaAl0AKYDnxRqXMreQEX2xBdkG07BOhSifPKE6f30FltfYEwm/C1qajP2uA5iYgUFGTJf/+1l3//bSA5OcfO6Nz9Sful+0fd5f6hWjCuPO+IvOI2VQpwkdf/L1ZE9PAdiNSrV4lnvNWqvYzjx0s//vHHurOQkLIDBPLzRb77TovPgQNS5LLl5mrBue02kWPHdDRG27baY+rcWaRTJ319ES0qUDyE+Ntvp18nO1vkk09OzjC7ebPIzJn6WkeP6mHBevV0AlarVWTjRi1Ef/xxcl9Hjujh0JJZxg2GWoqDxMkXeLnQuQD+B/hW6txKXmBAYYfABJsSNq3EeeWJ0xRgWontz4BrKuqztoiTiEh6+lZZvtxHNmwYIBbLmdX4ycnPkY0XdZQYt2BRHhly95W6roXl2edERE+X+PuLjB9fic6WLdN/CqNHl378xhv1w/7663VG7pJYrfqhX+ipQLHLtm+fbnP11doYX19d+2jJEr3/iy90u/nz9fY330hRhu/ISJ35u1BZLRaRb7/V14fiukhZWSLNm+t9LVtqO/z8dB+V4f33dVkLU2PJUMtxhDidy6uy4rQVXcK3q+39/cDySpxXnji1B/5GF7jyAbYDnSrqszaJk4jI8ePf2eaf7j3jc3NbtJPfuFxCLv5EmIZs6dlEcsOCJTUlTkRE9uzRJYgq5JZbioXlVO9CRBfXGz26ONw6PV3v37ixaL5LWrfWcesffaSHz3r0KD7/p590m6uvFtm/v8QN5GohGzVKbz/4oB5my88XeecdfU7Pnnqeq3dvvd2tm54nApGXXhJ5+uni9x076rkjUzPJYDgNB3lOiwpH3GzbwcCCSp1byQtstP18Gril5L5yzvkOiAXy0eV/b6FE0Spbm0fQEXvbgQcqY0ttEycRkX37HpKlS5HY2C8rf1JamlhQMs31WTkQnSWPLHxELrpRz63cOgq5Y+4dkpGbUXE/2dk62OH667XX0bz5yZFy8fH6z+SVV/SCWtDRbXv3ai8oNFTk3Xd1RdiSfRYKWCEJCaVf/5FHdOBEfLwuztevn95vsYh8+aVIRIS+ZuPGIrNmFXtSV1yhC/t5eoqMG6f3FRSUfR2DoY7jIHHaVJl9pZ5byQssBx63zQs1AFypZMRFVb9qozhZLPmyadMQWb7cS9LSNpbb9o8/RJ58UmTps8tFQN4ZVuzpHE+LlZQOLSU2IlhcnkbavttWFuxfIBZrOZNOP/yg/wwWLSoueevrq0O9L7xQh3aDyMqVxXNCs2bpInouLjoLxLmwZYvu85139HDcPadEMGZladsyTwm7j4oS8fbWw4XOtMjXYHBSHCROG7AtF7JtN6vIsSl8Vaqek1KqATAOWCciK5VSkcAQEfmywpOrmJpUz+lMyMuLZ/36Hri4uNOjx1o8POqd1mblSr0mND8fHmA603mIqFWxNO/foLjRN9/AhAkc+L9buTj8L9Ljj/K/DUE06zaYrs9+TLhf+Mmdjh6tF/IePgyurnox6oYNeqXuDz/oukTu7nrxrbu7Xpj6wAPw44/Qpg0sWHDuN9+1KyQm6tpHn38OkyZV7rxFi3Ry1cGDz90Gg6GW44h6TkqpYcAMtIMDev3rZBGp8MFR6WKDSqlwoLdtc62IxJ+FredMbRUngLS0tWzePBhf365067YEV1efomMHDkDfvjrLw99/g9eYy/CJ2YvP0f0nd5KfDyNGwKJFWFu3ouD4MTzSs8hwh8aPuTKq+1heu+Q1Gvo31ILQsKEWm9deK80gXfbB3R2efFLv69xZF96LjdVCNmHCud/4a6/Bo4/q91u36msYDIYqxVHFBpVS9dHLgTYDXkC8iKyo8MRKumbXAtHALOBLIAq4urpdRKmlw3oliY//Rb77rqkEBqbK6NFWWb5c5LXXRMLDdST33r0ikpGh51oeeKD0TqxWHRrdu7fI5ZcXhYJ/9egw8XzeU4JeDpJPNnwiBffdq9cAlQzLrohrr9XDcD4+p88rnS0xMdoOb2+TkcFgsBM4ZljvVmAbkAwsBbKBJZU6t5IX2EKJ9EJAPWwpjar7VdvFSUTkiSdWCogEBGQWBdFddFGJ6Og5c/TOv/+uXIcWiw7BHjZMdifslvNnni9d7kAKFLJudG+Zu2eubD2+tfy5qUKefVZfe8KEs7y7Mhg1SmTo0Krt02AwFOEgcdpm85Y227bbAd9X5tzKFt92kZOH8ZIwtaDsxuLFA+nU6QivvNKB3btnM3DgCPr0KdFg7lwIDITzz69chy4uuqjTyy/T1hLEshuWkPJeF9L99nNp23UkfzcKgMFNBzNj1AzahLYpu6+uXfXPiRPP7ubK4scfq7Y/g8HgDOSISI5SCqWUp4jsVkq1rcyJlRWY+UqpBUqpSUqpScCfwLyztdZwMnFxOms4QEyMrhR+/fWNadp0BD16jKRp0++KG1utOtv3sGF6LqiyTJigz33rLVxuupmQjbsIevtjdj11nDW3rOGdYe+wJW4LXT7swn1/3cem2E0AJb8BaUaN0oX4Li03Kf2ZU1gT3mAw1CZilFJBwK/AIqXUb8Cxypx4JgERY9CZIhSwQkTmnJWp50htDIi47z54910dHBcbC/ffr8uqt2qVy5YtQ0lLW0WfedfjTQO44AIYPhy+/lp7Q2dCr146Es/DAx58UJcidyn+fhKbHstjix/j+x3fk2fJw83FjQJrAW1C2/DVlV/Rp3Gfcjo3GAzOjKMCIkpcfzAQCMwXkbwK21dWnJyF2iZOItC8OURHQ3AwNGmiHZxt2/Tx/Pxkdv3Smy5jDxSf5OoK8fEQEnJmF1u4EObMgUcegRYtymx2IvsEP+74kejUaNxc3Phyy5ccTT/KXb3uKhKsh897mMjAyLO4Y4PB4AgcLU5nSrnipJRKB0proAARkQB7GVYWtUGcdu/Wy4UiI7UIdemi9eL99yErC555BqZNK25fcPP1qG9ms+v1YNr91RW3Jm3g44+rzd6UnBQmz53Mjzt/xMfdB4vVgre7Nx+N+IhrO16LUqrabDEYDGdHrRInZ6Smi9PmzTBwIDRoALt26SU+Tzyh15/OmwdT7zjBsq0htG9vOyEuDiIjyZ9wBWtvXo5Siq5dl+Lr267abc8tyMXTzZMDJw4w/pfx/Hf0P+r51KNP4z70adyHvo37MiByAH4eftVum8FgKB8jTnamJotTbCz06aPXtqalwUcfwRdf6Irma9cCTzyBvPwyasECuPhifdLTT8MLL8CuXWRGWNi8+QKUcqFbt2X4+FQq6MUu5Fvy+WrrV6w8vJL/Yv5jd+JuBMHX3ZfrO13P6HajaeTfiMb+janvW994VwaDg6mMONkyOryNTlH3qYi8XEa73uiSR9eJyE9VbixGnKoNERgwQCdAWLkS7r5bZ31ISIBnn4Wngt7VkRHu7noSautW7U717KlDxm3hfJmZO20C5Uq3bksdKlAlSc1JZe3RtXy3/Tu+3/E9WflZRccCPAPoUK8D/Rr34/ym53NZ68vwcvNyoLUGQ92jInFSSrkCe4FL0Mm61wHXi8jOUtotAnKAmUacbNRUcVqyROfFmzEDbrsNli+HIUPAmywO3PkGDT96Bq64Am69Vacfevhh+P13nWJo1SpoVzyMl5m5g82bL0QpF7p0mY+fX1eH3VdppOemsz1+O3GZcRxOPcyexD1si9/GumPryCnIob5vfe7qdRc+7j7sTNxJem46LsqF/hH9ub/f/bgos4TOYKhqKiFO/dE19obath8HEJGXTmn3ALraRG/gDyNONmqqOF11FaxYodcxedmchkf7reCh9eNoYDkKV1+tc9V5ecGYMfDLL+DtDYsXw3nnndZfZuZOtm4dSkFBGp06/Upw8AXVfEdnTp4lj+WHljN9zXT+2v8XAA39GhLiHUJOQQ4Hkg8wrNUwvr7ya0J9QgG9zio1N5UgryAHWm4w1HyUUnnojA2FzBCRGSWOXw0ME5FbbdsTgb4ick+JNo2Bb4EL0QVi7SZOlc0QYTgHDh/Wo3KPPlosTAAveT8H9YHZy2HQoOID06fD8eMwdWqpwgTg69uB7t1XsXXrcLZuHUb79l9Rv/619r2Rc8TD1YNLWl7CJS0vISYtBl93X4K9gwEtQjM2zOC++fcR+VYkHet1JNQnlA3HNpCQlUDPhj2Z1G0S13e6vki4DAbDGVEgIr3KOV7axPCp3stbwGMiYrH3PLLxnKqBqVPhlVfg4EFo2tS2s6BAL2y68UZ4772z7js/P5nt20eTmvoPrVq9RUTEfVVjtIPYGLuRLzZ/wa7EXcRnxtO9QXdaBLfg192/sun4Jtxd3BnVdhThvuEcSTtCkFcQFze/mBbBLdh/Yj8nsk/QNqwtnep3IjIw0gwRGgw2qmJYTykVRbGIhQFZ6BIYv1a5vUac7Etmpo5vGDBAr38tYvNm6N5d118aN+6crmGxZLNr13gSE+fQpMljtGjxUq2Mjtsat5VZm2fx7fZvybPkEREQQWx6LAlZCaW293X3pWP9jgyKHMTQVkMZGDnQBGIY6iyVECc3dEDERcBRdEDEOBHZUUb7LzBzTsXUNHG64w4dBPHPP6eM0H3wgQ7Zi4qCZs3O+ToiFvbtu5djxz4kPHwibdt+hovLGeTeq6FYxcrWuK3EZcTRKqQVQV5B7Enaw/b47eyI38HmuM2sPrKafGs+3m7eDG42mKEthzK05VDiMuN4YcUL7EzYyeSek7m3z71myNBQa6lkKPll6KE7V3Qk3otKqTsAROSjU9p+gRGnYmqSOM2dC5dfrrM/vPrqKQcnTtTBDseOQRV5OSLC4cP/IyrqSfz9+9C+/Tf4+LSqkr5rMhl5GSw7tIyFBxay4MAC9ibtLTrWwK8B3Rp0Y/7++bgoFwI8Awj2CubC5hcypv0YBkQOIMCz2hOhGAxVjlmEW9ixUjOBkeiqh53KaXdGi7lqijgdP67TEjVuDGvWgKe7VQc6DBmi1y61bAndusHPP1f5tePjf2Lv3slYrXm0bfsJ4eHXV/k1ajKHUg6x8MBCXJUr47uMx8vNix3xO/hhxw8k5yRzLP0YCw8sJD0vHYAmAU0Y1HQQ13W8jr4RfbFYLbgoF4K8gvB0M5nUDTUDI06FHSs1CMgAvixLnM5mMVdNEKfsbK1B27frzA8dO4hetzR9up6AWrJE/3z9db3fDuTkxLBr1zhSU1fSvPlLREY+VivnoexFbkEuSw8tZVPsJrbFb2PBgQWcyD5xWjtvN29CvEPw9/QnMy+TtNw0wnzCaBrUlMFNB3Nj1xtpGtS0lCsYDNWLEaeSnSvVDD0mWZY4PcAZLuZydnGyWuH66+HHH4Qlr29kSN9sWLQInntO12CaP1/nMFq7Vi+u7d/fjrbksnv3JOLjZ9Oo0R20avU2Li4edrtebSbfks/ig4s5kHwAdxd3LGIhOTuZ5JxkkrOTSctLw8/DD38PfxKyEjhw4gDrj60HoFVIK/w9/fF09STXkou3mzcj24xkaMuhHEk7wp7EPTQNakrPhj0J8wk76bonsk+wJ2kPAENbDjVfMAxnjRGnkp2XI05nsphLKTUZmAzg4eHRMzc31242nytvvaVLJf064SdGf31N8YHrroNvv9U1mGbP1jWV0tLsXmBPxMrBg1M5cuQVAgPPp2PHH/HwCLfrNQ2a6JRovtzyJTsSdpCel06eJQ9PV0/iMuOKhOtMGBg5kPcve58u4V3sYK2htmPEqWTn5YvTj8AbIrLmTKI+nNlzOnYM2raF8wcKfyb1RaWk6Kg8T08dqufqCkeP6lREXbroirLVRFzcd+zZcwtubkG0aTODsLCR1XZtw+lEp0Tz75F/aR7UnHZh7TiUcogNsRtIz00/qZ2/pz9tQ9uyJ2kPUxZPISk7iTCfMNqHtefiFhczqs0oGvo3JN+ST2JWIkfSjhDgGcDAyIHkFuTy+qrXmbd/Hm9c+gYDIwc66G6dg9/3/M5H6z/i2zHfVmvGERFh34l9RAZGVriUYUnUEv7a9xcP9HuAxgGNi/ZbrBYOpRzC082TiICIs7LDiFPJzssXp7NazOXM4jRunM46dODzFTQeNxg+/FDHkp/K6tXg5wedO1erfRkZW9i1ayKZmdsID7+BVq3ewt09uFptMJw9SVlJfLX1K3Ym7GRL3BbWHV2HlFpuDUK9Q3F3ded4xnFCvUNJyUnh8YGPE+AZwI6EHVjEgrebN95u3ni5edE6tDWj2owi3C8ci9VCRl4G/p7+Jy1iLrAWsOzQMvw9/OnRsAcxaTHM2DCD7IJspgycQgO/BqTnprPqyCrCfMJoEtiEIK8gPFwdP5R8NO0onT7sREpOCtd2vJbZY2ZX6RCpVax8teUr5h+Yz8Hkg7i5uHFXr7vo1qAbDyx4gMUHF+Pl5sXAyIH0aNCDNqFt2JO0h/n75+Pu6s6Y9mOITolmxkadTcjX3Zd7+txDUlYSa4+tZU/iHnItuUwZMIWXLn6pAmtKx4hTyc4rmHMq0e4LarjntHQpXHihrVDgptF6Pik6WlcVdCKs1jyio18gOvp/eHjUp02bjwkLG+VoswxnQVxGHAsPLCQjLwN3V3dCvEOICIjgSOoRft71Myk5KTxx/hN0Du/M7X/czuztswFo5N8IT1dPsguyyc7PJrsgmzxLHgpF44DGHM84ToG1ABflQphPGF3Cu9A6pDVz984lJi0G0A/PrPwsXJQLLsoFLzcvhrUaxrx988jMP/n/09vNm6s7XM3LF79MI/9GJx0TEXYk7GBH/A5GtBlRYS2w2dtns/zQch4+72FahVRumYSIMPyb4aw8vJIbu97Ih+s/5IPLPiDQK5Bfd/9K5/qdubzt5QjCzoSdhPmEMbjp4KJIzLiMOGZumsnfUX/TPKg5bcPa4unqiSD4uPvg4erBu2vfZf2x9UQGRtI2tC0xaTHsStwFQKBnII8OeJT4zHiWHVrGrsRd5FnycHdx5/ym55OVn8WamDW4KBce7v8wN3a9kalLpvL7nt8J9gqmb0RfOtfvTLuwdvSP6E/7eu3Lu90yMeJU2LFS3wFD0F5RHPAM4A7ntpjLGcUpPx+6doWcHNj5y268urc/vZytk5GevpHduyeRmbmNpk2fpFmz58xkey1GRNiVuItw3/DTFhqLCNvitzFn1xwOJB8gIiCCEO8QUnNSOZZ+jM1xm9mZsJPzI89ncs/JiAgrolcQ4h3CbT1vIzs/mwcXPMg/h/9hTPsxXNfpOrLysziSeoTU3FRi0mL4fPPnuLu4M7TV0CIBSs9NZ2fCzqKAjxDvEO7tcy99G/elkX8jErMSiUqJooFfAwZGDuT1Va/z4soXAXBVrozrPI6+jfsSERDBnqQ97ErcRdvQtlzY/EIy8jJYE7OG6JRoDqcdZv7++bw3/D3u6HUHl3x1CUsPLQWgvm99EjITTvNAfd19aRvWlrTcNKJTosm35tO5fmdiM2JJzEo87fNt6NeQ1y55jXGdx6GUwipW5u+fz/pj65ncczIN/BoUtS2wFhCdEk193/r4e/oDcCT1CAXWApoHNy9ql5SVRIh3SJX9XxpxsjPOKE6vv64X2v71XQrD/jcIDh2C/fuhfn1Hm1YuVmsee/fexfHjn9GgwSTatPnYRPMZ7MKBEwd4YskTbIvfRmZeJoIQ4BlAY//GjG47mjahbXj7v7eZu3duuf3c2v1Wnhr8FK/9+xpfbv2StNy0omP1fOqdlsqqvm/9okXV7132Hi7Khdj0WF5f9TrDWw/nwuYXEp8Zz4L9C/Bx96F9vfYcTj3M3D1ziU6NJtArkKaBTZnUbRLtwnTZmuTsZCxiQaHIys8iLTeN5sHN8XF3rlGSUzHiZGecTZxiYnR8w9DBOfycMVTPJ/35J1xyiaNNqxQiQnT0cxw6NA0fn3a0avUWISFDHW2WoY4Smx5LVEoUx9KPEeodSrOgZkSnRrM0aiktgltwQ9cbijwJESE2I5bDqYdpHdKaUJ9QjmccZ0X0CgI9A+nTuE9R1nuDESe742zidNNNOjI87srbCfhuBnz3HYwd62izzpikpD/Zv/8BsrP3ExY2htat38PTs0HFJxoMhhqBESc740ziJAINGsBdPdbwzPz+8NBD8MYbjjbrrLFaczly5A0OHXoOV1dfWrV6m/Dw8WYuymCoBRhxsjPOJE4HD0LrlhaON+lDPctx2L0b/P0dbdY5k5m5mz17biYtbTUhIZfRps1HeHk1cbRZBoPhHKhp4mQqsZ0Dq1fDZGZQ78hGePPNWiFMAL6+7ejefSWtWr1FSsoy/vuvNXv23E5W1j5Hm2YwGOoIxnM6B+69R7j/gza07B+O+mdllZW+cCays6M4fPhljh+fhUgBkZGP0bTpU7i6mqJ9BkNNwnhOdYhjy/bQSvajxl1fK4UJwNu7OW3bfkz//tE0aDCRw4f/x/r13UhNrb7USwaDoe5hxOkMKCiAm2+G//6DrCxotcu2JmNU7c+w4OERTrt2n9OlywKs1hw2bTqfvXvvIT8/ydGmGQyGWogZ1jsDli2DCy7Q65refRc8LhlE1+ZpBB7c7BB7HEVBQQZRUU9w9Oi7uLh40aDBjTRp8hje3s0cbZrBYCgDM6xXi5k7F1xcdFDelNuSGMC/uF1Z+72mU3Fz86N167fp3Xs79euPIzZ2JmvXtuXAgUfIz092tHkGg6EWYDynSiICbdro6ure3uD769d8zUQ9xtenT7Xb40zk5MRw6NBTHD8+C1dXPxo1upOIiAfNIl6DwYmoaZ6TEadKsns3tG8P770HI0bA+lbXcbHHCoIyjmp3ykBGxlYOH36J+PgfcHHxIjLycZo0eRhXV29Hm2Yw1HlqmjiZp2olmWuLfRg5EpoFpXCl5zy8rh5lhKkEfn5d6NDhO/r02UNIyHAOHXqK//5rycGDT5CVtd/R5hkMhhqE8ZwqyaBBuqr65s3Aq6/CY4/Bpk3QrVu121JTSElZzuHDr3LixHxACA+/gebNX8DL6+wqeRoMhrOnpnlORpwqQXQ0tGgBU6fC80/lQfPmeoxv8eJqtaOmkpt7jJiYt4iJeQelFOHhNxIRcR++vh0cbZrBUGeoaeJkxqQqYM4c6NEDPD11GXa+/x6OHYOHH3a0aTUGT89GtGz5Kn377iE8fALHj3/BunUd2bJlKElJfyFidbSJBoPByTCeUzn8+itceaUWp2++gXatLXqjoAC2b6+1WSHsTV5eArGxMzh69H3y8mLx8WlHRMTDhIdPMGmRDAY7UdM8JyNO5TByJGzdqovaergL3HMPfPCBVqpx46rFhtqM1ZpHQsKPHDnyOhkZm/H0jKB58xcJD5+AUsapNxiqkpomTuYJUAaJibBgAVx/PXh4AC++qIXpkUeMMFURLi4ehIePp2fPjXTpshB393B2776Rdes6Ex39EtnZBx1tosFQp1BKDVNK7VFK7VdKTSnl+Gil1Fal1Gal1Hql1EC72WIvz0kpNRMYCcSLSKdSjo8HHrNtZgB3isiWivqtLs/po4/gzjt1dF7XtJU6XG/iRPjiCxM+bidErMTHf8fRo++RlrYGUNSrdy3Nmj2Fr29HR5tnMNRoKvKclFKuwF7gEiAGWAdcLyI7S7TxAzJFRJRSXYAfRKSdXey1ozgNQovOl2WI03nALhFJVkoNB6aJSN+K+q0ucRo0CJKSbFNLl4+CNWvg8GGdHsJgd3Jyojl27COOHn0PiyUDL6+WBAaeR1jYlYSGjsDFxcPRJhoMNYpKiFN/9HN4qG37cQAReamc9jNFpL097LWbCyAiK4AT5RxfJSKFidjWAE6z+OXwYVi5Uo/eqd274I8/9HyTEaZqw8urKS1avETfvlG0bPkGfn5dOHHiL3bsuIpVqxoRFfUUBQWpjjbTYKhJuNmG4gpfk0853hg4UmI7xrbvJJRSVyqldgN/AjfbzVh7dXyG3AL8VdZB24c4GcDDw/7fmL/6Sv+8/nrg5eng5QV33WX36xpOx8MjjCZNHqJJk4ewWgtITl5EbOwnREe/wNGj79Ow4S0EBAwgKOh83N1DHW2uweDMFIhIr3KOlxZ+fNrQmojMAebYRseeBy6uIvtONsae0XpKqWbAH6UN65VocwHwATBQRCosDmTvYb3UVL3gtk8f+OuLOGjaFCZN0pNQBqchPX0jUVFPk5y8EJF8lPKgfv1radToTgIC+qNMmL/BcBJVPaxnaxMF9BaRxKq216Gek21C7VNgeGWEqTp44w04cQJeejZPB0AUFMCDDzraLMMp+Pv3oEuXP7BYcsjI2EB8/A8cP/45cXFf4+kZSb16Y2jQYBJ+fl0cbarBUFNYB7RWSjUHjgJjgZNCk5VSrYADtoCIHoAHYJdnt8M8J6VUJLAEuEFEVlW2T3t6TvHx2msaeZmV2e4T4dtvYeZMuOkmu1zPULUUFKSTmPgLCQk/c+LEAkTy8PfvTVjYFQQHX4K/f0+zfspQZ6nMOiel1GXAW4ArOtjhRaXUHQAi8pFS6jHgBiAfyAYeEZF/7GKvHaP1vgOGAGFAHPAM4A5FN/kpMAaItp1S0XgoYB9xOngQfv5Zv9avE+InPkzIrOnwv//B449X6bUM1UN+fhJxcd9w/PgsMjI2AuDl1YKGDW8jPHyCST5rqHPUtEW4dT5DRGoqtGqlF922aQMz27/GgN8ehfvug7feMimKagF5efGcODGf48c/JyVlGQB+ft0IDR1JaOhI/P17G4/KUOsx4mRnqlSc3nyT/747wPr1MOYqaOCXAV9+Cdddp4f0zGLbWkdW1l4SE38lKekPUlP/Bay4uYUSGDiQoKDB1K8/Fk/Pho4202Cocow42ZkqE6eoKGjRgjT8wcOTgADb/iFD4OuvdRpyQ60mP/8EJ04sIDl5Iamp/5KdvQ9wJSxsFPXqXUtIyHDc3YMcbabBUCUYcbIzVSZOn30Gt95KJ7WDn3Z2oJ1dEnAYahJZWfuIjf2U48dnkZ8fh1JuBAUNITR0NGFhl+PlFeloEw2Gs8aIk52pKnHKv248ST/8zdRJscz83MwrGYoRsZCW9h+Jib+RmPgb2dl7APDz605Y2GhCQ0fj59fVrKUy1CiMONmZKhEnEXLDGvHziQsIW/Atl15aNbYZaidZWXuKhCotbTUgeHk1Jzx8AuHh4/H2bmOEyuD0GHGyM1UiTrt2QYcO3O7yCW+k3oqfX9XYZqj95OXFkZT0B/Hx35OcvBgQ3NyC8ffvSf3646lf/zpcXU0ORoPzYcTJzlSJOL3/PtxzD2O6HeDnTS2qxjBDnSMnJ4akpD/IyNhESspysrP34OYWQlDQBfj79yAk5DL8/bs52kyDAah54uQsiV+rlYKFS4ihKa0vbe5oUww1GC+vCBo3vgMAESElZRmxsZ+RlraGxMSfiYp6Aj+/HtSvfy0BAf3x9++Fq6uPg602GGoGdc9zslrJDwrjq/QraPTXTIYNqzrbDIZC8vOTiI+fTWzsp2RkbAZAKU+Cgy8mNHQkgYED8PXtgK7vZjDYn5rmOdU9cdq2Dbp0YZKaxbupN+DvX3W2GQylkZeXQHr6WpKTF5OY+Cs5OYcAcHUNICTkUkJDRxESchkeHmGONdRQq6lp4lT3hvV27AAgr2N3I0yGasHDox6hoSMIDR1By5Zvkp29n7S0NaSmriAp6U8SEn4CXAgI6E9w8MUEBZ1PQMB5JrDCUKepc+KUv2UnLrjQ9JI2jjbFUAdRSuHj0xofn9Y0aDARESvp6RtJSppLUtIfREc/R3S04OYWRHj4jTRqdDu+vnapgm0wODW1YlgvPz+fmJgYcnJyKjzfGpeAJSeP/HqN8TFz03h5eREREYG7u7ujTTEABQWppKb+Q1zc1yQk/IxIPoGBg6lf/1pcXX1xdfUjJGS4CawwnDE1bVivVohTVFQU/v7+hIaGVrgY0rJ1O2l5Xri3a1Xn1zeJCElJSaSnp9O8uYlcdDby8uI5fvwLjh37mJycg0X73dxCaNTodho2vAVv75YOtNBQkzDiZGdKE6ddu3bRrl27ilfpW63Ixo0cpyHBnRrj5WVHQ2sIIsLu3btp394MHTkrIlZyc48iUkBOThRHj75HYuKvgBAQ0J+wsNEEBV2Iv38PE/1nKJOaJk61Zs6pUuljcnNRQDZe1Ks1d35umLQ7zo9SLnh5NQHA27s5wcEXkpNzhPj474iL+5aDB6cA4OoaSFDQEIKDLyYkZCje3q3M79dQY6lbj+jsbABy8MbVfME01GC8vJoQGfkokZGPkpcXR3LyElJSlpCc/DdJSb/Z2jQnJGQoISHDCAq6EDc3E55qqDnUrWp6OTkIUODmWaUFblNSUvjggw/O6tzLLruMlJSUqjPGUOfw8AgnPPx62rb9hH79DtKnzz5at34PX99OHD/+Fdu3X8G//4awadNgoqP/R3r6RkSsjjbbYCiXWjPnVKk5kwMHyE/NYo9HZzp1qjqbDh06xMiRI9m+fftpxywWC65O7qZV+vMz1Dis1jxSU1eRnLyAEyfmF2Wr8PBoaCtTfznBwReZNVV1ADPnZEMpNRMYCcSLyGlSoPRg+NvAZUAWMElENp7rdR94ADZvLuNgZgMsosh14YzCyLt1g7feKvv4lClTOHDgAN26deOSSy5hxIgRPPvsszRs2JDNmzezc+dOrrjiCo4cOUJOTg73338/kydPBqBZs2asX7+ejIwMhg8fzsCBA1m1ahWNGzfmt99+w9v75IfG3LlzeeGFF8jLyyM0NJRvvvmG8PBwMjIyuPfee1m/fj1KKZ555hnGjBnD/PnzmTp1KhaLhbCwMP7+++/K37ihxuPi4kFw8BCCg4fQosVL5OYeJzl5IUlJc23plT7BxcUbf/8+eHu3xN+/J+HhN+DmVsdDWQ0Ox26ek1JqEJABfFmGOF0G3IsWp77A2yLSt6J+K/KcyhYngfQM8pUHBa6eeJ/BF8WKxOlUz2nZsmWMGDGC7du3F4VonzhxgpCQELKzs+nduzfLly8nNDT0JHFq1aoV69evp1u3blx77bVcfvnlTJgw4aRrJScnExQUhFKKTz/9lF27dvHGG2/w2GOPkZuby1s2Q5OTkykoKKBHjx6sWLGC5s2bF9lwKsZzqptYrbmkpCwnKWku6ekbyc4+QH5+HG5uwTRseCsBAefh59cNL6+mJrCiFmA8JxsiskIp1aycJqPRwiXAGqVUkFKqoYjEnst1yxSRnFzYvofDrs2wBnvSrDzLqoA+ffqctHbonXfeYc6cOQAcOXKEffv2ERoaetI5zZs3p1u3bgD07NmTQ4cOndZvTEwM1113HbGxseTl5RVdY/HixcyePbuoXXBwMHPnzmXQoEFFbUoTJkPdxcXFk5CQSwkJKa62mZq6hiNHXuXIkTeA1wAdBejn15WQkEsJC7vKZKwwVAuOjNZrDBwpsR1j23dO4lQmtki9TIs3/tVw176+xV9Qli1bxuLFi1m9ejU+Pj4MGTKk1GwWnp6eRe9dXV3JttlcknvvvZeHHnqIyy+/nGXLljFt2jRAr1c69dttafsMhvIIDOxHYOAvWCyZZGRsIzNzCxkZW0hPX0dU1JNERT2Jl1dzgoMvIijoIoKDL8TDo76jzTbUQhwpTqU9NUsdY1RKTQYmA3h4eJzd1by9sTaOIPuoF8FVfNf+/v6kp6eXeTw1NZXg4GB8fHzYvXs3a9asOetrpaam0rhxYwBmzZpVtP/SSy/lvffeO2lYr3///tx9991ERUWVO6xnMJyKq6uvTaj6Fe3LzT1KYuJvnDixkPj4H4mN/RQAX9/OBAdfRHDwxQQGDjIh64YqwZGh5DFAkxLbEcCx0hqKyAwR6SUivdzczlJZvLzID2mAFVfOtouyCA0NZcCAAXTq1IlHHnnktOPDhg2joKCALl268NRTT9GvX79Seqkc06ZN45prruH8888nLKy4xMKTTz5JcnIynTp1omvXrixdupR69eoxY8YMrrrqKrp27cp111131tc1GDw9G9O48V107vwrAwYk0qPHfzRv/j/c3etx9OiHbNs2kn//DWHDhn7s2jWJQ4eeJzn5byyWinNeGgynYtdQctuc0x9lBESMAO6hOCDiHRHpU1Gf5xJKnpkJu3ZBq1YQFFSpW6gTmIAIw7lisWSTlraK5OS/SU39l+zsA+TlHQXAxcWLgIABBAdfRGDgQPz8uptoQAdQmYAIpdQwdBS1K/CpiLx8yvHxwGO2zQzgThHZYg977RlK/h0wBAhTSsUAzwDuACLyETAPLUz70aHkN9nLlkIKCvTPqvacDIa6jqurt21o76KifQUF6aSmriA5+W+Sk/8mKmqq7YjC17eTrXbVEHx82uPl1RwXF/OP6UiUTsz4PnAJemRrnVLqdxHZWaJZFDBYRJKVUsOBGWjnosqxZ7Te9RUcF+Bue12/NPLz9U8jTgaD/XFz8y8qsgg6y3p6+jrS0zeQmrqSo0c/ICZmOgBKuePt3Rofn7Z4e7fE27sVAQH98PXtjFJ1K5GNA+kD7BeRgwBKqdnoqOoicRKRVSXar0FPx9iFOvWYNp6TweA4PDzqnyRWFks2GRmbycraQ3b2HrKydpOVtYukpHmI5ALg7l6fwMDzCQjojb9/H/z9e+LmFuDI26jNlBZBXZ5XdAvwl72MqVOP6UJxcvJsQgZDncDV1ZvAwP4EBvY/ab+IlZycw6SmLufEiUWkpa0mMfFn21GFl1dTPDwa4OkZgb9/bwIC+uPv39MUYKwYN6XU+hLbM0RkRontM4mgvgAtTgOr0L6TqHPi5O5OlSZ9NRgMVYtSLnh7N8PbuxkNGtwIQH5+Eunp60lLW0tW1m7y8xNIT99EQsJPtnPc8PXtSmBgf5tY9cbbu6UZEjyZAhHpVc7xSkVQK6W6AJ8Cw0UkqWpNLKbOiZMZ0jMYah7u7qG28h9DT9qfl5dIWtoa0tJWk5a2mtjYzzl69D0AXF0D8PZuibt7KD4+HWjc+C58fNo6wvyawjqgtVKqOXAUGAuMK9lAKRUJ/AJMFJG99jSmTj2qnUmc/Pz8yMjIcLQZBkONxsMjjLCwkYSFjQTAai0gM3M7GRkbSE/fSE5ONAUFSRw79jFHj76Dn18PCgpSsVhS8fPrTmDgALy8WuDh0QBv79Z4eUXWWW9LRAqUUvcAC9Ch5DNFZIdS6g7b8Y+Ap4FQ4ANb9pmKvLGzpk6VzNi+Hby9oWVLe1lXeZxJnMw6J0NtJy8vnmPHPiQlZTkeHuG4uPiSnr6OzMxtlJxWcXHxJTDwPMLCriAoaDDu7mG4uYXg4uLuOOOrCJP41dGUUzOjWYbNc/I6wz4rSEv+2GOP0bRpU+666y5AZ3Hw9/fn9ttvZ/To0SQnJ5Ofn88LL7zA6NGjy71UWaU1Sit9UVaZDIPBcDIeHvVp1uyZ0/YXFGSQlxdLXl4sWVl7yMzcyokTC9m3r3iVi1KeBAYOIChoEF5eLfDyisTTswmenhG4uJxlOjVDhdQ+cSoDAUTsEwwxduxYHnjggSJx+uGHH5g/fz5eXl7MmTOHgIAAEhMT6devH5dffnm5yVhnzpx5UmmNMWPGYLVaue22204qfQHw/PPPExgYyLZt2wCdT89gMFQeNzc/3Nxa4+PTmqCgQYBOmJyVtYuMjK0UFJwgO3sfyclLOXRo2ilnKzw8wvH0jMTHpz0BAX0ICOiLr2+XWuFpOZraJ05leDiWAtizGZo0gfDwqr1k9+7diY+P59ixYyQkJBAcHExkZCT5+flMnTqVFStW4OLiwtGjR4mLi6NBgwZl9lVaaY2EhIRSS1+UVibDYDCcG0opfH074Ovb4aT9FksWublHyMk5Qm7uEXJzD9veH+bEiXnExelEzC4uXnh7t8XdPRh393oEBg4kMHAQnp6NcHMLMt5WJal94lQG9l6Ae/XVV/PTTz9x/Phxxo4dC8A333xDQkICGzZswN3dnWbNmpVaKqOQskprlFX6wpTEMBiqD1dXH3x82pYa8Sci5OREk56+lrS0tWRn76GgII309HUkJPx4Ult39/p4e7fAy6sF3t4t8PFpbwt9b2X+n0tgxKmKGDt2LLfddhuJiYksX74c0OUt6tevj7u7O0uXLiU6OrrcPsoqrVFW6YvSymQY78lgqH6UUkVrs+rXv/akYzk50aSmrqagIIn8/GRycw+TnX2QtLTVxMd/D1gAcHMLwt+/Fz4+HQGxrfdqja9vZ3x9O+LuXrfK3RhxqiI6duxIeno6jRs3pmHDhgCMHz+eUaNG0atXL7p160a7du3K7WPYsGF89NFHdOnShbZt2xaV1ihZ+sJqtVK/fn0WLVrEk08+yd13302nTp1wdXXlmWee4aqrrrLPDRoMhrPCy6spXl5NSz1mteaTlbWTtLR1tryD6zh+/DPAFZF8rNasorYeHo1o0uQhmjR5uJosdyx1JpQ8IwPi4vSc09nWK6ytmFByg8H5EBFyc2PIzNxOZuYOMjO3ExIylPDwcnNql4kJJXdS/Pz0y2AwGGoCSim8vJrg5dWE0NDhjjan2qmbS6ENBoPB4NTUGnGqacOTzoL53AwGgzNSK8TJy8uLpKQk86A9Q0SEpKQkvLzONGWGwWAw2JdaMecUERFBTEwMCQkJjjalxuHl5UVEhN2KWRoMBsNZUSui9QwGg8FQPjUtWq9WDOsZDAaDoXZhxMlgMBgMTocRJ4PBYDA4HTVuzkkpZQWyz/J0N6CgCs2xNzXJXmOrfTC22oeaZCtUjb3eIlJjHJIaJ07nglJqvb1KCtuDmmSvsdU+GFvtQ02yFWqevVVBjVFRg8FgMNQdjDgZDAaDwemoa+I0w9EGnCE1yV5jq30wttqHmmQr1Dx7z5k6NedkMBgMhppBXfOcDAaDwVADMOJkMBgMBqejzoiTUmqYUmqPUmq/UmqKo+0piVKqiVJqqVJql1Jqh1Lqftv+EKXUIqXUPtvPYEfbWohSylUptUkp9Ydt2yltVUoFKaV+Ukrttn2+/Z3Y1gdtv//tSqnvlFJezmSrUmqmUipeKbW9xL4y7VNKPW77f9ujlBrqBLa+Zvs72KqUmqOUCnJWW0sc+z+llCilwpzB1uqkToiTUsoVeB8YDnQArldKdXCsVSdRADwsIu2BfsDdNvumAH+LSGvgb9u2s3A/sKvEtrPa+jYwX0TaAV3RNjudrUqpxsB9QC8R6QS4AmNxLlu/AIadsq9U+2x/v2OBjrZzPrD9H1YXX3C6rYuATiLSBdgLPA5OaytKqSbAJcDhEvscbWu1USfECegD7BeRgyKSB8wGRjvYpiJEJFZENtrep6MfoI3RNs6yNZsFXOEQA09BKRUBjAA+LbHb6WxVSgUAg4DPAEQkT0RScEJbbbgB3kopN8AHOIYT2SoiK4ATp+wuy77RwGwRyRWRKGA/+v+wWijNVhFZKCKFWRbWAIW1YpzOVhvTgUeBklFrDrW1Oqkr4tQYOFJiO8a2z+lQSjUDugP/AeEiEgtawID6DjStJG+h/2msJfY5o60tgATgc9sQ5KdKKV+c0FYROQq8jv6WHAukishCnNDWUyjLPmf/n7sZ+Mv23ulsVUpdDhwVkS2nHHI6W+1FXREnVco+p4uhV0r5AT8DD4hImqPtKQ2l1EggXkQ2ONqWSuAG9AA+FJHuQCZOMIRXGra5mtFAc6AR4KuUmuBYq84Jp/2fU0o9gR5K/6ZwVynNHGarUsoHeAJ4urTDpexzis+1qqkr4hQDNCmxHYEeMnEalFLuaGH6RkR+se2OU0o1tB1vCMQ7yr4SDAAuV0odQg+PXqiU+hrntDUGiBGR/2zbP6HFyhltvRiIEpEEEckHfgHOwzltLUlZ9jnl/5xS6kZgJDBeihd5OputLdFfUrbY/s8igI1KqQY4n612o66I0zqgtVKquVLKAz2h+LuDbSpCKaXQ8yK7ROTNEod+B260vb8R+K26bTsVEXlcRCJEpBn6c1wiIhNwTluPA0eUUm1tuy4CduKEtqKH8/oppXxsfw8XoecendHWkpRl3+/AWKWUp1KqOdAaWOsA+4pQSg0DHgMuF5GsEoecylYR2SYi9UWkme3/LAboYft7dipb7YqI1IkXcBk6QucA8ISj7TnFtoFo13wrsNn2ugwIRUdA7bP9DHG0rafYPQT4w/beKW0FugHrbZ/tr0CwE9v6LLAb2A58BXg6k63Ad+j5sHz0A/OW8uxDD00dAPYAw53A1v3o+ZrC/7GPnNXWU44fAsKcwdbqfJn0RQaDwWBwOurKsJ7BYDAYahBGnAwGg8HgdBhxMhgMBoPTYcTJYDAYDE6HESeDwWAwOB1GnAwGO6OUGlKYvd1gMFQOI04Gg8FgcDqMOBkMNpRSE5RSa5VSm5VSH9tqVmUopd5QSm1USv2tlKpna9tNKbWmRG2gYNv+VkqpxUqpLbZzWtq691PFdaW+sWWBQCn1slJqp62f1x106waD02HEyWAAlFLtgeuAASLSDbAA4wFfYKOI9ACWA8/YTvkSeEx0baBtJfZ/A7wvIl3RufFibfu7Aw+g64m1AAYopUKAK4GOtn5esOc9Ggw1CSNOBoPmIqAnsE4ptdm23QJdFuR7W5uvgYFKqUAgSESW2/bPAgYppfyBxiIyB0BEcqQ4h9taEYkRESs6dU4zIA3IAT5VSl0FlMz3ZjDUaYw4GQwaBcwSkW62V1sRmVZKu/LyfZVWzqCQ3BLvLYCb6MJ3fdDZ6K8A5p+ZyQZD7cWIk8Gg+Ru4WilVH0ApFaKUaor+H7na1mYc8I+IpALJSqnzbfsnAstF1+CKUUpdYevD01abp1Rs9bsCRWQeesivW5XflcFQQ3FztAEGgzMgIjuVUk8CC5VSLugM0XejCxR2VEptAFLR81Kgy0N8ZBOfg8BNtv0TgY+VUs/Z+rimnMv6A78ppbzQXteDVXxbBkONxWQlNxjKQSmVISJ+jrbDYKhrmGE9g8FgMDgdxnMyGAwGg9NhPCeDwWAwOB1GnAwGg8HgdBhxMhgMBoPTYcTJYDAYDE6HESeDwWAwOB3/D4ErumfLIJvJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델학습과정을 표시하고 평가하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')\n",
    "loss_ax.set_xlabel('epochs')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유 하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r',label='val acc')\n",
    "acc_ax.set_ylabel('acc')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:57:42.154011Z",
     "start_time": "2021-03-24T01:57:41.605717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 489us/step - loss: 1.3285 - accuracy: 0.5581\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test,Y_test,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:18:39.934040Z",
     "start_time": "2021-03-24T02:18:39.878119Z"
    }
   },
   "outputs": [],
   "source": [
    "# 7. 모델 사용하기\n",
    "idx = np.random.choice(X_test.shape[0],5)\n",
    "xhat = X_test[idx]\n",
    "yhat = model.predict(xhat)\n",
    "yhat = np.argmax(yhat,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:18:40.371809Z",
     "start_time": "2021-03-24T02:18:40.366847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 9, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측치\n",
    "yhat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:18:41.101862Z",
     "start_time": "2021-03-24T02:18:41.086215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 4, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제값\n",
    "np.argmax(Y_test[idx],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:20:32.719097Z",
     "start_time": "2021-03-24T02:20:32.711142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 실제값 :  2 \t예측값 :  3\n",
      "1 번째 실제값 :  4 \t예측값 :  4\n",
      "2 번째 실제값 :  4 \t예측값 :  9\n",
      "3 번째 실제값 :  3 \t예측값 :  3\n",
      "4 번째 실제값 :  5 \t예측값 :  5\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i,'번째 실제값 : ',np.argmax(Y_test[idx][i]),'\\t예측값 : ',yhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:17:05.810115Z",
     "start_time": "2021-03-24T02:17:05.566179Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8. 모델 저장하기\n",
    "model.save('model/mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:18:10.191050Z",
     "start_time": "2021-03-24T02:18:09.934524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\kks\\IDE\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 6, 3, 8, 4], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. 모델 재사용하기\n",
    "from tensorflow.keras.models import load_model\n",
    "model12 = load_model('model/mnist.h5')\n",
    "model12.predict_classes(xhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 위 모델(DNN)의 accuracy 늘리기\n",
    "<ol>\n",
    "    <li> 데이터 확보 </li>\n",
    "    <li> layer </li>\n",
    "    <li> 활성화 함수 : relu(은닉층에 사용), sigommid, softmax(output layer에서 사용)</li>\n",
    "    <li> optimizer, epoch 등을 조정</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:35:29.197857Z",
     "start_time": "2021-03-24T02:35:29.012595Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow.keras.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T04:23:30.818588Z",
     "start_time": "2021-03-24T04:17:32.023157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 32s 6ms/step - loss: 0.8224 - accuracy: 0.7375 - val_loss: 0.1638 - val_accuracy: 0.9529\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.1349 - accuracy: 0.9594 - val_loss: 0.1127 - val_accuracy: 0.9678\n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0816 - accuracy: 0.9754 - val_loss: 0.0880 - val_accuracy: 0.9733\n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0519 - accuracy: 0.9850 - val_loss: 0.0966 - val_accuracy: 0.9728\n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 0.0863 - val_accuracy: 0.9750\n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0954 - val_accuracy: 0.9760\n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0937 - val_accuracy: 0.9759\n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0116 - accuracy: 0.9965 - val_loss: 0.0813 - val_accuracy: 0.9792\n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0824 - val_accuracy: 0.9806\n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0818 - val_accuracy: 0.9826\n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 30s 6ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0967 - val_accuracy: 0.9792\n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 29s 6ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0897 - val_accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 셋 준비하기\n",
    "# 훈련셋, 테스트셋 분리. 보통 7:3으로 분류\n",
    "(X_train,Y_train),(X_test,Y_test) = mnist.load_data() # mnist 분리\n",
    "# 훈련셋에서 검증셋 분리 (X_train, Y_train)\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "# normalize 하기 위해 색상값으로 나눔\n",
    "X_train = X_train.reshape(50000,784).astype('float')/255.0\n",
    "X_val = X_val.reshape(10000,784).astype('float')/255.0\n",
    "X_test = X_test.reshape(10000,784).astype('float')/255.0\n",
    "# 데이터가 많아 시간상 매우오래 걸릴 수 있음.\n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "Y_train = utils.to_categorical(Y_train) # 자동으로 해준다\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "# 2단레이어 구조로 deeplearning\n",
    "model.add(Dense(units=1024,input_dim=784,activation='relu'))\n",
    "model.add(Dense(units=512,activation='relu'))\n",
    "model.add(Dense(units=256,activation='relu'))\n",
    "model.add(Dense(units=128,activation='relu'))\n",
    "model.add(Dense(units=64,activation='relu'))\n",
    "model.add(Dense(units=32,activation='relu'))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "\n",
    "# 3. 모델 학습과정\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "# 4. 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stop = EarlyStopping() # 성급한 조기종료( 1번이라도 val_loss가 커지면 종료)\n",
    "early_stop = EarlyStopping(patience=4) # patience 인자 수만큼 loss가 올라도 진행\n",
    "hist = model.fit(X_train,Y_train,epochs=20,batch_size=10,validation_data=(X_val,Y_val),verbose=1,\n",
    "                 callbacks=[early_stop])\n",
    "# validation_data로 과적합 발생률을 줄여준다.\n",
    "# early_stop 객체를 callbaks에 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:32:03.411890Z",
     "start_time": "2021-03-24T05:32:03.171451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. 모델학습과정을 표시하고 평가하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'],'y',label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')\n",
    "loss_ax.set_xlabel('epochs')\n",
    "loss_ax.set_ylabel('loss')\n",
    "\n",
    "acc_ax = loss_ax.twinx() # x축 공유 하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b',label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r',label='val acc')\n",
    "acc_ax.set_ylabel('acc')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:32:06.769444Z",
     "start_time": "2021-03-24T05:32:05.255555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0964 - accuracy: 0.9774\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test,Y_test,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:32:07.900342Z",
     "start_time": "2021-03-24T05:32:07.791317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020329722310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0 번째 실제값 :  1 \t예측값 :  1\n",
      "1 번째 실제값 :  5 \t예측값 :  5\n",
      "2 번째 실제값 :  4 \t예측값 :  4\n",
      "3 번째 실제값 :  4 \t예측값 :  4\n",
      "4 번째 실제값 :  6 \t예측값 :  6\n"
     ]
    }
   ],
   "source": [
    "# 7. 모델 사용하기\n",
    "idx = np.random.choice(X_test.shape[0],5)\n",
    "xhat = X_test[idx]\n",
    "yhat = model.predict(xhat)\n",
    "yhat = np.argmax(yhat,axis=1)\n",
    "for i in range(5):\n",
    "    print(i,'번째 실제값 : ',np.argmax(Y_test[idx][i]),'\\t예측값 : ',yhat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:52:55.669846Z",
     "start_time": "2021-03-24T02:52:55.596908Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8. 모델 저장하기\n",
    "model.save('model/mnist_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:52:58.319468Z",
     "start_time": "2021-03-24T02:52:58.116895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\kks\\IDE\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 9, 3, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. 모델 재사용\n",
    "from tensorflow.keras.models import load_model\n",
    "model12 = load_model('model/mnist_v2.h5')\n",
    "model12.predict_classes(xhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
